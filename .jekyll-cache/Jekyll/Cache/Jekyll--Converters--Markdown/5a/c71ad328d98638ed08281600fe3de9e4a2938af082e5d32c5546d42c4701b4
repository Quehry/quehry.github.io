I"<h1 id="目录">目录</h1>

<!-- TOC -->

<ul>
  <li><a href="#目录">目录</a></li>
  <li><a href="#1-博客简介">1. 博客简介</a></li>
  <li><a href="#2-gan简介">2. GAN简介</a></li>
  <li><a href="#3-adversarial-nets">3. Adversarial nets</a></li>
  <li><a href="#4-理论原理">4. 理论原理</a></li>
  <li><a href="#5-其他">5. 其他</a></li>
</ul>

<!-- /TOC -->

<h1 id="1-博客简介">1. 博客简介</h1>
<p>GAN的全称是generative adversarial nets，是Goodfellow于2014年提出的新的生成模型框架，这种全新的生成模型框架有很多应用和变种，这篇博客主要介绍最开始的GAN的原理和论文整理，这里阅读的论文不是最终版(区别在于related work不同)，下面列出一些链接</p>
<ul>
  <li><a href="https://arxiv.org/abs/1406.2661" target="_blank">论文链接</a></li>
  <li><a href="https://www.bilibili.com/video/BV1rb4y187vD/?spm_id_from=333.788&amp;vd_source=64c99329fc39a0e3f42825a4c837e2a5" target="_blank">李沐讲解</a></li>
</ul>

<h1 id="2-gan简介">2. GAN简介</h1>
<p>GAN是一种全新的生成模型框架，它包含两个部分，生成模型G和辨别模型D，G的作用是捕捉数据的分布，D的作用是辨别数据来源于真实数据分布还是G生成的数据分布。生成模型训练过程就是让D犯错的可能性更高。GAN框架其实就是一个minmax game，如果G和D都是MLP的话，那么整个系统可以用逆传播机制训练。GAN的作者举了一个简单的例子介绍模型训练过程，生成模型可以看成印假钞的团伙，辨别模型可以看成警察，双方都在训练中提升自己的能力，最终希望达到的效果是警察无法分辨出一张假钞是真币还是假币。论文只介绍了一种特殊情况，就是G和D都是MLP的情况，作者把这种情况称为Adversarial nets</p>

<h1 id="3-adversarial-nets">3. Adversarial nets</h1>
<p>为了让生成模型学习到分布$p_g$(分布尽量和原始数据x的分布一致)，需要定义输入噪音的先验分布$p_z(z)$，$G(z;\theta_g)$表示噪音z输入生成模型的结果，G是一个可微分的函数，这里是MLP，参数为$\theta_g$。$D(x;\theta_d)$表示输入x后的辨别模型的结果，输出是一个标量，表示x来自于真实数据分布的概率。</p>

<p>也就是说，D和G的价值函数V(G, D)可表示为:</p>
<center><img src="../assets/img/posts/20220927/2.jpg" /></center>
<p>辨别模型D的目标是最大化价值函数的值，D(x)的取值在0-1之间，所以价值函数越大说明辨别模型D的效果越好，生成模型G的目标是最小化价值函数的值。GAN训练生成模型和辨别模型的过程为:</p>
<center><img src="../assets/img/posts/20220927/3.jpg" /></center>
<p>绿色的线是生成模型，蓝色虚线是辨别模型，黑色的散点线是原始数据分布</p>

<h1 id="4-理论原理">4. 理论原理</h1>
<p>算法原理由下面这一张图片展示:</p>
<center><img src="../assets/img/posts/20220927/4.jpg" /></center>
<p>在每个迭代周期的每个批量中，我们有m个取自先验分布的噪音z，其中z$\sim$ $p_g(z)$和m个取自真实分布的x，其中x$\sim$ $p_{data}(x)$，先训练辨别器D，沿着梯度上升的方向更新参数，然后在沿着log(1-D(G($z^{(i)}$)))的梯度下降的方向更新参数。</p>

<p>接下来介绍了一些命题和证明和一些定理，证实了GAN用到的价值函数和目标函数的可行性</p>

<h1 id="5-其他">5. 其他</h1>
<ul>
  <li>GAN在刚提出的时候还是有很多缺点的，比如模型还是比较难训练的，但是后续有很多很多的工作来优化原始的GAN模型，所以GAN更像是抛出了一个引子，让后续模型来优化它</li>
  <li>GAN本质上就是左右手互博，目标函数设计的也很好</li>
</ul>
:ET