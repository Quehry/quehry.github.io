I"-<!-- TOC -->

<ul>
  <li><a href="#1-推荐系统总览">1. 推荐系统总览</a>
    <ul>
      <li><a href="#11-协同过滤-collaborative-filtering">1.1. 协同过滤 Collaborative Filtering</a></li>
      <li><a href="#12-显式反馈和隐式反馈">1.2. 显式反馈和隐式反馈</a></li>
      <li><a href="#13-推荐任务">1.3. 推荐任务</a></li>
    </ul>
  </li>
  <li><a href="#2-矩阵分解-matrix-factorization">2. 矩阵分解 Matrix Factorization</a></li>
  <li><a href="#3-autorec">3. AutoRec</a>
    <ul>
      <li><a href="#31-overview">3.1. overview</a></li>
      <li><a href="#32-formula">3.2. formula</a></li>
    </ul>
  </li>
  <li><a href="#4-personalized-ranking-for-recommender-system">4. Personalized Ranking for Recommender System</a>
    <ul>
      <li><a href="#41-overview">4.1. overview</a></li>
      <li><a href="#42-bayesian-personalized-ranking-loss-贝叶斯损失">4.2. Bayesian Personalized Ranking loss 贝叶斯损失</a></li>
      <li><a href="#43-hinge-loss">4.3. Hinge Loss</a></li>
    </ul>
  </li>
  <li><a href="#5-neural-collaborative-filtering-for-personalized-ranking-使用协同过滤网络个性化排序">5. Neural Collaborative Filtering for Personalized Ranking 使用协同过滤网络个性化排序</a>
    <ul>
      <li><a href="#51-the-neumf-model">5.1. The NeuMF model</a></li>
      <li><a href="#52-evaluator">5.2. Evaluator</a></li>
      <li><a href="#53-代码">5.3. 代码</a></li>
    </ul>
  </li>
  <li><a href="#6-sequence-aware-recommender-systems">6. Sequence-Aware Recommender Systems</a>
    <ul>
      <li><a href="#61-model-architectures">6.1. Model Architectures</a></li>
      <li><a href="#62-negative-sampling-负采样">6.2. Negative Sampling 负采样</a></li>
    </ul>
  </li>
  <li><a href="#7-feature-rich-recommender-systems">7. Feature-Rich Recommender Systems</a></li>
  <li><a href="#8-factorization-machines">8. Factorization Machines</a></li>
</ul>

<!-- /TOC -->

<h2 id="1-推荐系统总览">1. 推荐系统总览</h2>
<h3 id="11-协同过滤-collaborative-filtering">1.1. 协同过滤 Collaborative Filtering</h3>
<p>协同过滤最早出现在1992年Tapestry system，“人们相互协作，相互帮助，执行过滤程序，以处理大量的电子邮件和张贴到新闻组的信息。”现在协同过滤的概念更加广泛，从广义上讲，它是利用涉及多个用户、代理和数据源之间协作的技术来过滤<strong>信息或模式</strong>的过程。</p>

<p>协同过滤模型可以分为:1.memory-based CF; 2.model-based CF. 其中Memory-based CF又可以分为item-based和user-based CF。model-based CF有矩阵分解模型。</p>

<p>总的来说，协同过滤就是利用用户-物品的数据来预测和推荐。</p>

<h3 id="12-显式反馈和隐式反馈">1.2. 显式反馈和隐式反馈</h3>
<p>为了学习用户的偏好，系统需要收集用户的反馈feedback。反馈可以分为显式和隐式。</p>

<p>显式反馈就是需要用户主动提供兴趣偏好。比如点赞、点踩。</p>

<p>隐式反馈则是间接反映用户的喜好，比如购物历史记录，浏览记录，观看记录甚至是鼠标移动。</p>

<h3 id="13-推荐任务">1.3. 推荐任务</h3>
<p>电影推荐、新闻推荐、评分预测rating prediction task、top-n reommendation。如果使用了时间戳信息，那么我们构建了sequence-aware recommendation。针对新用户推荐新物品称为cold-start recommendation冷启动推荐。</p>

<h2 id="2-矩阵分解-matrix-factorization">2. 矩阵分解 Matrix Factorization</h2>
<p>The Matrix Factorization Model矩阵分解模型</p>

<p>R是user-item矩阵，行数是用户数量，列数是物品数量,那么R∈R<sup>mxn</sup>。P是user latent matrix，P∈R<sup>mxk</sup>，Q是item latent matrix，Q∈R<sup>nxk</sup></p>

<p>矩阵分解就是把R分解成P和Q，那么预测的评分就是：</p>

<p><img src="../assets/img/posts/20211216/2.jpg" /></p>

<p>但是上面这个式子没有考虑偏置，我们会有下面这个完整的式子：</p>

<p><img src="../assets/img/posts/20211216/3.jpg" /></p>

<p>那么<strong>目标函数</strong>可以定义为：</p>

<p><img src="../assets/img/posts/20211216/4.jpg" /></p>

<p>右边那一串是正则项，为了避免过拟合</p>

<p>下面这张图值观的展示了矩阵分解过程：</p>

<p><img src="../assets/img/posts/20211216/5.jpg" /></p>

<h2 id="3-autorec">3. AutoRec</h2>
<h3 id="31-overview">3.1. overview</h3>
<p>使用autoencoder预测评分，上小节介绍的矩阵分解模型是线性模型，它不能捕捉复杂的非线性关系，比如用户的偏好。这一小节介绍一个非线性协同过滤神经网络模型AutoRec。</p>

<p>AutoRec是基于自编码器的结构，自编码器是一种特殊的神经网络架构，他的输入和输出的架构是相同的，自编码器通过无监督学习来训练获取输入数据在较低维度的表达，在神经网络的后段，这些低纬度的信息再次被重构回高维的数据表达。</p>

<p>所以AutoRec的架构也是输入层，隐藏层和重构输出层。它的目的是输入一个只有部分兴趣矩阵，输出一个完整的兴趣矩阵。</p>

<p>AutoRec可以分为user-based 和 item-based</p>

<h3 id="32-formula">3.2. formula</h3>
<p>针对item-based：</p>

<p>$R_{*i}$表示兴趣矩阵的第i列，不知道的项填为0。那么神经网络的构架可以定义为：</p>

<center><img src="../assets/img/posts/20211216/6.jpg" /></center>

<p>h()表示最终的输出，输出一个完整的兴趣矩阵，那么误差定义为：</p>

<center><img src="../assets/img/posts/20211216/7.jpg" /></center>

<h2 id="4-personalized-ranking-for-recommender-system">4. Personalized Ranking for Recommender System</h2>
<h3 id="41-overview">4.1. overview</h3>
<p>在上一节中，我们用到了显式反馈，同时模型只在能观察到的评分上训练。那么这种模型有两个缺点：第一个是很多的反馈并不是显式的。第二个是没有观察到的评分被完全忽略了。</p>

<p>个性化推荐可以分为:1.pointwise;2.pairwise;3.listwise。Pointwise表示每次预测单个偏好，pairwise则是预测出一系列的偏好然后进行排序，listwise则是预测所有的item并进行排序。</p>

<h3 id="42-bayesian-personalized-ranking-loss-贝叶斯损失">4.2. Bayesian Personalized Ranking loss 贝叶斯损失</h3>
<ul>
  <li>
    <p>贝叶斯损失是一种pairwise个性化推荐损失。它被广泛应用于多种推荐系统中。它假设用户相对于无观察项，更加喜欢positive item</p>
  </li>
  <li>
    <p>训练集格式是(u, i, j)表示用户u喜欢i超过j，BPR希望最大化下面这个后验概率：</p>
  </li>
</ul>

<center><img src="../assets/img/posts/20211216/8.jpg" /></center>

<p>其中$\Theta$表示推荐系统的参数，$&gt;_u$表示用户u对所有item的排序。</p>

<center><img src="../assets/img/posts/20211216/9.jpg" /></center>

<h3 id="43-hinge-loss">4.3. Hinge Loss</h3>
<ul>
  <li>数学表达式</li>
</ul>

<center><img src="../assets/img/posts/20211216/10.jpg" /></center>

<p>其中m表示安全系数，它的目的是让不喜欢的项离喜欢的项更远。它和贝叶斯都是为了优化positive sample和negative sample之间的距离。</p>

<h2 id="5-neural-collaborative-filtering-for-personalized-ranking-使用协同过滤网络个性化排序">5. Neural Collaborative Filtering for Personalized Ranking 使用协同过滤网络个性化排序</h2>
<p>本小节重新将目光聚集到隐式反馈中，介绍协同过滤推荐系统NeuMF。NeuMF利用隐式反馈，它由两个子结构组成，分别是generalized matrix factorization(GMF)和MLP。不同于评分的预测如AutoRec，它将生成一系列的推荐，它根据用户是否看过这场电影来区分为正例和反例</p>

<h3 id="51-the-neumf-model">5.1. The NeuMF model</h3>
<p>NeuMF的网络结构由两部分组成。</p>

<ul>
  <li>一部分是GMF，也就是matrix factorization的类似形式，输入用户向量$p_u$和物品向量$q_i$，返回x</li>
</ul>

<center><img src="../assets/img/posts/20211216/12.jpg" /></center>

<ul>
  <li>另一部分是MLP，输入和GMF一样，但是用不同的字母表示，具体公式如下：</li>
</ul>

<center><img src="../assets/img/posts/20211216/13.jpg" /></center>

<ul>
  <li>最后对这两个子结构concatenate一下，就是最终的输出</li>
</ul>

<center><img src="../assets/img/posts/20211216/14.jpg" /></center>

<ul>
  <li>大体的网络结构如下</li>
</ul>

<center><img src="../assets/img/posts/20211216/11.jpg" /></center>

<h3 id="52-evaluator">5.2. Evaluator</h3>
<p>有两个性能度量指标</p>

<ul>
  <li>hit rate at given cutting off l，记作Hit@l</li>
</ul>

<center><img src="../assets/img/posts/20211216/15.jpg" /></center>

<p>这个式子的主题思路是判断推荐的物品是否在top l中，m表示用户的数量，$rank_{u,g_u}$表示对于用户u和物品$g_u$的排名，1表示指标函数</p>

<ul>
  <li>AUC，即ROC曲线下的面积，也是模型泛化能力的一个指标</li>
</ul>

<center><img src="../assets/img/posts/20211216/16.jpg" /></center>

<p>其中$S_u$表示模型对于u的推荐物品集，I表示item set，AUC越大越好</p>

<h3 id="53-代码">5.3. 代码</h3>
<p>网络结构就是上面介绍的那样，net的输出是用户和物品匹配出的一个推荐值(我的想法)。在进行训练的时候，会给出正例物品(即用户有过评分的物品)和反例物品(用户没有评分，也就是没有看过)分别与用户得到一个推荐值，然后利用上一小节介绍的贝叶斯损失来优化(让评分过的物品有更高的推荐值)，然后最终我们希望返回一系列的推荐物品，这些推荐物品都是没有负例物品，然后根据推荐值进行排序。性能指标是hit或者auc。hit的思想是让真实评分的物品在推荐列表中。</p>

<h2 id="6-sequence-aware-recommender-systems">6. Sequence-Aware Recommender Systems</h2>
<p>之前的模型都没有考虑时序信息，这小节的Caser模型将会考虑用户的时序信息。</p>
<h3 id="61-model-architectures">6.1. Model Architectures</h3>
<p>模型的输入$E^{(u,t)}$表示用户u的近期L个评价的物品，Caser模型有横向和纵向的卷积层，输入矩阵分别与卷积层作用后，结果concatenate变成$z$，$z$再和用户的一般信息结合，也就是$z$和$p_u$concatenate最终输出$\hat{y}_{uit}$，其中$p_u$表示用户u的item信息</p>

<center><img src="../assets/img/posts/20211216/17.jpg" /></center>

<h3 id="62-negative-sampling-负采样">6.2. Negative Sampling 负采样</h3>
<p>我们需要对数据集进行重新处理，比如一个人喜欢9部电影，同时我们的L=5，那么我们将最近的一部电影留出来作为test，其余的都作为训练集，可以划分出3个训练集。同时我们也需要进行负采样(采样没有评分的item)</p>

<h2 id="7-feature-rich-recommender-systems">7. Feature-Rich Recommender Systems</h2>
<p>之前的模型大都用到了用户物品的交互矩阵，但是很少有用到一些额外的信息，比如物品的特征，用户的简介，发生交互的背景等等…利用这些信息可以获得用户的兴趣特征。本节提出了一个新的任务CTR(click-through rate)，也就是点击率任务，对象可以是广告、电影等等。</p>

<h2 id="8-factorization-machines">8. Factorization Machines</h2>
:ET