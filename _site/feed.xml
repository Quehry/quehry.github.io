<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-12-13T11:54:24+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Quehry</title><subtitle>Artificial Intelligence trends and concepts made easy.</subtitle><author><name>Quehry</name></author><entry><title type="html">Robotics</title><link href="http://localhost:4000/Robotics.html" rel="alternate" type="text/html" title="Robotics" /><published>2021-12-13T00:00:00+08:00</published><updated>2021-12-13T00:00:00+08:00</updated><id>http://localhost:4000/Robotics</id><content type="html" xml:base="http://localhost:4000/Robotics.html">&lt;h1 id=&quot;报告&quot;&gt;报告&lt;/h1&gt;
&lt;h2 id=&quot;报告内容&quot;&gt;报告内容&lt;/h2&gt;
&lt;p&gt;用solidworks设计一个至少三个自由度的机械臂，并且描述它的动能，移动能力等等。提交的是截图，源文件等等。&lt;/p&gt;
&lt;h2 id=&quot;报告格式&quot;&gt;报告格式&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;标题，下面有姓名学号电话等等&lt;/li&gt;
  &lt;li&gt;摘要&lt;/li&gt;
  &lt;li&gt;正文&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Quehry</name></author><category term="note" /><summary type="html">报告 报告内容 用solidworks设计一个至少三个自由度的机械臂，并且描述它的动能，移动能力等等。提交的是截图，源文件等等。 报告格式 标题，下面有姓名学号电话等等 摘要 正文</summary></entry><entry><title type="html">数据挖掘</title><link href="http://localhost:4000/datamining.html" rel="alternate" type="text/html" title="数据挖掘" /><published>2021-12-10T00:00:00+08:00</published><updated>2021-12-10T00:00:00+08:00</updated><id>http://localhost:4000/datamining</id><content type="html" xml:base="http://localhost:4000/datamining.html">&lt;h1 id=&quot;总体情况&quot;&gt;总体情况&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;书籍:Python数据挖掘入门与实践&lt;/li&gt;
  &lt;li&gt;github_url:https://github.com/LinXueyuanStdio/PythonDataMining&lt;/li&gt;
  &lt;li&gt;配套代码和笔记，很适合迅速上手&lt;/li&gt;
  &lt;li&gt;这篇博客主要记录一些比较重要的算法&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;第一章-开始数据挖掘之旅&quot;&gt;第一章 开始数据挖掘之旅&lt;/h2&gt;
&lt;h3 id=&quot;11-亲和性分析&quot;&gt;1.1 亲和性分析&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;亲和性分析根据样本个体（物体）之间的&lt;strong&gt;相似度&lt;/strong&gt;，确定它们关系的亲疏。&lt;/li&gt;
  &lt;li&gt;例子：商品推荐。&lt;/li&gt;
  &lt;li&gt;我们要找出“如果顾客购买了商品X，那么他们可能愿意购买商品Y”这样的规则。简单粗暴的做法是，找出数据集中所有同时购买的两件商品。找出规则后，还需要判断其优劣，我们挑好的规则用。&lt;/li&gt;
  &lt;li&gt;规则的优劣有多种判断标准，常用的有支持度(support)和置信度(confidence)&lt;/li&gt;
  &lt;li&gt;支持度：数据集中规则应验的次数，统计起来很简单。有时候，还需要对支持度进行规范化，即再除以规则有效前提下的总数量。&lt;/li&gt;
  &lt;li&gt;置信度是衡量规则的准确性如何。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;12-分类&quot;&gt;1.2 分类&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;根据特征分出类别&lt;/li&gt;
  &lt;li&gt;例子：Iris植物分类数据集，通过四个特征分出三个类别&lt;/li&gt;
  &lt;li&gt;特征连续值变成离散值&lt;/li&gt;
  &lt;li&gt;OneR算法：它根据已有数据中，具有相同特征值的个体最可能属于哪个类别进行分类。比如对于某一个特征值来说，属于A的类别有80个，属于B的类别有20个，那么对于这个特征值来说，取值为1代表为A类别，错误率有20％。给出所有特征值，找出错误率最小的特征值作为判断标准。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;第二章-用scikit-learn估计器分类&quot;&gt;第二章 用scikit-learn估计器分类&lt;/h2&gt;
&lt;h3 id=&quot;21-scikit-learn&quot;&gt;2.1 scikit-learn&lt;/h3&gt;
&lt;p&gt;scikit-learn里面已经封装好很多数据挖掘的算法&lt;/p&gt;

&lt;p&gt;现介绍数据挖掘框架的搭建方法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;转换器（Transformer）用于数据预处理，数据转换&lt;/li&gt;
  &lt;li&gt;流水线（Pipeline）组合数据挖掘流程，方便再次使用（封装）&lt;/li&gt;
  &lt;li&gt;估计器（Estimator）用于分类，聚类，回归分析（各种算法对象）
    &lt;ul&gt;
      &lt;li&gt;所有的估计器都有下面2个函数
        &lt;ul&gt;
          &lt;li&gt;fit() 训练
            &lt;ul&gt;
              &lt;li&gt;用法：estimator.fit(X_train, y_train)，&lt;/li&gt;
              &lt;li&gt;estimator = KNeighborsClassifier() 是scikit-learn算法对象&lt;/li&gt;
              &lt;li&gt;X_train = dataset.data 是numpy数组&lt;/li&gt;
              &lt;li&gt;y_train = dataset.target 是numpy数组&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;predict() 预测
            &lt;ul&gt;
              &lt;li&gt;用法：estimator.predict(X_test)&lt;/li&gt;
              &lt;li&gt;estimator = KNeighborsClassifier() 是scikit-learn算法对象&lt;/li&gt;
              &lt;li&gt;X_test = dataset.data 是numpy数组&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;22-邻近算法knn&quot;&gt;2.2 邻近算法KNN&lt;/h3&gt;
&lt;p&gt;邻近算法，或者说K最邻近（KNN，K-NearestNeighbor）分类算法是数据挖掘分类技术中最简单的方法之一。所谓K最近邻，就是K个最近的邻居的意思，说的是每个样本都可以用它最接近的K个邻近值来代表。近邻算法就是将数据集合中每一个记录进行分类的方法。&lt;/p&gt;

&lt;p&gt;例子：分类，Ionosphere数据集&lt;/p&gt;

&lt;h2 id=&quot;第三章-用决策树预测获胜球队&quot;&gt;第三章 用决策树预测获胜球队&lt;/h2&gt;

&lt;h3 id=&quot;31-决策树&quot;&gt;3.1 决策树&lt;/h3&gt;
&lt;p&gt;例子：预测NBA球队获胜情况&lt;/p&gt;

&lt;p&gt;决策树是一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试输出，每个叶节点代表一种类别。&lt;/p&gt;

&lt;p&gt;分类树（决策树）是一种十分常用的分类方法。它是一种监督学习，所谓监督学习就是给定一堆样本，每个样本都有一组属性和一个类别，这些类别是事先确定的，那么通过学习得到一个分类器，这个分类器能够对新出现的对象给出正确的分类。这样的机器学习就被称之为监督学习。&lt;/p&gt;

&lt;p&gt;scikit-learn库实现了分类回归树（Classification and Regression Trees，CART）算法并将其作为生成决策树的默认算法，它支持连续型特征和类别型特征。&lt;/p&gt;

&lt;h3 id=&quot;32-随机森林&quot;&gt;3.2 随机森林&lt;/h3&gt;
&lt;p&gt;随机森林指的是利用多棵树对样本进行训练并预测的一种分类器。&lt;/p&gt;

&lt;p&gt;在机器学习中，随机森林是一个包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。&lt;/p&gt;

&lt;h2 id=&quot;第四章-用亲和性分析方法推荐电影&quot;&gt;第四章 用亲和性分析方法推荐电影&lt;/h2&gt;
&lt;h3 id=&quot;41-亲和性分析&quot;&gt;4.1 亲和性分析&lt;/h3&gt;
&lt;p&gt;亲和性分析就是分析两个样本之间的疏密关系，常用的算法有Apriori，Apriori算法的一大特点是根据最小支持度生成&lt;strong&gt;频繁项集&lt;/strong&gt;（frequent itemest），它只从数据集中频繁出现的商品中选取共同出现的商品组成频繁项集。其他亲和性分析算法有Eclat和频繁项集挖掘算法（FP-growth）。&lt;/p&gt;

&lt;h3 id=&quot;42-apriori算法&quot;&gt;4.2 Apriori算法&lt;/h3&gt;
&lt;p&gt;Apriori算法主要有两个阶段，第一个阶段是根据最小支持度生成频繁项集，第二个阶段是根据最小置信度选择规则，返回规则。&lt;/p&gt;

&lt;p&gt;本章的例子是电影推荐。&lt;/p&gt;

&lt;p&gt;第一个阶段，算法会先生成长度较小的项集，再将这个项集作为超集寻找长度较大的项集。&lt;/p&gt;

&lt;p&gt;第二个阶段是从频繁项集中抽取关联规则。把其中几部电影作为前提，另一部电影作为结论。组成如下形式的规则：如果用户喜欢前提中的所有电影，那么他们也会喜欢结论中的电影。&lt;/p&gt;

&lt;h2 id=&quot;第五章-用转换器抽取特征&quot;&gt;第五章 用转换器抽取特征&lt;/h2&gt;
&lt;h3 id=&quot;51-抽取特征&quot;&gt;5.1 抽取特征&lt;/h3&gt;
&lt;p&gt;抽取数据集的特征是重要的一步，在之前的学习中我们都获得了数据集的特征，但很多没有处理的文本特征并不是很明显，比如一段文本等等。特征值可以分为连续特征，序数特征，类别型特征。&lt;/p&gt;

&lt;h3 id=&quot;52-特征选择&quot;&gt;5.2 特征选择&lt;/h3&gt;
&lt;p&gt;通常特征有很多，但我们只想选择其中一部分。&lt;strong&gt;选用干净的数据，选取更具描述性的特征。&lt;/strong&gt;判断特征相关性：书中列举的例子是判断一个人的收入能不能超过五万，利用单变量卡方检验(或者皮尔逊相关系数)判断各个特征的相关性，然后给出了三个最好的特征，分别是年龄，资本收入和资本损失。&lt;/p&gt;

&lt;h3 id=&quot;53-创建特征&quot;&gt;5.3 创建特征&lt;/h3&gt;
&lt;p&gt;主成分分析算法（Principal Component Analysis，PCA）的目的是找到能用较少信息描述数据集的特征组合。&lt;/p&gt;

&lt;h2 id=&quot;第六章-使用朴素贝叶斯进行社会媒体挖掘&quot;&gt;第六章 使用朴素贝叶斯进行社会媒体挖掘&lt;/h2&gt;
&lt;h3 id=&quot;61-消歧&quot;&gt;6.1 消歧&lt;/h3&gt;
&lt;p&gt;本章我们将处理文本，文本通常被称为无结构格式。文本挖掘的一个难点来自于歧义，比如bank一词多义。本章将探讨区别Twitter消息中Python的意思。&lt;/p&gt;

&lt;h3 id=&quot;62-文本转换器&quot;&gt;6.2 文本转换器&lt;/h3&gt;
&lt;p&gt;Python中处理文本的库NLTK(Natural Language Toolkit)。据作者说很好用，可以作自然语言处理。N元语法是指由连续的词组成的子序列。&lt;/p&gt;

&lt;h3 id=&quot;63-朴素贝叶斯&quot;&gt;6.3 朴素贝叶斯&lt;/h3&gt;
&lt;p&gt;朴素贝叶斯概率模型是以对贝叶斯统计方法的朴素解释为基础。&lt;/p&gt;

&lt;p&gt;贝叶斯定理公式如下：&lt;/p&gt;

&lt;p&gt;$ P(A|B) = \frac {P(B|A)P(A)}{P(B)} $&lt;/p&gt;

&lt;p&gt;贝叶斯公式可以用它来计算个体属于给定类别的概率。朴素贝叶斯算法假定了各个特征之间相互独立，那么我们计算文档D属于类别C的概率为P(D|C)=P(D1|C)*P(D2|C)…P(Dn|C)。贝叶斯分类器是输入数据来更新贝叶斯的先验概率和后验概率，输入贝叶斯模型后，返回不同类别中概率的最大值。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;举例说明下计算过程，假如数据集中有以下一条用二值特征表示的数据：[1, 0, 0, 1]。&lt;br /&gt;
训练集中有75%的数据属于类别0，25%属于类别1，且每个特征属于每个类别的似然度如下。&lt;br /&gt;
类别0：[0.3, 0.4, 0.4, 0.7] &lt;br /&gt;
类别1：[0.7, 0.3, 0.4, 0.9] &lt;br /&gt;
拿类别0中特征1的似然度举例子，上面这两行数据可以这样理解：类别0中有30%的数据，特征1的值为1。&lt;br /&gt;
我们来计算一下这条数据属于类别0的概率。类别为0时，P(C=0) = 0.75。&lt;br /&gt;
朴素贝叶斯算法用不到P(D)，因此我们不用计算它。我们来看下计算过程。&lt;br /&gt;
P(D|C=0) = P(D1|C=0) x P(D2|C=0) x P(D3|C=0) x P(D4|C=0)&lt;br /&gt;
= 0.3 x 0.6 x 0.6 x 0.7 &lt;br /&gt;
= 0.0756 &lt;br /&gt;
现在，我们就可以计算该条数据从属于每个类别的概率。需要提醒的是，我们没有计算P(D)，因此，计算结果不是实际的概率。由于两次都不计算P(D)，结果具有可比较性，能够区分出大小就足够了。来看下计算结果。&lt;br /&gt;
P(C=0|D) = P(C=0) P(D|C=0) &lt;br /&gt;
= 0.75 * 0.0756 &lt;br /&gt;
= 0.0567&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;64-f1值&quot;&gt;6.4 F1值&lt;/h3&gt;
&lt;p&gt;F1值是一种评价指标。F1值是以每个类别为基础进行定义的，包括两大概念：准确率（precision）和召回率（recall）。准确率是指预测结果属于某一类的个体，实际属于该类的比例。召回率是指被正确预测为某个类别的个体数量与数据集中该类别个体总量的比例。F1值是准确率和召回率的调和平均数。&lt;/p&gt;</content><author><name>Quehry</name></author><category term="note" /><summary type="html">总体情况 书籍:Python数据挖掘入门与实践 github_url:https://github.com/LinXueyuanStdio/PythonDataMining 配套代码和笔记，很适合迅速上手 这篇博客主要记录一些比较重要的算法</summary></entry><entry><title type="html">RACE数据集相关文献</title><link href="http://localhost:4000/RACE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE.html" rel="alternate" type="text/html" title="RACE数据集相关文献" /><published>2021-11-30T00:00:00+08:00</published><updated>2021-11-30T00:00:00+08:00</updated><id>http://localhost:4000/RACE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE</id><content type="html" xml:base="http://localhost:4000/RACE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE.html">&lt;h1 id=&quot;目录&quot;&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot;&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#文献整理&quot;&gt;文献整理&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#要求&quot;&gt;要求&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#搜集到相关文献标题和地址&quot;&gt;搜集到相关文献标题和地址&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#第一篇&quot;&gt;第一篇&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#title&quot;&gt;Title&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#author&quot;&gt;Author&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#abstract&quot;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bert-distractor-generation&quot;&gt;BERT distractor generation&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1bert-based-distractor-generationbdg&quot;&gt;1)BERT-based distractor generation(BDG)&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2multi-task-with-parallel-mlm&quot;&gt;2)Multi-task with Parallel MLM&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3answer-negative-regularization&quot;&gt;3)Answer Negative Regularization&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#multiple-distractor-generation&quot;&gt;Multiple Distractor Generation&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1selecting-distractors-by-entropy-maximization&quot;&gt;1)Selecting Distractors by Entropy Maximization&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2bdg-em&quot;&gt;2)BDG-EM&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#performance-evaluation&quot;&gt;Performance Evaluation&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1datasets&quot;&gt;1)datasets&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2implementation-details&quot;&gt;2)implementation details&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3compared-methods&quot;&gt;3)compared methods&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#4token-score-comparison&quot;&gt;4)token score comparison&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#5mcq-model-accuracy-comparison&quot;&gt;5)MCQ Model Accuracy Comparison&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#6parameter-study-on-γ&quot;&gt;6）Parameter Study on γ&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#我的看法&quot;&gt;我的看法&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#第二篇&quot;&gt;第二篇&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#title-1&quot;&gt;Title&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#author-1&quot;&gt;Author&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#abstract-1&quot;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#method&quot;&gt;Method&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1question-generation&quot;&gt;1)question generation&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2distractor-generation&quot;&gt;2)distractor generation&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3qa-filtering&quot;&gt;3)QA filtering&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#results&quot;&gt;Results&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1quantitative-evaluation&quot;&gt;1)quantitative evaluation&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2question-answering-ability&quot;&gt;2)question answering ability&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3human-evaluation&quot;&gt;3)human evaluation&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#第三篇&quot;&gt;第三篇&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#title-2&quot;&gt;Title&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#author-2&quot;&gt;Author&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#abstract-2&quot;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#framework-description-网络结构&quot;&gt;Framework Description 网络结构&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1task-definition&quot;&gt;1)Task Definition&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2framework-overview&quot;&gt;2)Framework overview&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3hierarchical-encoder&quot;&gt;3)Hierarchical encoder&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#4static-attention-mechanism&quot;&gt;4)static attention mechanism&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#5encoding-layer&quot;&gt;5)encoding layer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#6matching-layer&quot;&gt;6)matching layer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#7nomalization-layer&quot;&gt;7)nomalization layer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#8distractor-decoder&quot;&gt;8)distractor decoder&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#9question-based-initializer&quot;&gt;9)question-based initializer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#10dynamic-hierarchical-attention-mechanism&quot;&gt;10)dynamic hierarchical attention mechanism&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#11training-and-inference&quot;&gt;11)training and inference&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#experimental-setting-实验设置&quot;&gt;experimental setting 实验设置&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1dataset&quot;&gt;1)dataset&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2implementation-details-1&quot;&gt;2)implementation details&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3baselines-and-ablations&quot;&gt;3)baselines and ablations&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#results-and-analysis-结果与分析&quot;&gt;results and analysis 结果与分析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#我的看法-1&quot;&gt;我的看法&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#第四篇&quot;&gt;第四篇&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#title-3&quot;&gt;Title&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#author-3&quot;&gt;Author&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#abstract-3&quot;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#proposed-framework-网络结构&quot;&gt;Proposed Framework 网络结构&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1notations-and-task-definition&quot;&gt;1)notations and task definition&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2model-overview&quot;&gt;2)model overview&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3encoding-article-and-question&quot;&gt;3)encoding article and question&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#4co-attention-between-article-and-question&quot;&gt;4)Co-attention between article and question&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#5merging-sentence-representation&quot;&gt;5)Merging sentence representation&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#6question-initialization&quot;&gt;6)question initialization&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#7hierarchical-attention&quot;&gt;7)hierarchical attention&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#8semantic-similarity-loss&quot;&gt;8)semantic similarity loss&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#experimental-settings&quot;&gt;Experimental Settings&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1dataset-1&quot;&gt;1)dataset&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2baselines-and-evaluation-metrics&quot;&gt;2)baselines and evaluation metrics&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3implementation-details&quot;&gt;3)implementation details&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#results-and-analysis-结果与分析&quot;&gt;Results and Analysis 结果与分析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#我的看法-2&quot;&gt;我的看法&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#补充&quot;&gt;补充&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#race数据集简介&quot;&gt;RACE数据集简介&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bleu&quot;&gt;BLEU&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#rouge&quot;&gt;ROUGE&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;文献整理&quot;&gt;文献整理&lt;/h1&gt;

&lt;h2 id=&quot;要求&quot;&gt;要求&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/requirements.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;搜集到相关文献标题和地址&quot;&gt;搜集到相关文献标题和地址&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2010.05384.pdf&quot;&gt;A BERT-based Distractor Generation Scheme with Multi-tasking and Negative Answer Training Strategies&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2010.09598.pdf&quot;&gt;Better Distractions: Transformer-based Distractor Generation and Multiple Choice Question Filtering&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ojs.aaai.org//index.php/AAAI/article/view/4606&quot;&gt;Generating Distractors for Reading Comprehension Questions from Real Examinations&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ojs.aaai.org/index.php/AAAI/article/view/6522&quot;&gt;Co-attention hierarchical network: Generating coherent long distractors for reading comprehension&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aclanthology.org/2020.coling-main.189.pdf&quot;&gt;Automatic Distractor Generation for Multiple Choice Questions in Standard Tests&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aclanthology.org/W18-0533.pdf&quot;&gt;Distractor Generation for Multiple Choice Questions Using Learning to Rank&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ojs.aaai.org/index.php/AAAI/article/view/16559&quot;&gt;Knowledge-Driven Distractor Generation for Cloze-style Multiple Choice Questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;第一篇&quot;&gt;第一篇&lt;/h1&gt;
&lt;h2 id=&quot;title&quot;&gt;Title&lt;/h2&gt;
&lt;p&gt;A BERT-based Distractor Generation Scheme with Multi-tasking and
Negative Answer Training Strategies&lt;/p&gt;
&lt;h2 id=&quot;author&quot;&gt;Author&lt;/h2&gt;
&lt;p&gt;Ho-Lam Chung, Ying-Hong Chan, Yao-Chung Fan&lt;/p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;现有的DG&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;局限在只能生成一个误导选项，我们需要生成多个误导选项，文章中提到他们团队用multi-tasking和negative answer training技巧来生成多个误导选项，模型结果达到了学界顶尖。&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;DG效果不好，文章提出了两个提升的空间：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;DG质量提升：&lt;br /&gt;
 BERT模型来提升误导选项质量&lt;/li&gt;
  &lt;li&gt;多个误导选项生成：
 运用了覆盖的方法来选择distractor，而不是选择概率最高但是语义很相近的distractor&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;bert-distractor-generation&quot;&gt;BERT distractor generation&lt;/h2&gt;
&lt;h3 id=&quot;1bert-based-distractor-generationbdg&quot;&gt;1)BERT-based distractor generation(BDG)&lt;/h3&gt;
&lt;p&gt;输入：段落P，答案A，问题Q，用C表示这三者concatenate后的结果。&lt;br /&gt;
BDG模型是一个自回归模型，在预测阶段，每次输入C和上一次预测的词元，BDG迭代预测词元，直到预测出特殊词元[S]停止。下面这张图简单介绍了这个过程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;网络结构简单介绍：h&lt;sub&gt;[M]&lt;/sub&gt;表示bert输出的隐藏状态，隐藏状态再输入到一个全连接层中用来预测词元。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/3.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2multi-task-with-parallel-mlm&quot;&gt;2)Multi-task with Parallel MLM&lt;/h3&gt;
&lt;p&gt;MLM全称masked language model，遮蔽语言模型,通过并行BDG和P-MLM来训练模型让模型有更好的效果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/4.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图中左边的sequential MLM就是之前提到的BDG，BDG模型是一个词接一个词的预测，P-MLM是对所有的masked token进行预测，最后的损失函数是这两者相加&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;，公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/5.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/6.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/7.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;作者如此设计的思路是：BDG可能会忽略整体语义语义信息，但是会过拟合单个词预测。那么并行一个P-MLM可以防止过拟合。&lt;/p&gt;

&lt;h3 id=&quot;3answer-negative-regularization&quot;&gt;3)Answer Negative Regularization&lt;/h3&gt;
&lt;p&gt;目前机器预测的distractor和answer有很高的相似度，下面一张表可以展示相似度。其中PM表示机器，Gold表示人工，作者将这类问题称为answer copying problem。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/8.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了解决这个问题，作者提出了answer negative loss来让机器更多的选择与answer不同的词来表示新的distractor，公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/9.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出BDG的loss替换成了AN的loss，每一项都减去了Answer negative loss。&lt;/p&gt;

&lt;h2 id=&quot;multiple-distractor-generation&quot;&gt;Multiple Distractor Generation&lt;/h2&gt;
&lt;h3 id=&quot;1selecting-distractors-by-entropy-maximization&quot;&gt;1)Selecting Distractors by Entropy Maximization&lt;/h3&gt;
&lt;p&gt;选择语义不同的distractor set。文章借鉴了MRC&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;的方法，让BDGmodel生成很多distractor组成 $\hat{D}$ = {$\hat{d}$&lt;sub&gt;1&lt;/sub&gt;, $\hat{d}$&lt;sub&gt;2&lt;/sub&gt;, $\hat{d}$&lt;sub&gt;3&lt;/sub&gt;…}，然后找出最好的一组选项，一般情况下由三个误导选项和一个答案组成。选择的一句是最大化下面这个公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/10.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2bdg-em&quot;&gt;2)BDG-EM&lt;/h3&gt;
&lt;p&gt;我们可以通过不同的BDG模型来生成不同的误导选项最后组合，不同的模型区别是有没有answer negative/multi-task training，比如我们有这几个模型:$\hat{D}$,$\hat{D}$&lt;sub&gt;PM&lt;/sub&gt;,$\hat{D}$&lt;sub&gt;PM+AN&lt;/sub&gt;，它们分别代表含PM&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;和含AN&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/11.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;performance-evaluation&quot;&gt;Performance Evaluation&lt;/h2&gt;
&lt;h3 id=&quot;1datasets&quot;&gt;1)datasets&lt;/h3&gt;
&lt;p&gt;RACE,沿用了&lt;a href=&quot;https://ojs.aaai.org//index.php/AAAI/article/view/4606&quot;&gt;Gao&lt;/a&gt;那篇论文的处理,后面也会梳理那篇论文&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/12.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2implementation-details&quot;&gt;2)implementation details&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;tokenizer: wordpiece tokenizer&lt;/li&gt;
  &lt;li&gt;framewordk:huggingface trainsformers&lt;/li&gt;
  &lt;li&gt;optimizer:adamW(lr:5e-5)&lt;/li&gt;
  &lt;li&gt;github_url: &lt;a href=&quot;https://github.com/voidful/BDG&quot;&gt;BDG&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3compared-methods&quot;&gt;3)compared methods&lt;/h3&gt;
&lt;p&gt;比较了不同的distractor generation&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CO-Att：出自&lt;a href=&quot;https://ojs.aaai.org/index.php/AAAI/article/view/6522&quot;&gt;Zhou&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;DS-Att: 出自&lt;a href=&quot;https://ojs.aaai.org//index.php/AAAI/article/view/4606&quot;&gt;Gao&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;GPT:baseline&lt;/li&gt;
  &lt;li&gt;BDG: 没有应用P-MLM和Answer negative&lt;/li&gt;
  &lt;li&gt;BDG&lt;sub&gt;PM&lt;/sub&gt;&lt;/li&gt;
  &lt;li&gt;BDG&lt;sub&gt;AN+PM&lt;/sub&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4token-score-comparison&quot;&gt;4)token score comparison&lt;/h3&gt;
&lt;p&gt;BLEU和ROUGE(L)两种判断指标&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/13.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;copying problem的效果&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/14.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;5mcq-model-accuracy-comparison&quot;&gt;5)MCQ Model Accuracy Comparison&lt;/h3&gt;
&lt;p&gt;与回答系统相结合，将生成好的选项（一个正确答案三个误导选项）放入MCQ answering model，下面是回答正确率的表格&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/15.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出作者的模型选项的误导性还是很高的。&lt;/p&gt;

&lt;h3 id=&quot;6parameter-study-on-γ&quot;&gt;6）Parameter Study on γ&lt;/h3&gt;
&lt;p&gt;之前使用P-MLM并行训练时候有个权重参数γ，下表显示了不同γ值的影响，对于只有PM的模型来说，γ=6，对于既有AN和PM来说，γ=7&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/16.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;现存的DG可以分为cloze-style distractor generation和 reading comprehension distractor generation，前者主要是word filling，后者主要看重语义信息，基于两者的设计出了很多模型，目前来看还是考虑语义信息生成的误导选项更好。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/17.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;我的看法&quot;&gt;我的看法&lt;/h2&gt;
&lt;p&gt;文章中的模型提到了三种技术，第一是bert预训练模型使用。第二是P-MLM的并行使用， 它的使用让模型可以考虑段落的语义信息，那么生成的误导选项是sentence-level而不是之前模型所使用的类似word-filling这种word-level。第三是Answer negative loss的使用，它的使用相当于让模型不要考虑与正确答案语义很接近的误导选项，因为目前大多数DG生成多个选项时语义与正确答案都非常接近，这与实际情况不符，同时也起不到误导的作用。  &lt;br /&gt;
同时文章提出了生成多个误导选项时使用不同模型生成的误导选项拼在一起作为选项是一种比较好的解决方法，让一次性生成多个误导选型有了一定的可用性。&lt;br /&gt;
文章的代码开源，可以去&lt;a href=&quot;https://github.com/voidful/BDG&quot;&gt;github&lt;/a&gt;上看训练细节和网络结构细节。&lt;/p&gt;

&lt;h1 id=&quot;第二篇&quot;&gt;第二篇&lt;/h1&gt;
&lt;h2 id=&quot;title-1&quot;&gt;Title&lt;/h2&gt;
&lt;p&gt;Better Distractions: Transformer-based Distractor Generation and Multiple Choice Question Filtering&lt;/p&gt;
&lt;h2 id=&quot;author-1&quot;&gt;Author&lt;/h2&gt;
&lt;p&gt;Jeroen Offerijns, Suzan Verberne, Tessa Verhoef&lt;/p&gt;
&lt;h2 id=&quot;abstract-1&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;运用GPT2模型生成三个误导选项，同时用BERT模型去回答这个问题，只挑选出回答正确的问题。相当于使用了QA作为一个过滤器(QA filtering)。&lt;/p&gt;
&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;
&lt;p&gt;作者使用了Question generation model, distractor generation model和question answer filter，作者将从这三方面介绍，下图是大概的流程图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/18.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1question-generation&quot;&gt;1)question generation&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;预训练模型：GPT-2&lt;/li&gt;
  &lt;li&gt;数据集：English SQuAD&lt;/li&gt;
  &lt;li&gt;tokenizer：Byte-Pair-Encoding(BPE) tokenizer&lt;/li&gt;
  &lt;li&gt;optimizer:Adam&lt;/li&gt;
  &lt;li&gt;下图展示了QG的输入，黑框内被tokenizer标记为特殊词元&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/19.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2distractor-generation&quot;&gt;2)distractor generation&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;预训练模型：GPT-2&lt;/li&gt;
  &lt;li&gt;数据集：RACE&lt;/li&gt;
  &lt;li&gt;tokenizer:BPE&lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
  &lt;li&gt;使用了repetition penalty技术，保证了尽量不会生成相似的text，并且过滤到那些不好的生成（比如生成了空字符串）&lt;/li&gt;
  &lt;li&gt;输入：经典的C(context)，A(answer),Q(question)，下图展示了输入格式&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/20.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3qa-filtering&quot;&gt;3)QA filtering&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;预训练模型：DistilBERT&lt;/li&gt;
  &lt;li&gt;网络结构：CQA&lt;sup id=&quot;fnref:7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;输入到distilbert，再连接一个dropout，全连接层和softmax，最后输出一个答案，具体结构如下图&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/21.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;h3 id=&quot;1quantitative-evaluation&quot;&gt;1)quantitative evaluation&lt;/h3&gt;
&lt;p&gt;下表中展示了和上一篇论文类似的指标,与现有的模型进行了比较：SEQ2SEQ,HSA&lt;sup id=&quot;fnref:8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;和CHN&lt;sup id=&quot;fnref:9&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;。可以看出BLEU明显要比之前模型要好，但是ROUGE没有之前的高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/22.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2question-answering-ability&quot;&gt;2)question answering ability&lt;/h3&gt;
&lt;p&gt;用GPT-2模型生成误导选项再输入到QAmodel中，具体结果见下图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/23.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3human-evaluation&quot;&gt;3)human evaluation&lt;/h3&gt;
&lt;p&gt;人工评估，从两方面评估distractor生成的好坏：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Is the question well-formed and can you understand the meaning?&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;If the question is at least understandable, does the answer make sense in relation to the question?&lt;/strong&gt;
评估过程中，使用了155个没有经过QA筛选和155经过QA筛选的，了解一下QA过滤模型的效果。整体来说QA过滤器还是有一点效果，具体结果如下：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/24.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion-1&quot;&gt;conclusion&lt;/h2&gt;
&lt;p&gt;我认为作者使用的DG模型主要有两大特色，一个是使用了GPT2预训练模型，目前使用基于transformer的模型已经成为主流。第二个是使用了QA过滤器来筛选掉回答错误的，有一定提升但不显著。&lt;/p&gt;

&lt;h1 id=&quot;第三篇&quot;&gt;第三篇&lt;/h1&gt;
&lt;h2 id=&quot;title-2&quot;&gt;Title&lt;/h2&gt;
&lt;p&gt;Generating Distractors for Reading Comprehension Questions from Real Examinations&lt;/p&gt;
&lt;h2 id=&quot;author-2&quot;&gt;Author&lt;/h2&gt;
&lt;p&gt;Yifan Gao, Lidong Bing, Piji Li,
Irwin King, Michael R. Lyu&lt;/p&gt;
&lt;h2 id=&quot;abstract-2&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;上面两篇文献都有提到这篇文章。作者使用了&lt;strong&gt;Hierarchical encoder-decoder framework&lt;/strong&gt; with &lt;strong&gt;static&lt;/strong&gt; and &lt;strong&gt;dynamic&lt;/strong&gt; attention mechanisms来生成有语义信息的误导选项。使用了编码器-解码器结构网络和静态和动态注意力机制。&lt;/p&gt;
&lt;h2 id=&quot;framework-description-网络结构&quot;&gt;Framework Description 网络结构&lt;/h2&gt;
&lt;h3 id=&quot;1task-definition&quot;&gt;1)Task Definition&lt;/h3&gt;
&lt;p&gt;输入：文章，问题和答案。P代表文章，s&lt;sub&gt;1&lt;/sub&gt;,s&lt;sub&gt;2&lt;/sub&gt;,s&lt;sub&gt;3&lt;/sub&gt;…表示不同的句子，q和a分别表示问题和答案，那么我们的任务是生成误导选项$\overline{d}$。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/25.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2framework-overview&quot;&gt;2)Framework overview&lt;/h3&gt;
&lt;p&gt;网络结构如下图所示，下面将从各个组成部分分别介绍：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/26.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3hierarchical-encoder&quot;&gt;3)Hierarchical encoder&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;word embedding&lt;/strong&gt;:词嵌入，将每个句子s&lt;sub&gt;i&lt;/sub&gt;中的每个词元变成词向量(w&lt;sub&gt;i,1&lt;/sub&gt;,w&lt;sub&gt;i,2&lt;/sub&gt;,w&lt;sub&gt;i,3&lt;/sub&gt;…)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;word encoder&lt;/strong&gt;:将句子s&lt;sub&gt;i&lt;/sub&gt;的词向量(w&lt;sub&gt;i,1&lt;/sub&gt;,w&lt;sub&gt;i,2&lt;/sub&gt;,w&lt;sub&gt;i,3&lt;/sub&gt;…)作为输入，用&lt;strong&gt;双向LSTM&lt;/strong&gt;作为编码器，获得word-level representation h&lt;sub&gt;i,j&lt;/sub&gt;&lt;sup&gt;e&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/27.jpg&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;sentence encoder&lt;/strong&gt;:将word encoder中每个句子正向LSTM的最后一个隐藏状态和反向LSTM的最开始的隐藏状态作为输入到另一个双向LSTM中获得&lt;strong&gt;sentence-level representation&lt;/strong&gt;(u&lt;sub&gt;1&lt;/sub&gt;,u&lt;sub&gt;2&lt;/sub&gt;,u&lt;sub&gt;3&lt;/sub&gt;…)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4static-attention-mechanism&quot;&gt;4)static attention mechanism&lt;/h3&gt;
&lt;p&gt;目的：生成的误导选项必须和问题Q语义相关，但是和答案A必须语义不相关。我们从(s&lt;sub&gt;1&lt;/sub&gt;,s&lt;sub&gt;2&lt;/sub&gt;,s&lt;sub&gt;3&lt;/sub&gt;…)学习到句子的权重分布(γ&lt;sub&gt;1&lt;/sub&gt;,γ&lt;sub&gt;2&lt;/sub&gt;,γ&lt;sub&gt;3&lt;/sub&gt;…)，然后将问题q和答案a作为query。&lt;/p&gt;

&lt;h3 id=&quot;5encoding-layer&quot;&gt;5)encoding layer&lt;/h3&gt;
&lt;p&gt;我们希望把问题q，答案a和句子s都变成一样的长度的向量表示，也就是上图中紫色虚线部分。对于q和a，我们用两个独立的双向LSTM来获得(&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt;,&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;2&lt;/sub&gt;…&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;k&lt;/sub&gt;)和(&lt;strong&gt;q&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt;,&lt;strong&gt;q&lt;/strong&gt;&lt;sub&gt;2&lt;/sub&gt;…&lt;strong&gt;q&lt;/strong&gt;&lt;sub&gt;l&lt;/sub&gt;)，然后用平均池化层平均一下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/28.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于句子s，我们不用u而用h：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/29.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;6matching-layer&quot;&gt;6)matching layer&lt;/h3&gt;
&lt;p&gt;目的：加重与问题q有关的句子，减轻与答案a有关的句子。o&lt;sub&gt;i&lt;/sub&gt;表示不同句子的importance score&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/30.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;7nomalization-layer&quot;&gt;7)nomalization layer&lt;/h3&gt;
&lt;p&gt;目的：有些问题q和一两个句子有关，而有些问题q和很多句子有关，比如summarizing，下面的τ(temperature)就是这个作用&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/31.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/32.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;作者介绍static attention mechanism用了很大篇幅&lt;/p&gt;

&lt;h3 id=&quot;8distractor-decoder&quot;&gt;8)distractor decoder&lt;/h3&gt;
&lt;p&gt;解码器使用的也是LSTM，但是并没有使用编码器的最后一个隐藏状态作为初始状态，而是定义了一个
&lt;strong&gt;question-based initializer&lt;/strong&gt;来让生成的误导选项语法和问题q一致&lt;/p&gt;

&lt;h3 id=&quot;9question-based-initializer&quot;&gt;9)question-based initializer&lt;/h3&gt;
&lt;p&gt;定义了一个question LSTM来编码问题q，使用最后一层的cell state和hidden state作为decoder初始状态，同时输入q&lt;sub&gt;last&lt;/sub&gt;，表示问题q的最后一个词元。&lt;/p&gt;

&lt;h3 id=&quot;10dynamic-hierarchical-attention-mechanism&quot;&gt;10)dynamic hierarchical attention mechanism&lt;/h3&gt;
&lt;p&gt;常规的注意力机制将一篇文章作为长句子，然后decoder的每一个时间步都与encoder中所有的hidden state进行比较，但是这种方法并不适合目前的模型。原因：首先LSTM不能处理这么长的输入，其次，一些问题只与部分句子有关。&lt;br /&gt;
目的：每个decoder时间步只关注&lt;strong&gt;重要句子&lt;/strong&gt;，作者将这种注意力机制称为动态注意力机制，因为不同的时间步，word-level和sentence-level 注意力分布都不同。&lt;br /&gt;
每一个时间步的输入是词元d&lt;sub&gt;t-1&lt;/sub&gt;和上一个隐藏状态h&lt;sub&gt;t-1&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/33.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/34.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;α和β分别表示word-level,sentence-level权重，最后使用之前静态注意力机制获得的γ来调节α和β&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/35.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/36.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;获得上下文变量&lt;strong&gt;c&lt;/strong&gt;&lt;sub&gt;t&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/37.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;获得attention vector $\tilde{h}$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/38.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;11training-and-inference&quot;&gt;11)training and inference&lt;/h3&gt;
&lt;p&gt;损失函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/39.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;生成多个误导选项的方法是束搜索，但是生成的误导选项很相似，作者做了相应的处理方法，但我觉得效果还是很差&lt;/p&gt;

&lt;h2 id=&quot;experimental-setting-实验设置&quot;&gt;experimental setting 实验设置&lt;/h2&gt;
&lt;h3 id=&quot;1dataset&quot;&gt;1)dataset&lt;/h3&gt;
&lt;p&gt;RACE数据集，作者做了相应的处理，去掉了很多不合理的和语义不相关的，作者的处理标准是：对于误导选项中的词元，如果它们在文章中出现的次数小于5次，那么将被保留，同时去掉了那些需要在句子中间和句子开始填空的问题。下表展示了处理后的数据集的一些信息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/40.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2implementation-details-1&quot;&gt;2)implementation details&lt;/h3&gt;
&lt;p&gt;词表：保留了频率最高的50k个词元，同时使用GloVe作为词嵌入预训练模型。其他的细节都可以在文章中看见，这里不一一列出了，主要是超参数的设置。&lt;/p&gt;

&lt;h3 id=&quot;3baselines-and-ablations&quot;&gt;3)baselines and ablations&lt;/h3&gt;
&lt;p&gt;与HRED&lt;sup id=&quot;fnref:10&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;和seq2seq比较&lt;/p&gt;

&lt;h2 id=&quot;results-and-analysis-结果与分析&quot;&gt;results and analysis 结果与分析&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/41.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;人工评估：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/42.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;大致过程是这样：四个误导选项，分别来自seq2seq，HRED，作者的模型和原本的误导选项，让英语能力很好的人来选择最适合的选项，得出的结果可以发现，作者的模型生成的误导选项拥有最好的误导效果。&lt;/p&gt;

&lt;p&gt;下图直观展示了static attention distribution：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/43.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;我的看法-1&quot;&gt;我的看法&lt;/h2&gt;
&lt;p&gt;这篇文章应该是第一个提出用处理后的RACE数据集来处理MCQ问题，处理后的RACE数据集在后面也有很多文献用到，这篇文章使用了seq2seq网络结构同时使用了静态和动态注意力机制，对于网络结构和注意力机制的解释非常完全和详细，虽然这篇文章的效果放到现在来看可能不是最好了，但是它提出来的评估标准可能会成为一个通用的标准。它的数据集和训练代码在&lt;a href=&quot;https://github.com/Yifan-Gao/Distractor-Generation-RACE&quot;&gt;github&lt;/a&gt;上也完全开源。&lt;/p&gt;

&lt;h1 id=&quot;第四篇&quot;&gt;第四篇&lt;/h1&gt;
&lt;h2 id=&quot;title-3&quot;&gt;Title&lt;/h2&gt;
&lt;p&gt;Co-attention hierarchical network: Generating coherent long distractors for reading comprehension&lt;/p&gt;
&lt;h2 id=&quot;author-3&quot;&gt;Author&lt;/h2&gt;
&lt;p&gt;Xiaorui Zhou, Senlin Luo, Yunfang Wu&lt;/p&gt;
&lt;h2 id=&quot;abstract-3&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;这篇文献是针对上一篇Gao的文章(seq2seq)所作的改进。本篇文章提出了Gao的模型的两个问题：1.没有建立文章和问题的关系，他的解决方法是使用&lt;strong&gt;co-attention enhanced hierarchical architecture&lt;/strong&gt;来捕获文章和问题之间的关系，让解码器生成更有关联的误导选项。2.没有加重整篇文章和误导选项的关系。作者的解决思路是添加一个额外的语义相关性损失函数，让生成的误导选项与整篇文章更有关联。&lt;/p&gt;
&lt;h2 id=&quot;proposed-framework-网络结构&quot;&gt;Proposed Framework 网络结构&lt;/h2&gt;
&lt;h3 id=&quot;1notations-and-task-definition&quot;&gt;1)notations and task definition&lt;/h3&gt;
&lt;p&gt;article T=(s&lt;sub&gt;1&lt;/sub&gt;,s&lt;sub&gt;2&lt;/sub&gt;…s&lt;sub&gt;k&lt;/sub&gt;)，一篇文章有k个句子s，同时每个句子都有不同的长度l，s&lt;sub&gt;i&lt;/sub&gt;=(w&lt;sub&gt;i,1&lt;/sub&gt;,w&lt;sub&gt;i,2&lt;/sub&gt;…w&lt;sub&gt;i,l&lt;/sub&gt;)，每个文章有m个问题和z个误导选项，Q=(q&lt;sub&gt;1&lt;/sub&gt;,q&lt;sub&gt;2&lt;/sub&gt;…q&lt;sub&gt;m&lt;/sub&gt;),D=(d&lt;sub&gt;1&lt;/sub&gt;,d&lt;sub&gt;2&lt;/sub&gt;…d&lt;sub&gt;z&lt;/sub&gt;),我们的任务是根据输入的T和Q生成D&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/44.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2model-overview&quot;&gt;2)model overview&lt;/h3&gt;
&lt;p&gt;整体结构如下图所示，下面将从各个部分分别介绍：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/45.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3encoding-article-and-question&quot;&gt;3)encoding article and question&lt;/h3&gt;
&lt;p&gt;文章和问题的编码器结构&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;hierarchical article encoder&lt;/strong&gt;
双向LSTM，和上一篇结构很像，很多部分我就简单列个式子。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/46.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每一句最后的词元来表示整个句子&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/47.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;sentence-level encoder：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/48.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;同样，用最后一个句子来表示整篇文章&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/49.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;用&lt;strong&gt;H&lt;/strong&gt;&lt;sup&gt;*&lt;/sup&gt;来作为sentence-level representation of article,我们有&lt;strong&gt;H&lt;/strong&gt;&lt;sub&gt;:t&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;=h&lt;sub&gt;t&lt;/sub&gt;&lt;sup&gt;s&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;这样，通过使用两个双向LSTM获得word-level encoding和sentence-level encoding&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;question encoder&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/50.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;用&lt;strong&gt;U&lt;/strong&gt;&lt;sup&gt;*&lt;/sup&gt;来作为word-level representations of question, 我们有&lt;strong&gt;U&lt;/strong&gt;&lt;sub&gt;:t&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;=h&lt;sub&gt;t&lt;/sub&gt;&lt;sup&gt;q&lt;/sup&gt;&lt;/p&gt;

&lt;h3 id=&quot;4co-attention-between-article-and-question&quot;&gt;4)Co-attention between article and question&lt;/h3&gt;
&lt;p&gt;Co-attention mechanism就是使用了两个方向的注意力机制，有从article到question的，也有question到article的。&lt;br /&gt;
用一个“相似”矩阵S表示H和U的关系：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/51.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;S&lt;sub&gt;i,j&lt;/sub&gt;就表示第i个句子和第j个问题词元的相似性&lt;/p&gt;

&lt;p&gt;我们可以获得两个特殊的矩阵&lt;strong&gt;S&lt;/strong&gt;&lt;sup&gt;&lt;strong&gt;Q&lt;/strong&gt;&lt;/sup&gt;和&lt;strong&gt;S&lt;/strong&gt;&lt;sup&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/52.jpg&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;article-to-question attention&lt;br /&gt;
$\tilde{U}$&lt;sub&gt;:j&lt;/sub&gt; = $\sum$ S&lt;sub&gt;i,j&lt;/sub&gt;&lt;sup&gt;Q&lt;/sup&gt;U&lt;sub&gt;:,i&lt;/sub&gt;&lt;/li&gt;
  &lt;li&gt;question-to-article attention&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/53.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后，将问题的词级表示H，两个方向的注意力结果$\tilde{U}$和$\tilde{H}$结合一下获得G&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/54.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;5merging-sentence-representation&quot;&gt;5)Merging sentence representation&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/55.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Z表示final representation of sentence-level hidden states&lt;/p&gt;

&lt;h3 id=&quot;6question-initialization&quot;&gt;6)question initialization&lt;/h3&gt;
&lt;p&gt;接下来就进入decoder环节，这里的question initialization和上篇文献处理方法相同&lt;/p&gt;

&lt;h3 id=&quot;7hierarchical-attention&quot;&gt;7)hierarchical attention&lt;/h3&gt;
&lt;p&gt;不同时间步有不同的句子相关，和上篇文献的处理方法动态注意力机制相同。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/56.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/57.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/58.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/59.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;8semantic-similarity-loss&quot;&gt;8)semantic similarity loss&lt;/h3&gt;
&lt;p&gt;目的：获得文章和误导选项的关系。还记得之前定义的e&lt;sub&gt;T&lt;/sub&gt;吗，它表示整篇文章，那么我们通过下面的公式可以获得distractor representation:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/60.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中S&lt;sub&gt;M&lt;/sub&gt;是decoder最后一个隐藏状态，那么我们通过cos计算相似关系，那么最终的损失函数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/61.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;experimental-settings&quot;&gt;Experimental Settings&lt;/h2&gt;
&lt;h3 id=&quot;1dataset-1&quot;&gt;1)dataset&lt;/h3&gt;
&lt;p&gt;使用了上篇文献处理过的RACE数据集。&lt;/p&gt;

&lt;h3 id=&quot;2baselines-and-evaluation-metrics&quot;&gt;2)baselines and evaluation metrics&lt;/h3&gt;
&lt;p&gt;与seq2seq，HRED，HCP&lt;sup id=&quot;fnref:11&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;，HSA&lt;sup id=&quot;fnref:12&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;比较。&lt;/p&gt;

&lt;h3 id=&quot;3implementation-details&quot;&gt;3)implementation details&lt;/h3&gt;
&lt;p&gt;网络超参数设置技巧，不展开了&lt;/p&gt;

&lt;h2 id=&quot;results-and-analysis-结果与分析-1&quot;&gt;Results and Analysis 结果与分析&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/62.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/63.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/64.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;介绍一下上面这张表，这张表是人工评估的结果，从三个维度分析，分别是fluency,coherence,distracting ability。可以看出作者的模型并不是在所有维度都是最好的。&lt;/p&gt;

&lt;p&gt;下图是案例分析：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/65.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;我的看法-2&quot;&gt;我的看法&lt;/h2&gt;
&lt;p&gt;这篇文献是基于上一篇文献的方法进行了两个改进：1.关联了整篇文章和问题，解决方法是使用了Co-attention mechanism。2.让distractor和article语义相关，方法是定义了相关性loss。&lt;/p&gt;

&lt;h1 id=&quot;补充&quot;&gt;补充&lt;/h1&gt;
&lt;h2 id=&quot;race数据集简介&quot;&gt;RACE数据集简介&lt;/h2&gt;
&lt;p&gt;RACE数据集是一个来源于中学考试题目的大规模阅读理解数据集，包含了大约 28000 个文章以及近 100000 个问题。它的形式类似于英语考试中的阅读理解（选择题），给定一篇文章，通过阅读并理解文章（Passage），针对提出的问题（Question）从四个选项中选择正确的答案（Answers）。&lt;/p&gt;
&lt;h2 id=&quot;bleu&quot;&gt;BLEU&lt;/h2&gt;
&lt;p&gt;BLEU是一个评价指标，最开始用于机器翻译任务，定义如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/66.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;它的总体思想就是准确率，假如给定标准译文reference，神经网络生成的句子是candidate，句子长度为n，candidate中有m个单词出现在reference，m/n就是bleu的1-gram的计算公式。BLEU还有许多变种。根据n-gram可以划分成多种评价指标，常见的指标有BLEU-1、BLEU-2、BLEU-3、BLEU-4四种，其中n-gram指的是连续的单词个数为n。&lt;/p&gt;

&lt;h2 id=&quot;rouge&quot;&gt;ROUGE&lt;/h2&gt;
&lt;p&gt;Rouge(Recall-Oriented Understudy for Gisting Evaluation)，是评估自动文摘以及机器翻译的一组指标。它通过将自动生成的摘要或翻译与一组参考摘要（通常是人工生成的）进行比较计算，得出相应的分值，以衡量自动生成的摘要或翻译与参考摘要之间的“相似度”。它的定义如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/67.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;文献中使用的ROUGE-L是一种变种，L即是LCS(longest common subsequence，最长公共子序列)的首字母，因为Rouge-L使用了最长公共子序列。Rouge-L计算方式如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/68.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中LCS(X, Y)是X和Y的最长公共子序列的长度,m、n分别表示参考摘要和自动摘要的长度（一般就是所含词的个数），R&lt;sub&gt;lcs&lt;/sub&gt;,P&lt;sub&gt;lcs&lt;/sub&gt;分别表示召回率和准确率。最后的F&lt;sub&gt;lcs&lt;/sub&gt;即是我们所说的Rouge-L。&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;distractor generation 误导选项生成，简称DG &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;当我们test时，只需要Sequential MLM decoder来预测。 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;multi-choice reading comprehension (MRC) model &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;P-MLM &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Answer negative &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Byte-Pair-Encoding &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;context，question，answer &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;hierarchical encoder-decoder model with static attention &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;hierarchical model enhanced with co-attention &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;hierarchical encoder-decoder &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;相当于HRED+copy,是基于HRED的网络结构 &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;就是上篇文献的网络 &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Quehry</name></author><category term="paper" /><summary type="html">目录</summary></entry><entry><title type="html">软件方法</title><link href="http://localhost:4000/%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95.html" rel="alternate" type="text/html" title="软件方法" /><published>2021-11-30T00:00:00+08:00</published><updated>2021-11-30T00:00:00+08:00</updated><id>http://localhost:4000/%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95</id><content type="html" xml:base="http://localhost:4000/%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95.html">&lt;h2 id=&quot;课程要求&quot;&gt;课程要求&lt;/h2&gt;
&lt;p&gt;学习面向对象这种软件开发方法（目前概念越来越广），通过java来了解面向对象具体怎么实现。&lt;/p&gt;

&lt;h3 id=&quot;随记&quot;&gt;随记&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;类，对象：
    &lt;ul&gt;
      &lt;li&gt;给类赋值变成实例/对象&lt;/li&gt;
      &lt;li&gt;c语言可以构建面向对象所有的结构&lt;/li&gt;
      &lt;li&gt;对象就是给类声明的一个变量&lt;/li&gt;
      &lt;li&gt;类集合了属性和方法&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;面向对象的三大特征：
    &lt;ul&gt;
      &lt;li&gt;封装（encapsulation）:
        &lt;ul&gt;
          &lt;li&gt;private, protected, public&lt;/li&gt;
          &lt;li&gt;可作用于属性和方法&lt;/li&gt;
          &lt;li&gt;一般是隐藏对象的属性和实现细节，但是提供方法的接口&lt;/li&gt;
          &lt;li&gt;提供公开的方法&lt;/li&gt;
          &lt;li&gt;提高了软件开发的效率&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/1.jpg&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;继承（inheritance）：
        &lt;ul&gt;
          &lt;li&gt;子类与父类&lt;/li&gt;
          &lt;li&gt;子类自动具有父类属性和方法，添加自己特有的属性和方法，并且子类使用父类的方法也可以覆盖/重写父类方法&lt;/li&gt;
          &lt;li&gt;可以实现代码的复用（当然功能不止于此）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;多态（polymorphism）：
        &lt;ul&gt;
          &lt;li&gt;父类有多个子类&lt;/li&gt;
          &lt;li&gt;子类覆盖/重写父类方法&lt;/li&gt;
          &lt;li&gt;相当于是根据实际创建的对象类型动态决定使用哪个方法&lt;/li&gt;
          &lt;li&gt;所有的子类都可以看成父类的类型，运行时，系统会自动调用各种子类的方法&lt;/li&gt;
          &lt;li&gt;UML可以画出类之间的关系&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;java程序设计
    &lt;ul&gt;
      &lt;li&gt;百分百面向对象
        &lt;ul&gt;
          &lt;li&gt;不存在类以外代码&lt;/li&gt;
          &lt;li&gt;只能采用面向对象方法编程&lt;/li&gt;
          &lt;li&gt;java文件命名规范
            &lt;ul&gt;
              &lt;li&gt;必须以.java结尾&lt;/li&gt;
              &lt;li&gt;源文件中如果只有一个类，文件类必须与该类名相同&lt;/li&gt;
              &lt;li&gt;如果有多个类，且没有public类，文件名可与任一类名相同&lt;/li&gt;
              &lt;li&gt;有多个类，且有public类，文件名必须与该类名相同&lt;/li&gt;
              &lt;li&gt;一个JAVA源文件只能有一个public类，一个文件中只能有一个main主函数&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;静态方法/static，可以直接用类和函数名直接调用，和普通方法的区别是不用new一个示例&lt;/li&gt;
      &lt;li&gt;多态的实现，先定义抽象的（abstract）父类，然后子类继承父类然后定义父类的抽象方法
        &lt;ul&gt;
          &lt;li&gt;通过抽象方法固定通用接口&lt;/li&gt;
          &lt;li&gt;子类通过强制实现抽象方法实现多态&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>Quehry</name></author><category term="school" /><summary type="html">课程要求 学习面向对象这种软件开发方法（目前概念越来越广），通过java来了解面向对象具体怎么实现。</summary></entry><entry><title type="html">课程总结</title><link href="http://localhost:4000/%E5%A4%A7%E5%9B%9B%E4%B8%8A%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93.html" rel="alternate" type="text/html" title="课程总结" /><published>2021-11-28T00:00:00+08:00</published><updated>2021-11-28T00:00:00+08:00</updated><id>http://localhost:4000/%E5%A4%A7%E5%9B%9B%E4%B8%8A%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93</id><content type="html" xml:base="http://localhost:4000/%E5%A4%A7%E5%9B%9B%E4%B8%8A%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93.html">&lt;h1 id=&quot;概率统计&quot;&gt;概率统计&lt;/h1&gt;
&lt;h3 id=&quot;简介&quot;&gt;简介&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;授课老师：牛薇&lt;/li&gt;
  &lt;li&gt;授课材料：一份法语讲义，一份习题集（10个EX），上课用的PPT&lt;/li&gt;
  &lt;li&gt;B站有录播，up主：却道成归&lt;/li&gt;
  &lt;li&gt;笔记记在侧边栏为大四上A的笔记本最前面&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;内容总览&quot;&gt;内容总览&lt;/h3&gt;
&lt;p&gt;一半时间概率一半时间统计&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;概率
    &lt;ul&gt;
      &lt;li&gt;先从之前学的概率空间讲起，介绍了概率分布（离散or连续），密度函数，期望方差，收敛性。&lt;/li&gt;
      &lt;li&gt;估计，比如说用平均值估计期望，用频率估计概率等等&lt;/li&gt;
      &lt;li&gt;估计又分为点估计和区间估计，点估计中介绍了似然函数以及最大似然法来找估计量&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;统计
    &lt;ul&gt;
      &lt;li&gt;主要介绍了几种检验方法来检验分布、估计量选择的好坏&lt;/li&gt;
      &lt;li&gt;包括了参数检验，分布检验，比较检验等等&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;A4纸&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/1.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/2.jpg&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;流体力学&quot;&gt;流体力学&lt;/h1&gt;
&lt;h3 id=&quot;简介-1&quot;&gt;简介&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- 授课老师：方乐
- 授课材料：PPT，TD都是6个，分别对应六大章
- B站有录播
- 笔记在侧边栏为大四上A的中后部分和大四上B前面
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;内容总览-1&quot;&gt;内容总览&lt;/h3&gt;
&lt;p&gt;第一章主要讲了流体的概念和动力学的公式。第二章从能量角度出发，介绍了NS方程（斯托克斯方程），和伯努利原理（压强和流速的关系）。第三章介绍了雷诺数，无量纲分析，雷诺数大的是湍流，雷诺数小的是层流。第四章介绍了边界层，第五章介绍了湍流，系统平均。第六章介绍了涡量。&lt;/p&gt;

&lt;h3 id=&quot;a4纸&quot;&gt;A4纸&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/3.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/4.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;报告&quot;&gt;报告&lt;/h3&gt;
&lt;p&gt;结课之前需要我们写一个报告，什么形式的都可以，我觉得这种方式挺好的，自由发挥，我做的实验，用牛奶和墨水还原了卡门涡街。&lt;/p&gt;

&lt;h1 id=&quot;电磁辐射波&quot;&gt;电磁辐射波&lt;/h1&gt;
&lt;h3 id=&quot;简介-2&quot;&gt;简介&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- 授课老师: José Penuelas(负责前几章教学), Bertrand Vilquin(负责后几章教学), 孙鸣捷老师(负责TD) 
- 授课形式：线上讲解原理，线下TD
- 授课材料：PPT，讲义，TD
- B站有录播
- 有笔记，侧边栏叫做电磁学(大四上)
- 考试闭卷，所以没有A4纸 ### 内容总览 首先回顾了之前学的波动物理和电磁学，电磁辐射，顾名思义是要将辐射，讲了波导，腔和光电效应，能级跃迁等等
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;传感器&quot;&gt;传感器&lt;/h1&gt;
&lt;h3 id=&quot;简介-3&quot;&gt;简介&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- 授课老师：徐平
- 授课形式：线下授课，做实验
- 授课材料：大学生MOOC
- 没有考试，没有笔记 ### 内容总览 讲解了传感器的基本原理，构造和常见传感器，每节课都需要在MOOC上做题，也有安排答辩，我和蔡卓江、宋正浩、刘亚林、马卫一一组讲解了机器狗。做实验是指去214玩小车，上面有不少传感器，也有大疆的线上模拟器，还是挺不错的一次动手实验。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Quehry</name></author><category term="school" /><summary type="html">概率统计 简介 授课老师：牛薇 授课材料：一份法语讲义，一份习题集（10个EX），上课用的PPT B站有录播，up主：却道成归 笔记记在侧边栏为大四上A的笔记本最前面</summary></entry><entry><title type="html">MCQ文献阅读</title><link href="http://localhost:4000/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html" rel="alternate" type="text/html" title="MCQ文献阅读" /><published>2021-11-25T00:00:00+08:00</published><updated>2021-11-25T00:00:00+08:00</updated><id>http://localhost:4000/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB</id><content type="html" xml:base="http://localhost:4000/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html">&lt;h2 id=&quot;整理集合&quot;&gt;整理集合&lt;/h2&gt;
&lt;p&gt;多选题自动生成：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;定义&lt;br /&gt;
输入一篇文章，从这篇文章生成一系列多选题&lt;/li&gt;
  &lt;li&gt;模型结构&lt;br /&gt;
待补充&lt;/li&gt;
  &lt;li&gt;工作流程&lt;br /&gt;
六大步：
    &lt;ul&gt;
      &lt;li&gt;输入文章预处理&lt;/li&gt;
      &lt;li&gt;选择句子&lt;/li&gt;
      &lt;li&gt;从句子中选择关键字&lt;/li&gt;
      &lt;li&gt;生成疑问句&lt;/li&gt;
      &lt;li&gt;生成误导选项&lt;/li&gt;
      &lt;li&gt;后期处理&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;主流的研究关注点与现存的问题
    &lt;ul&gt;
      &lt;li&gt;目前大多数处理文本都不考虑公式、图片和图标等等信息，文本预处理只提取文本信息，今后MCQG的研究需要关注处理嵌入在文本中的信息的能力。&lt;/li&gt;
      &lt;li&gt;现有的MCQ生成方法侧重于从单个句子生成问题，然而，文本可能通过多个句子来生成句子，所以今后的研究应该侧重于从多个句子中生成问题。&lt;/li&gt;
      &lt;li&gt;关键字的选择取决于下游任务或者应用领域，早期的关键字选择依赖于基本的统计和句法信息。最新的研究趋势是使用&lt;strong&gt;机器学习&lt;/strong&gt;或者&lt;strong&gt;语义信息&lt;/strong&gt;作为选择的标准。&lt;/li&gt;
      &lt;li&gt;误导选项的选择同样与应用领域有关，目前的MCQ生成系统中使用的都是简单的误导选项生成，但在实际情况中，误导选项可以是非常多种类的，可以是不同的命名体，数字大小，多个单词的误导选项等等。作者认为文本的深层语义分析或使用基于神经嵌入的方法可能是复杂误导答案生成的一个可能的方向。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;一篇关于mcqg的综述&quot;&gt;一篇关于MCQG的综述&lt;/h2&gt;
&lt;h3 id=&quot;title&quot;&gt;Title&lt;/h3&gt;
&lt;p&gt;Automatic Multiple Choice Question Generation From Text: A Survey&lt;/p&gt;
&lt;h3 id=&quot;author&quot;&gt;Author&lt;/h3&gt;
&lt;p&gt;Dhawaleswar Rao CH and Sujan Kumar Saha&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/Dhawaleswar.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/Sujan.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;abstract&quot;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;MCQ&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;工作20年前已经开始研究，综述将概括目前常见的多选题自动生成的&lt;strong&gt;工作流&lt;/strong&gt;和&lt;strong&gt;评估系统&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&quot;1introduction&quot;&gt;1.introduction&lt;/h3&gt;
&lt;p&gt;介绍了MCQ的重要性，是评估知识学习的工具之一，优点是耗时短但是人工出题需要很多时间，所以通过一段文章自动生成问题是人们关注的重点。&lt;/p&gt;
&lt;h3 id=&quot;2multiple-choice-question&quot;&gt;2.multiple choice question&lt;/h3&gt;
&lt;p&gt;介绍了MCQ和MCQ的基本结构，由题干，正确答案和误导答案组成，同时具体介绍了MCQ的优缺点。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;优点&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;缺点&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;快速评估，耗时短&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;涵盖的知识面很小&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;可以实现机器阅卷&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;答案有猜测出来的可能&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;3research-motivation-and-objectives&quot;&gt;3.research motivation and objectives&lt;/h3&gt;
&lt;p&gt;MCQ的研究动机主要来源于人工出题繁琐且耗时间。&lt;/p&gt;
&lt;h3 id=&quot;4review-methodology&quot;&gt;4.review methodology&lt;/h3&gt;
&lt;p&gt;作者从大量paper中挑选了86篇文章做来做MCQ的综述。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/article_collection.jpg&quot; alt=&quot;article_collection&quot; /&gt;&lt;/p&gt;

&lt;p&gt;介绍了一下检索文章的步骤&lt;br /&gt;
同时介绍了不同的QG的方法分布&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/分布图.jpg&quot; alt=&quot;distribution&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;5discussion-on-the-appproaches-for-mcq-generation&quot;&gt;5.discussion on the appproaches for MCQ generation&lt;/h3&gt;
&lt;p&gt;自动生成MCQ和手动生成MCQ的步骤大致相同：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pre-processing of Input Text 预处理输入文章&lt;/li&gt;
  &lt;li&gt;Sentence Selection 句子选择&lt;/li&gt;
  &lt;li&gt;Key Selection 选择答案信息&lt;/li&gt;
  &lt;li&gt;Question Formation 问题生成&lt;/li&gt;
  &lt;li&gt;Distractor Generation 错误答案生成&lt;/li&gt;
  &lt;li&gt;Post-Processing 后期处理&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/workflow.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面从这六个阶段分别分析：&lt;/p&gt;
&lt;h4 id=&quot;1pre-processing-of-input-text&quot;&gt;1.&lt;strong&gt;Pre-processing of Input Text&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;用到的技巧（每一个技巧都有对应的文献）：
    &lt;ul&gt;
      &lt;li&gt;text normalization: 将文本格式变成我们需要的格式，不同的应用领域需要不同的格式化方法&lt;/li&gt;
      &lt;li&gt;structure analysis：给出段落结构&lt;/li&gt;
      &lt;li&gt;sentence simplification：把长句子变成短句子&lt;/li&gt;
      &lt;li&gt;lexical analysis：词汇分析，把文本分隔成单词，符号和数字。同时需要进行词根提取&lt;/li&gt;
      &lt;li&gt;statistical analysis：统计分析，包括不同的统计手段，比如词频，n元词频等&lt;/li&gt;
      &lt;li&gt;syntactic analysis：语法分析，包括POS&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;，NER&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;，syntactic parsing&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;。&lt;/li&gt;
    &lt;/ul&gt;

    &lt;ul&gt;
      &lt;li&gt;coreference resolution: 代词通常不作为疑问句的主语，代词解析就是将代词映射到相应的名词。&lt;/li&gt;
      &lt;li&gt;word sense disambiguation：消除句子中单词的歧义&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;作者指出，对于text的预处理主要取决于输入文本的性质和下游任务的需求，比如说从web端爬下的文本会包含很多噪音和没必要的内容，那么文本清理就是必须的，再比如wikipedia文档作为输入时常常是一个长句子，需要把长句子简化变成短句子。&lt;br /&gt;
目前大多数处理文本都不考虑公式、图片和图标等等信息，文本预处理只提取文本信息，今后MCQG的研究需要关注处理嵌入在文本中的信息的能力。&lt;/p&gt;

&lt;h4 id=&quot;2sentence-selection&quot;&gt;2.&lt;strong&gt;sentence selection&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在对输入文本进行处理之后需要挑选出包含questionable fact的句子，我的理解是那些包含事实的句子。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;一些技巧：
    &lt;ul&gt;
      &lt;li&gt;sentence length：给出句子中单词的数量，一般来说，很短的句子不能包含足够的信息来生成问题，同样来说，很长的句子通常包含多个事实和关系，这会给生成问题带来困难。&lt;/li&gt;
      &lt;li&gt;occurrence of a particular word：查找特殊词汇&lt;/li&gt;
      &lt;li&gt;parts-of-speech information: 根据一个句子中出现词汇的词性挑选句子，比如说根据名词-形容词对的出来情况来选择句子。&lt;/li&gt;
      &lt;li&gt;parse information: 根据句子结构挑选，比如主谓宾&lt;/li&gt;
      &lt;li&gt;semantic information: 文本中包含的语义信息也作为选择句子的标准&lt;/li&gt;
      &lt;li&gt;machine learning: 使用机器学习算法，比如支持向量机、神经网络等&lt;/li&gt;
      &lt;li&gt;summarization：基于摘要的方法来选择句子&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;句子的选择同样需要根据任务的不同来选择。现有的MCQ生成方法侧重于从单个句子生成问题，然而，文本可能通过多个句子来生成句子，所以今后的研究应该侧重于&lt;strong&gt;从多个句子中生成问题&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&quot;3key-selection&quot;&gt;3.&lt;strong&gt;key Selection&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;选择好句子后，我们从中挑选出关键词。我们不能将一个句子的全部词汇都作为关键词，因此，关键字的选择是确定句子中要被删除的单词（或者短语、n元词元）&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一些技巧：
    &lt;ul&gt;
      &lt;li&gt;frequency count: 统计单词的出现频率作为选择标准&lt;/li&gt;
      &lt;li&gt;part-of-speech and parse information: 在某些特定的应用领域中，一个特定的词性或者语法可以成为一个潜在的关键字。比如一些研究用动词作为关键字，一些研究用介词作为关键字。&lt;/li&gt;
      &lt;li&gt;semantic information: 语义信息。&lt;/li&gt;
      &lt;li&gt;pattern matching：模式匹配，从结构相似的句子中提取出常见的句型，这样有助于句子解析结构来寻找关键字&lt;/li&gt;
      &lt;li&gt;machine learning：利用机器学习来生成动词或者部分习语或者副词来作为关键字。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;关键字的选择同样取决于下游任务或者应用领域，早期的关键字选择依赖于基本的统计和句法信息。最新的研究趋势是使用&lt;strong&gt;机器学习&lt;/strong&gt;或者&lt;strong&gt;语义信息&lt;/strong&gt;作为选择的标准。&lt;/p&gt;

&lt;h4 id=&quot;4question-formation&quot;&gt;4.&lt;strong&gt;question formation&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;选完关键字后，我们下一个任务就是把陈述句转化为疑问句。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一些技巧：
    &lt;ul&gt;
      &lt;li&gt;by appropriate wh-word selection: 根据句子的语法结构和关键字来确定使用哪个wh&lt;/li&gt;
      &lt;li&gt;subject-verb-object and their relationship：通过主谓宾结构来生成疑问句&lt;/li&gt;
      &lt;li&gt;knowledge in sentence：根据句子所包含的知识类型来确定转换规则，例如这个句子是概念，定义，示例等等。&lt;/li&gt;
      &lt;li&gt;dependency based patterns: 根据句子的依赖关系树来确定主要动词和将被问及的问题部分&lt;/li&gt;
      &lt;li&gt;syntactic transformation：通过句法结构来生成问题。&lt;/li&gt;
      &lt;li&gt;discourse connectives：通过不同的关系来转化，比如时间关系，空间关系。&lt;/li&gt;
      &lt;li&gt;semantic information based：基于语义来转化。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;question generation，问题生成也是一个热门的研究方向，该领域的目标是根据输入文本生成问题。在MCQ中，我们首先选取一个句子，然后选择关键字，最后根据关键字转换成问句形式。&lt;/p&gt;

&lt;h4 id=&quot;5distractor-generation&quot;&gt;5.&lt;strong&gt;distractor generation&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;错误选项在MCQ中扮演重要的地位，如果错误选项不能很好的迷惑学生，那么这道多选题出的并不好。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;一些技巧：
    &lt;ul&gt;
      &lt;li&gt;parts-of-speech information：错误选项和关键字在语义上很接近，所以他们的词性也要一样&lt;/li&gt;
      &lt;li&gt;frequency：频率也是一个重要的指标，关键字和错误选项的出现频率应该相近。&lt;/li&gt;
      &lt;li&gt;wordnet：wordnet是一个词汇数据库，它将单词分组为同义词集并记录这些词集成员的关系。因此可以用wordnet来生成错误选项。&lt;/li&gt;
      &lt;li&gt;domain ontology：一些文献用web ontology language来寻找错误答案。&lt;/li&gt;
      &lt;li&gt;distributional hypothesis: 分布假设认为相似的词出现在相似的语境中，那么我们可以基于分布相似度来寻找错误答案。&lt;/li&gt;
      &lt;li&gt;semantic analysis：基于语义。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;错误选项的选择同样与应用领域有关，目前的MCQ生成系统中使用的都是简单的错误选项生成，但在实际情况中，错误选项可以是非常多种类的，可以是不同的命名体，数字大小，多个单词的错误选项等等。作者认为文本的深层语义分析或使用基于神经嵌入的方法可能是复杂错误答案生成的一个可能的方向。&lt;/p&gt;

&lt;h4 id=&quot;6post-processing&quot;&gt;6.&lt;strong&gt;post-processing&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;后期处理是提高生成MCQ质量的阶段，系统生成的MCQ可能存在各种各样的错误。可能是标点符号错误，疑问词不恰当，问句过长等等，后期处理希望消除这些问题。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;一些技巧：
    &lt;ul&gt;
      &lt;li&gt;question post-editing：有些文献的方法是手动更改， 首先对于问题执行分类，是小问题就更正拼写和标点，如果是大问题就对题干进行重新措辞和替换等等。&lt;/li&gt;
      &lt;li&gt;question filtering：有些文献设计了一个过滤器来拒绝不对的问题，有的过滤器主要判断错误选项的质量，有的过滤器基于项目信息来过滤。&lt;/li&gt;
      &lt;li&gt;question ranking：对问题进行排名。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;6mcq-system-evalutaion&quot;&gt;6.MCQ system evalutaion&lt;/h3&gt;
&lt;p&gt;评估MCQ生成好坏，目前大多数系统采用
人工评估的办法。由于MCQ生成包含了很多步骤，那么就产生了不同的度量标准。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;evaluation of the stem and key&lt;/strong&gt;:
  目前还没有标准的公共数据集来评估MCQ，所以一般都是开发人员创建测试数据，下面有一张图展示了MCQ系统的评估过程，从表中可以看出，并没有一个标准的性能度量标准，开发人员采用了各种指标和参数。我们只能比较基于同一套评价体系下的MCQ。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/evaluation.jpg&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;evaluation of the distractors&lt;/strong&gt;：
  同样的，错误答案的评估也没有标准的数据集和评估指标。在许多应用领域中，MCQ有大量的干扰因素，所以一个标准的数据集可能无法容纳所有。所以目前还是有相关专家来评估。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;7conclusion&quot;&gt;7.conclusion&lt;/h3&gt;
&lt;p&gt;总结了工作流程中的六个阶段，总结了目前的挑战和今后的研究方向，以及评价标准未确立等等。MCQ领域还有很多地方值得深入研究。&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;multiple choice question，多选题。 &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;part of speech 词性分析 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;命名实体识别 &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;句子结构分析 &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Quehry</name></author><category term="paper" /><summary type="html">整理集合 多选题自动生成： 定义 输入一篇文章，从这篇文章生成一系列多选题 模型结构 待补充 工作流程 六大步： 输入文章预处理 选择句子 从句子中选择关键字 生成疑问句 生成误导选项 后期处理 主流的研究关注点与现存的问题 目前大多数处理文本都不考虑公式、图片和图标等等信息，文本预处理只提取文本信息，今后MCQG的研究需要关注处理嵌入在文本中的信息的能力。 现有的MCQ生成方法侧重于从单个句子生成问题，然而，文本可能通过多个句子来生成句子，所以今后的研究应该侧重于从多个句子中生成问题。 关键字的选择取决于下游任务或者应用领域，早期的关键字选择依赖于基本的统计和句法信息。最新的研究趋势是使用机器学习或者语义信息作为选择的标准。 误导选项的选择同样与应用领域有关，目前的MCQ生成系统中使用的都是简单的误导选项生成，但在实际情况中，误导选项可以是非常多种类的，可以是不同的命名体，数字大小，多个单词的误导选项等等。作者认为文本的深层语义分析或使用基于神经嵌入的方法可能是复杂误导答案生成的一个可能的方向。</summary></entry><entry><title type="html">练习Markdown</title><link href="http://localhost:4000/%E7%BB%83%E4%B9%A0Markdown.html" rel="alternate" type="text/html" title="练习Markdown" /><published>2021-11-24T00:00:00+08:00</published><updated>2021-11-24T00:00:00+08:00</updated><id>http://localhost:4000/%E7%BB%83%E4%B9%A0Markdown</id><content type="html" xml:base="http://localhost:4000/%E7%BB%83%E4%B9%A0Markdown.html">&lt;h1 id=&quot;1标题&quot;&gt;1.标题&lt;/h1&gt;
&lt;h1 id=&quot;一级标题&quot;&gt;一级标题&lt;/h1&gt;
&lt;h2 id=&quot;二级标题&quot;&gt;二级标题&lt;/h2&gt;
&lt;h3 id=&quot;三级标题&quot;&gt;三级标题&lt;/h3&gt;
&lt;p&gt;一共有6级标题&lt;/p&gt;

&lt;h1 id=&quot;2段落及格式&quot;&gt;2.段落及格式&lt;/h1&gt;
&lt;p&gt;用两个空格加回车表示换行&lt;br /&gt;
当然也可以直接空一行出来表示换行&lt;/p&gt;

&lt;h2 id=&quot;1各种文字表示&quot;&gt;1)各种文字表示&lt;/h2&gt;
&lt;h3 id=&quot;斜体&quot;&gt;斜体&lt;/h3&gt;
&lt;p&gt;用两个&lt;em&gt;或者两个_把需要斜体的文字围起来&lt;br /&gt;
比如：&lt;br /&gt;
*斜体&lt;/em&gt;&lt;br /&gt;
&lt;em&gt;斜体&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;粗体&quot;&gt;粗体&lt;/h3&gt;
&lt;p&gt;用两个&lt;strong&gt;或者两个__把需要粗体的文字围起来&lt;br /&gt;
比如:&lt;br /&gt;
**粗体&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;粗体&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;粗斜体&quot;&gt;粗斜体&lt;/h3&gt;
&lt;p&gt;用两个&lt;strong&gt;&lt;em&gt;或者两个___把需要粗体的文字围起来&lt;br /&gt;
比如:&lt;br /&gt;
**&lt;/em&gt;粗体&lt;/strong&gt;*&lt;br /&gt;
&lt;strong&gt;&lt;em&gt;粗体&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;2分隔线&quot;&gt;2)分隔线&lt;/h2&gt;
&lt;p&gt;你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线：&lt;br /&gt;
***&lt;/p&gt;
&lt;hr /&gt;
&lt;hr /&gt;
&lt;hr /&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;3删除线&quot;&gt;3)删除线&lt;/h2&gt;
&lt;p&gt;如果段落上的文字要添加删除线，只需要在文字的两端加上两个波浪线&lt;del&gt;即可
比如：&lt;br /&gt;
~~哈哈哈哈&lt;/del&gt;&lt;/p&gt;

&lt;h2 id=&quot;4下划线&quot;&gt;4)下划线&lt;/h2&gt;
&lt;p&gt;下划线可以通过HTML的&amp;lt;u&amp;gt;标签来实现
比如：&lt;br /&gt;
&lt;u&gt;下划线&lt;/u&gt;&lt;/p&gt;

&lt;h2 id=&quot;5脚注&quot;&gt;5)脚注&lt;/h2&gt;
&lt;p&gt;脚注是对文本的补充说明   &lt;br /&gt;
创建脚注格式类似这样 &lt;sup id=&quot;fnref:12&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;br /&gt;
脚注链接与脚注不能紧挨在一起。&lt;br /&gt;
注脚默认在最后&lt;/p&gt;

&lt;h1 id=&quot;3列表&quot;&gt;3.列表&lt;/h1&gt;

&lt;h2 id=&quot;1无序列表&quot;&gt;1)无序列表&lt;/h2&gt;
&lt;p&gt;无序列表使用星号(*)、加号(+)或是减号(-)作为列表标记，这些标记后面要添加一个空格，然后再填写内容。&lt;br /&gt;
比如：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;第一项&lt;/li&gt;
  &lt;li&gt;第二项&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;第三项&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;第一项&lt;/li&gt;
  &lt;li&gt;第二项&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;第三项&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;第一项&lt;/li&gt;
  &lt;li&gt;第二项&lt;/li&gt;
  &lt;li&gt;第三项&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2有序列表&quot;&gt;2)有序列表&lt;/h2&gt;
&lt;p&gt;有序列表使用数字并加上 . 号来表示，如：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;第一项&lt;/li&gt;
  &lt;li&gt;第二项&lt;/li&gt;
  &lt;li&gt;第三项&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;3列表嵌套&quot;&gt;3)列表嵌套&lt;/h2&gt;
&lt;p&gt;列表嵌套只需在子列表中的选项前面添加四个空格即可。比如：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;第一项：
    &lt;ul&gt;
      &lt;li&gt;第一项嵌套的第一个元素&lt;/li&gt;
      &lt;li&gt;第一项嵌套的第二个元素&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;第二项：
    &lt;ul&gt;
      &lt;li&gt;第二项嵌套的第一个元素&lt;/li&gt;
      &lt;li&gt;第二项嵌套的第二个元素&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;3区块&quot;&gt;3.区块&lt;/h1&gt;

&lt;h2 id=&quot;1区块引用&quot;&gt;1)区块引用&lt;/h2&gt;
&lt;p&gt;Markdown 区块引用是在段落开头使用 &amp;gt; 符号 ，然后后面紧跟一个空格符号：&lt;br /&gt;
比如：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;区块引用&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;2区块嵌套&quot;&gt;2)区块嵌套&lt;/h2&gt;
&lt;p&gt;另外区块是可以嵌套的，一个 &amp;gt; 符号是最外层，两个 &amp;gt; 符号是第一层嵌套，以此类推：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;最外层&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;第一层嵌套&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;3区块中使用列表&quot;&gt;3)区块中使用列表&lt;/h2&gt;
&lt;p&gt;比如：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;区块中使用列表&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;第一项&lt;/li&gt;
    &lt;li&gt;第二项
      &lt;ul&gt;
        &lt;li&gt;第一项&lt;/li&gt;
        &lt;li&gt;第二项&lt;/li&gt;
        &lt;li&gt;第三项&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;4列表中使用区块&quot;&gt;4)列表中使用区块&lt;/h2&gt;
&lt;p&gt;如果要在列表项目内放进区块，那么就需要在 &amp;gt; 前添加四个空格的缩进。&lt;br /&gt;
列表中使用区块实例如下：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;第一项
    &lt;blockquote&gt;
      &lt;p&gt;菜鸟教程
学的不仅是技术更是梦想&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;第二项&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;4使用代码&quot;&gt;4.使用代码&lt;/h1&gt;

&lt;h2 id=&quot;1代码&quot;&gt;1)代码&lt;/h2&gt;
&lt;p&gt;如果是段落上的一个函数或片段的代码可以用反引号把它包起来(`)，例如：&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;printf()&lt;/code&gt;函数&lt;/p&gt;

&lt;h2 id=&quot;2指定一种语言&quot;&gt;2)指定一种语言&lt;/h2&gt;
&lt;p&gt;可以用```包裹一段代码，并指定一种语言（也可以不指定）：&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;  
    &lt;span class=&quot;n&quot;&gt;qhr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qhr&lt;/span&gt;  
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;qhr&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;5使用链接&quot;&gt;5.使用链接&lt;/h1&gt;

&lt;h2 id=&quot;1链接使用方法&quot;&gt;1)链接使用方法&lt;/h2&gt;
&lt;p&gt;[链接名称](链接地址)或者&lt;链接地址&gt;&lt;/链接地址&gt;&lt;/p&gt;

&lt;p&gt;比如：&lt;/p&gt;

&lt;p&gt;这是一个链接 &lt;a href=&quot;https://www.runoob.com&quot;&gt;菜鸟教程&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;2直接使用链接地址&quot;&gt;2)直接使用链接地址&lt;/h2&gt;
&lt;p&gt;用&amp;lt;&amp;gt;把链接括起来。&lt;br /&gt;
比如:&lt;a href=&quot;http://www.runoob.com&quot;&gt;http://www.runoob.com&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;6图片&quot;&gt;6.图片&lt;/h1&gt;

&lt;h2 id=&quot;1使用图片&quot;&gt;1)使用图片&lt;/h2&gt;
&lt;p&gt;图片的语法格式：![alt 属性文本](图片地址 “可选标题”)&lt;/p&gt;

&lt;h2 id=&quot;2链接图片&quot;&gt;2)链接图片&lt;/h2&gt;
&lt;p&gt;大概长这样：&lt;br /&gt;
&amp;lt;img src=”http://static.runoob.com/images/runoob-logo.png” width=”50%”&amp;gt;
结果：&lt;br /&gt;
&lt;img src=&quot;http://static.runoob.com/images/runoob-logo.png&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;7表格&quot;&gt;7.表格&lt;/h1&gt;

&lt;h2 id=&quot;1格式&quot;&gt;1)格式&lt;/h2&gt;

&lt;p&gt;Markdown 制作表格使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行。&lt;br /&gt;
比如：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;表头&lt;/th&gt;
      &lt;th&gt;表头&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;单元格&lt;/td&gt;
      &lt;td&gt;单元格&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;单元格&lt;/td&gt;
      &lt;td&gt;单元格&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;2对齐方法&quot;&gt;2)对齐方法&lt;/h2&gt;
&lt;p&gt;在---前面加上:表示左对齐，在后面加上:表示右对齐，在两端加上:表示居中&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;左对齐&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;右对齐&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;居中对齐&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;单元格&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;单元格&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;单元格&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;单元格&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;单元格&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;单元格&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;8高级技巧&quot;&gt;8.高级技巧&lt;/h1&gt;

&lt;h2 id=&quot;1插入数学公式&quot;&gt;1)插入数学公式&lt;/h2&gt;
&lt;p&gt;当你需要在编辑器中插入数学公式时，可以使用两个美元符 $$ 包裹 TeX 或 LaTeX 格式的数学公式来实现。提交后，问答和文章页会根据需要加载 Mathjax 对数学公式进行渲染。比如：&lt;/p&gt;

&lt;p&gt;$$&lt;br /&gt;
\mathbf{V}_1 \times \mathbf{V}_2 =  \begin{vmatrix} 
\mathbf{i} &amp;amp; \mathbf{j} &amp;amp; \mathbf{k} &lt;br /&gt;
\frac{\partial X}{\partial u} &amp;amp;  \frac{\partial Y}{\partial u} &amp;amp; 0 &lt;br /&gt;
\frac{\partial X}{\partial v} &amp;amp;  \frac{\partial Y}{\partial v} &amp;amp; 0 &lt;br /&gt;
\end{vmatrix}
${$tep1}{\style{visibility:hidden}{(x+1)(x+1)}}&lt;br /&gt;
$$&lt;/p&gt;

&lt;p&gt;输出结果为：&lt;/p&gt;

\[\mathbf{V}_1 \times \mathbf{V}_2 =  \begin{vmatrix} 
\mathbf{i} &amp;amp; \mathbf{j} &amp;amp; \mathbf{k} \\
\frac{\partial X}{\partial u} &amp;amp;  \frac{\partial Y}{\partial u} &amp;amp; 0 \\
\frac{\partial X}{\partial v} &amp;amp;  \frac{\partial Y}{\partial v} &amp;amp; 0 \\
\end{vmatrix}
${$tep1}{\style{visibility:hidden}{(x+1)(x+1)}}\]

\[\sum_{i=0}N\int_{a}{b}g(t,i)\text{d}t\]

&lt;p&gt;&lt;strong&gt;还没有整明白，用到的时候在看&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;未完待续&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:12&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;我是脚注脚注脚注注脚 &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Quehry</name></author><category term="daily" /><summary type="html">1.标题 一级标题 二级标题 三级标题 一共有6级标题</summary></entry><entry><title type="html">空天报国,敢为人先</title><link href="http://localhost:4000/%E7%A9%BA%E5%A4%A9%E6%8A%A5%E5%9B%BD%E6%95%A2%E4%B8%BA%E4%BA%BA%E5%85%88.html" rel="alternate" type="text/html" title="空天报国,敢为人先" /><published>2021-11-18T00:00:00+08:00</published><updated>2021-11-18T00:00:00+08:00</updated><id>http://localhost:4000/%E7%A9%BA%E5%A4%A9%E6%8A%A5%E5%9B%BD%E6%95%A2%E4%B8%BA%E4%BA%BA%E5%85%88</id><content type="html" xml:base="http://localhost:4000/%E7%A9%BA%E5%A4%A9%E6%8A%A5%E5%9B%BD%E6%95%A2%E4%B8%BA%E4%BA%BA%E5%85%88.html">&lt;!-- 今天是71期党校的最后一节党课，今天很幸运，徐惠彬校长第一次讲党课。

以前我对于学校的归属感并不强，但现在我会比较自豪的说出我是北航人。空天报国，敢为人先是北航的口号，虽然我并不是学的航空航天专业，但是我认为这句口号是全北航人适用的。我希望能传承下这份精神与荣誉。前辈们为我们铺垫了很多，我们北航人自带红色基因，尽忠报国是我要向徐校长学习的，我对于国家和学校的归属感第一次这么强烈。

记于2021.11.19 1：16，最近各种事儿都忙起来了。 --&gt;</content><author><name>Quehry</name></author><category term="daily" /><summary type="html">&amp;lt;!– 今天是71期党校的最后一节党课，今天很幸运，徐惠彬校长第一次讲党课。</summary></entry><entry><title type="html">Who owns the copyright for an AI generated creative work?</title><link href="http://localhost:4000/AI-and-intellectual-property.html" rel="alternate" type="text/html" title="Who owns the copyright for an AI generated creative work?" /><published>2021-04-20T00:00:00+08:00</published><updated>2021-04-20T00:00:00+08:00</updated><id>http://localhost:4000/AI-and-intellectual-property</id><content type="html" xml:base="http://localhost:4000/AI-and-intellectual-property.html">&lt;p&gt;Recently I was &lt;a href=&quot;https://www.rollingstone.com/music/music-features/nirvana-kurt-cobain-ai-song-1146444/&quot;&gt;reading an article&lt;/a&gt; about a cool project that intends to have a neural network create songs of the late club of the 27 (artists that have tragically died at age 27 or near, and in the height of their respective careers), artists such as Amy Winehouse, Jimmy Hendrix, Curt Cobain and Jim Morrison.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/tjzOzuKQhSM&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;The project was created by &lt;a href=&quot;https://overthebridge.org&quot;&gt;Over the Bridge&lt;/a&gt;, an organization dedicated to increase awareness on mental health and substance abuse in the music industry, trying to denormalize and remove the glamour around such illnesses within the music community.&lt;/p&gt;

&lt;p&gt;They are using Google’s &lt;a href=&quot;https://magenta.tensorflow.org&quot;&gt;Magenta&lt;/a&gt;, which is a neural network that precisely was conceived to explore the role of machine learning within the creative process. Magenta has been used to create a brand new “Beatles” song or even there was a band that &lt;a href=&quot;https://arstechnica.com/gaming/2019/08/yachts-chain-tripping-is-a-new-landmark-for-ai-music-an-album-that-doesnt-suck/&quot;&gt;used it to write a full album&lt;/a&gt; in 2019.&lt;/p&gt;

&lt;p&gt;So, while reading the article, my immediate thought was: who owns the copyright of these new songs?&lt;/p&gt;

&lt;p&gt;Think about it, imagine one of this new songs becomes a massive hit with millions of youtube views and spotify streams, who can claim the royalties generated?&lt;/p&gt;

&lt;p&gt;At first it seems quite simple, &lt;em&gt;Over the Bridge&lt;/em&gt; should be the ones reaping the benefits, since they are the ones who had the idea, gathered the data and then fed the neural network to get the “work of art”. But in a second thought, didn’t the original artists provide the basis for the work the neural network generated? shouldn’t their state get credit? what about Google whose tool was used, should they get credit too?&lt;/p&gt;

&lt;p&gt;Neural networks have been also used to create poetry, paintings and to write news articles, but how do they do it? A computer program developed for machine learning purposes is an algorithm that “learns” from data to make future decisions. When applied to art, music and literary works, machine learning algorithms are actually learning from some input data to generate a new piece of work, making independent decisions throughout the process to determine what the new work looks like. An important feature of this is that while programmers can set the parameters, the work is actually generated by the neural network itself, in a process akin to the thought processes of humans.&lt;/p&gt;

&lt;p&gt;Now, creative works qualify for copyright protection if they are original, with most definitions of originality requiring a human author. Most jurisdictions, including &lt;a href=&quot;https://www.wipo.int/wipolex/en/details.jsp?id=1319&quot;&gt;Spain&lt;/a&gt; and &lt;a href=&quot;https://dejure.org/gesetze/UrhG/7.html&quot;&gt;Germany&lt;/a&gt;, specifically state that only works created by a human can be protected by &lt;a href=&quot;https://www.wipo.int/copyright/en/&quot;&gt;copyright&lt;/a&gt;. In the United States, for example, &lt;a href=&quot;https://copyright.gov/comp3/chap300/ch300-copyrightable-authorship.pdf&quot;&gt;the Copyright Office has declared&lt;/a&gt; that it will “register an original work of authorship, provided that the work was created by a human being.”&lt;/p&gt;

&lt;p&gt;So as we currently stand, a human author is required to grant a copyright, which makes sense, there is no point of having a neural network be the beneficiary of royalties of a creative work (no bank would open an account for them anyways, lol).&lt;/p&gt;

&lt;p&gt;I think amendments have to be made to the law to ensure that the person who undertook all the arrangements necessary for the work to be created by the neural network gets the credit but also we need to modify copyright law to ensure the original authors of the body of work used as data input to produce the new piece get their corresponding share of credit. This will get messy if someone uses for example the #1 song of every month in a decade to create the decade song, then there would be as many as 120 different artists to credit.&lt;/p&gt;

&lt;tweet&gt;In a computer generated artistic work, both the person who undertook all the arrangements necessary for its creation as well as the original authors of the data input need to be credited.&lt;/tweet&gt;

&lt;p&gt;There will still be some ambiguity as to who undertook the arrangements necessary, only the one who gathered the data and pressed the button to let the network learn, or does the person who created the neural network’s model also get credit? Shall we go all the way and say that even the programmer of the neural network gets some credit as well?&lt;/p&gt;

&lt;p&gt;There are some countries, in particular the UK where some progress has been made to amend copyright laws to cater for computer generated works of art, but I believe this is one of those fields where technology will surpass our law making capacity and we will live under a grey area for a while, and maybe this is just what we need, by having these works ending up free for use by anyone in the world, perhaps a new model for remunerating creative work can be established, one that does not require commercial success to be necessary for artists to make a living, and thus they can become free to explore their art.&lt;/p&gt;

&lt;tweet&gt;Perhaps a new model for remunerating creative work can be established, one that does not require commercial success to be necessary for artists to make a living.&lt;/tweet&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20210420/post8-rembrandt2.jpg&quot; alt=&quot;The next Rembrandt&quot; /&gt;
&lt;small&gt;&lt;a href=&quot;https://www.jwt.com/en/work/thenextrembrandt&quot;&gt;The Next Rembrandt&lt;/a&gt; is a computer-generated 3-D–printed painting developed by a facial-recognition algorithm that scanned data from 346 known paintings by the Dutch painter in a process lasting 18 months. The portrait is based on 168,263 fragments from Rembrandt’s works.&lt;/small&gt;&lt;/p&gt;</content><author><name>Armando Maynez</name></author><category term="opinion" /><category term="copyright" /><category term="creativity" /><category term="neural networks" /><category term="machine learning" /><category term="artificial intelligence" /><summary type="html">Recently I was reading an article about a cool project that intends to have a neural network create songs of the late club of the 27 (artists that have tragically died at age 27 or near, and in the height of their respective careers), artists such as Amy Winehouse, Jimmy Hendrix, Curt Cobain and Jim Morrison.</summary></entry><entry><title type="html">So, what is a neural network?</title><link href="http://localhost:4000/back-to-basics.html" rel="alternate" type="text/html" title="So, what is a neural network?" /><published>2021-04-02T00:00:00+08:00</published><updated>2021-04-02T00:00:00+08:00</updated><id>http://localhost:4000/back-to-basics</id><content type="html" xml:base="http://localhost:4000/back-to-basics.html">&lt;p&gt;The omnipresence of technology nowadays has made it commonplace to read news about AI, just a quick glance at today’s headlines, and I get:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.morningbrew.com/emerging-tech/stories/2021/03/29/one-biggest-advancements-ai-also-sparked-fierce-debate-heres?utm_source=morning_brew&quot;&gt;This Powerful AI Technique Led to Clashes at Google and Fierce Debate in Tech.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://fortune.com/2021/04/02/ai-forecasting-supply-chain-factories-caterpillar-agco/&quot;&gt;How A.I.-powered companies dodged the worst damage from COVID&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.mobihealthnews.com/news/emea/ai-technology-detects-ticking-time-bomb-arteries&quot;&gt;AI technology detects ‘ticking time bomb’ arteries&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.genengnews.com/insights/ai-in-drug-discovery-starts-to-live-up-to-the-hype/&quot;&gt;AI in Drug Discovery Starts to Live Up to the Hype&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.c4isrnet.com/artificial-intelligence/2021/04/02/pentagon-seeks-commercial-solutions-to-get-its-data-ready-for-ai/&quot;&gt;Pentagon seeks commercial solutions to get its data ready for AI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Topics from business, manufacturing, supply chain, medicine and biotech and even defense are covered in those news headlines, definitively the advancements on the fields of artificial intelligence, in particular machine learning and deep neural networks have permeated into our daily lives and are here to stay. But, do the general population know what are we talking about when we say “an AI”?  I assume most people correctly imagine a computer algorithm or perhaps the more adventurous minds think of a physical machine, an advanced computer entity or even a robot, getting smarter by itself with every use-case we throw at it. And most people will be right, when “an AI” is mentioned it is indeed an algorithm run by a computer, and there is where the boundary of their knowledge lies.&lt;/p&gt;

&lt;p&gt;They say that the best way to learn something is to try to explain it, so in a personal exercise I will try to do an ELI5 (&lt;strong&gt;E&lt;/strong&gt;xplain it &lt;strong&gt;L&lt;/strong&gt;ike &lt;strong&gt;I&lt;/strong&gt; am &lt;strong&gt;5&lt;/strong&gt;) version of what is a neural network.&lt;/p&gt;

&lt;p&gt;Let’s start with a little history, humans have been tinkering with the idea of an intelligent machine for a while now, some even say that the idea of artificial intelligence was conceived by the ancient greeks (&lt;a href=&quot;https://www.thinkautomation.com/bots-and-ai/a-history-of-automation-the-rise-of-robots-and-ai/&quot;&gt;source&lt;/a&gt;), and several attempts at devising “intelligent” machines have been made through history, a notable one was ‘The Analytical Engine’ created by Charles Babbage in 1837:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20210402/post7-analytical-engine.jpg&quot; alt=&quot;The Analytical Engine&quot; /&gt;
&lt;small&gt;The Analytical Engine of Charles Babbage - 1837&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Then, in the middle of last century by trying to create a model of how our brain works, Neural Networks were born. Around that time, Frank Rosenblatt at Cornell trying to understand the simple decision system present in the eye of a common housefly,  proposed the idea of a &lt;a href=&quot;./single-neuron-perceptron.html&quot;&gt;perceptron&lt;/a&gt;, a very simple system that processes certain inputs with basic math operations and produces an output.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20210125/Perceptron.png&quot; alt=&quot;A perceptron&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To illustrate, let’s say that the brain of the housefly is a perceptron, its inputs are whatever values are produced by the multiple cells in its eyes, when the eye cell detects “something” it’s output will be a 1, and if there is nothing a 0. Then the combination of all those inputs can be processed by the perceptron (the fly brain), and the output is a simple 0 or 1 value. If it is a 1 then the brain is telling the fly to flee and if it is a 0 it means it is safe to stay where it is.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20210402/post7-housefly-eye.jpg&quot; alt=&quot;A housefly eye&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can imagine then that if many of the eye cells of the fly produce 1s, it means that an object is quite near, and therefore the perceptron will calculate a 1, it is time to flee.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20210402/post7-fly-vision.jpg&quot; alt=&quot;The fly vision&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The perceptron is just a math operation, one that multiplies certain input values with preset “parameters” (called weights) and adds up the resulting multiplications to generate a value.&lt;/p&gt;

&lt;p&gt;Then the magic spark was ignited, the parameters (weights) of the perceptron could be “learnt” by a process of minimizing the difference between known results of particular observations, and what the perceptron is actually calculating. It is this process of learning what we call &lt;strong&gt;training the neural network&lt;/strong&gt;.&lt;/p&gt;

&lt;tweet&gt;This idea is so powerful that even today it is one of the fundamental building blocks of what we call AI.&lt;/tweet&gt;

&lt;p&gt;From this I will try to explain how this simple concept can have such diverse applications as natural language processing (think Alexa), image recognition like medical diagnosis from a CTR scan, autonomous vehicles, etc.&lt;/p&gt;

&lt;p&gt;A basic neural network is a combination of perceptrons in different arrangements, the perceptron therefore was downgraded from “fly brain” to “network neuron”.
&lt;img src=&quot;./assets/img/posts/20210402/post7-multilayer-perceptron.png&quot; alt=&quot;A multilayer perceptron&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A neural network has different components, in its basic form it has:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Input&lt;/li&gt;
  &lt;li&gt;Hidden layers&lt;/li&gt;
  &lt;li&gt;Output&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20210228/nnet_flow.gif&quot; alt=&quot;Neural network components&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;input&quot;&gt;Input&lt;/h3&gt;

&lt;p&gt;The inputs of a neural network are in their essence just numbers, therefore anything that can be converted to a number can become an input. Letters in a text, pixels in an image, frequencies in a sound wave, values from a sensor, etc. are all different things that when converted to a numerical value serve as inputs for the neural network. This is one of the reasons why applications of neural networks are so diverse.&lt;/p&gt;

&lt;p&gt;Inputs can be as many as one need for the task at hand, from maybe 9 inputs to teach a neural network how to play tic-tac-toe to thousands of pixels from a camera for an autonomous vehicle. Since the input of a perceptron needs to be a single value, if for example a color pixel is chosen as input, it most likely will be broken into three different values; its  red, green and blue components, hence each pixel will become 3 different inputs for the neural network.&lt;/p&gt;

&lt;h3 id=&quot;hidden-layers&quot;&gt;Hidden layers&lt;/h3&gt;

&lt;p&gt;A “layer” within a neural network is just a group of perceptrons that all perform the same exact mathematical operation to the inputs and produce an output. The catch is that each of them have different weights (parameters), therefore their output for a given input will be different amongst them. There are many types of layers, the most typical of them being a “dense” layer, which is another word to say that all the inputs are connected to all the neurons (individual perceptrons), and as said before, each of these connections have a weight associated with it, so that the operation that each neuron performs is a simple weighted sum of all the inputs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20210402/post7-dense-layers.png&quot; alt=&quot;post7-dense-layers&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The hidden layer is then typically connected to another dense layer, and their connection means that each output of a neuron from the first layer is treated effectively as an input for the subsequent one, and it is thus connected to every neuron.&lt;/p&gt;

&lt;p&gt;A neural network can have from one to as many layers as one can think, and the number of layers depends solely on the experience we have gathered on the particular problem we would like to solve.&lt;/p&gt;

&lt;p&gt;Another critical parameter of a hidden layer is the number of neurons it has, and again, we need to rely on experience to determine how many neurons are needed for a given problem. I have seen networks that vary from a couple of neurons to the thousands. And of course each hidden layer can have as many neurons as we please, so the number of combinations is vast.&lt;/p&gt;

&lt;p&gt;To the number of layers, their type and how many neurons each have, is what we call the &lt;em&gt;network topology&lt;/em&gt; (including the number of inputs and outputs).&lt;/p&gt;

&lt;h3 id=&quot;output&quot;&gt;Output&lt;/h3&gt;

&lt;p&gt;At the very end of the chain, another layer lies (which behaves just like a hidden layer), but has the peculiarity that it is the final layer, and therefore whatever it calculates will be the output values of the whole network. The number of outputs the network has is a function of the problem we would like to solve. It could be as simple as one output, with its value representing a probability of an action (like in the case of the flee reaction of the housefly), to many outputs, perhaps if our network is trying to distinguish images of animals, one would have an output for each animal species, and the output would represent how much confidence the network has that the particular image belongs to the corresponding species.&lt;/p&gt;

&lt;p&gt;As we said, the neural network is just a collection of individual neurons, doing basic math operations on certain inputs in series of layers that eventually generate an output. This mesh of neurons is then “trained” on certain output values from known cases of the inputs; once it has learned it can then process new inputs, values that it has never seen before with surprisingly accurate results.&lt;/p&gt;

&lt;p&gt;Many of the problems neural networks solve, could be certainly worked out by other algorithms, however, since neural networks are in their core very basic operations, once trained, they are extremely efficient, hence much quicker and economical to produce results.&lt;/p&gt;

&lt;p&gt;There are a few more details on how a simple neural network operate that I purposedly left out to make this explanation as simple as possible. Thinks like biases, the activation functions and the math behind learning, the backpropagation algorithm, I will leave to a more in depth article. I will also write (perhaps in a series) about the more complex topologies combining different types of layers and other building blocks, a part from the perceptron.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20210402/post7-alexa.png&quot; alt=&quot;Alexa recognizing speach&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Things like “Alexa”, are a bit more complex, but work on exactly the same principles. Let’s break down for example the case of asking “Alexa” to play a song in spotify. Alexa uses several different neural networks to acomplish this:&lt;/p&gt;

&lt;h4 id=&quot;1-speech-recognition&quot;&gt;1. Speech recognition&lt;/h4&gt;

&lt;p&gt;As a basic input we have our speech: the command &lt;strong&gt;“Alexa, play Van Halen”&lt;/strong&gt;. This might seem quite simple for us humans to process, but for a machine is an incredible difficult feat to be able to understand speech, things like each individual voice timbre, entonation, intention and many more nuances of human spoken language make it so that traditional algorithms have struggled a lot with this. In our simplified example let’s say that we use a neural network to transform our spoken speech into text characters a computer is much more familiarized to learn.&lt;/p&gt;

&lt;h4 id=&quot;2-understanding-what-we-mean-natural-language-understanding&quot;&gt;2. Understanding what we mean (Natural Language Understanding)&lt;/h4&gt;

&lt;p&gt;Once the previous network managed to succesfuly convert our spoken words into text, there comes the even more difficult task of making sense of what we said. Things that we humans take for granted such as context, intonation and non verbal communication, help give our words meaning in a very subtle, but powerful way, a machine will have to do with much less information to correctly understand what we mean. It has to correctly identify the intention of our sentence and the subject or entities of what we mean.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20210402/post7-alexa-natural-lang.png&quot; alt=&quot;post7-alexa-natural-lang&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The neural network has to identify that it received a command (by identifying its name), the command (“play music”), and our choice (“Van Halen”). And it does so by means of simple math operations as described before. Of course the network involved is quite complex and has different types of neurons and connection types, but the underlying principles remain.&lt;/p&gt;

&lt;h4 id=&quot;3-replying-to-us&quot;&gt;3. Replying to us&lt;/h4&gt;

&lt;p&gt;Once Alexa understood what we meant, it then proceeds to execute the action of the command it interpreted and it replies to us in turn using natural language. This is accomplished using a technique called speech synthesis, things like pitch, duration and intensity of the words and phonems are selected based on the “meaning” of what Alexa will respond to us: “Playing songs by Van Halen on Spotify” sounding quite naturally. And all is accomplished with neural networks executing many simple math operations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20210402/post7-alexa-steps.png&quot; alt=&quot;post7-alexa-steps&quot; /&gt;
&lt;small&gt;Although it seems quite complex, the process for AI to understand us can be boiled down to simple math operations&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Of course Amazon’s Alexa neural networks have undergone quite a lot of training to get to the level where they are, the beauty is that once trained, to perform their magic they just need a few mathematical operations.&lt;/p&gt;

&lt;p&gt;As said before, I will continue to write about the basics of neural networks, the next article in the series will dive a bit deeper into the math behind a basic neural network.&lt;/p&gt;</content><author><name>Armando Maynez</name></author><category term="theory" /><category term="neural networks" /><category term="machine learning" /><category term="artificial intelligence" /><summary type="html">The omnipresence of technology nowadays has made it commonplace to read news about AI, just a quick glance at today’s headlines, and I get: This Powerful AI Technique Led to Clashes at Google and Fierce Debate in Tech. How A.I.-powered companies dodged the worst damage from COVID AI technology detects ‘ticking time bomb’ arteries AI in Drug Discovery Starts to Live Up to the Hype Pentagon seeks commercial solutions to get its data ready for AI</summary></entry></feed>