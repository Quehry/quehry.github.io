<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-10-18T00:12:47+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Quehry</title><subtitle>Artificial Intelligence trends and concepts made easy.</subtitle><author><name>Quehry</name></author><entry><title type="html">Latent Diffusion Model</title><link href="http://localhost:4000/Latent-Diffusion-Model.html" rel="alternate" type="text/html" title="Latent Diffusion Model" /><published>2022-10-16T00:00:00+08:00</published><updated>2022-10-16T00:00:00+08:00</updated><id>http://localhost:4000/Latent-Diffusion-Model</id><content type="html" xml:base="http://localhost:4000/Latent-Diffusion-Model.html"><![CDATA[<!-- TOC -->

<ul>
  <li><a href="#1-ldm简介">1. LDM简介</a></li>
  <li><a href="#2-模型">2. 模型</a></li>
</ul>

<!-- /TOC -->

<h1 id="1-ldm简介">1. LDM简介</h1>
<p>Latent Diffusion Model(LDM)是Diffusion Model的改进版本。扩散模型相比于之前的生成模型而言，已经能取得非常好的效果，但是扩散模型有个特点，贵。不仅训练贵，而且推理也很贵。为了节省空间和资源，LDM将反向扩散过程在隐空间中进行，而不是之前的逐像素进行反向扩散(因为隐空间的维度比原始图片要小，能让训练和推断变得不那么贵)。LDM与扩散模型最大的区别就是隐空间，模型在github上开源，stable diffusion也是基于latent diffusion进行实现</p>
<ul>
  <li><a href="https://arxiv.org/abs/2112.10752" target="_blank">LDM</a></li>
  <li><a href="https://github.com/CompVis/latent-diffusion" target="_blank">github</a></li>
</ul>

<h1 id="2-模型">2. 模型</h1>
<p>LDM的模型如下图所示:</p>

<center><img src="../assets/img/posts/20221016/2.jpg" /></center>

<ul>
  <li>前向扩散: 输入x首先经过压缩后得到隐空间表达z，正常的前向扩散得到$z_T$</li>
  <li>反向扩散: 隐空间的随机噪声$z_T$经过T步去噪U-Net后得到z，然后z经过解压得到原始大小的图片$\tilde{x}$</li>
</ul>

<p>我们关心的是模型反向扩散的过程，关于图片压缩和解压的模型，作者尝试了VAE和VQVAE，返现VAE的表现稍微好一点，所以选择了VAE作为antoencoder。与一般的扩散模型一样，LDM也可以做条件生成，LDM采取的策略是classifier-free guidance，具体实现方法是将预处理好的y与U-Net的每一个中间表达都应用注意力机制，其中查询是U-Net的中间层表达，key和value是预处理好的y。预处理的encoder与y相关，如果y是文本，那么encoder可以是clip的text encoder，也可以是transformer-based encoder</p>

<center><img src="../assets/img/posts/20221016/3.jpg" /></center>]]></content><author><name>Quehry</name></author><category term="notes" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">扩散模型</title><link href="http://localhost:4000/Diffusion-Model.html" rel="alternate" type="text/html" title="扩散模型" /><published>2022-10-12T00:00:00+08:00</published><updated>2022-10-12T00:00:00+08:00</updated><id>http://localhost:4000/Diffusion-Model</id><content type="html" xml:base="http://localhost:4000/Diffusion-Model.html"><![CDATA[<!-- TOC -->

<ul>
  <li><a href="#1-扩散模型简介">1. 扩散模型简介</a></li>
  <li><a href="#2-模型">2. 模型</a>
    <ul>
      <li><a href="#21-前向扩散">2.1. 前向扩散</a></li>
      <li><a href="#22-反向扩散过程">2.2. 反向扩散过程</a></li>
      <li><a href="#23-损失函数">2.3. 损失函数</a></li>
      <li><a href="#24-ddpm中给出的训练与采样生成过程">2.4. DDPM中给出的训练与采样(生成)过程</a></li>
      <li><a href="#25-小结">2.5. 小结</a></li>
    </ul>
  </li>
  <li><a href="#3-一些技巧和主要网络结构">3. 一些技巧和主要网络结构</a>
    <ul>
      <li><a href="#31-\beta_t和\sigma_\theta的取值">3.1. $\beta_t$和$\Sigma_\theta$的取值</a></li>
      <li><a href="#32-加速扩散模型采样的技巧">3.2. 加速扩散模型采样的技巧</a></li>
      <li><a href="#33-u-net">3.3. U-Net</a></li>
    </ul>
  </li>
  <li><a href="#4-条件生成">4. 条件生成</a>
    <ul>
      <li><a href="#41-classifier-guided-diffusion">4.1. Classifier Guided Diffusion</a></li>
      <li><a href="#42-classifier-free-guidance">4.2. Classifier-Free Guidance</a></li>
      <li><a href="#43-scale-up-generation-resolution-and-quality">4.3. Scale up Generation Resolution and Quality</a></li>
    </ul>
  </li>
</ul>

<!-- /TOC -->

<h1 id="1-扩散模型简介">1. 扩散模型简介</h1>
<p>扩散模型(Diffusion Model)是深度生成模型中的SOTA，相比于GAN、VAE、Flow-based这些生成模型而言，扩散模型可以取得更好的效果。扩散模型受非平衡热力学启发，它定义了一条多时间步的马尔可夫链来逐步给图片添加噪声，如果时间步够大，最终图片会变成纯噪声，扩散模型的目的是学习反向的扩散过程，也就是输入随机噪声，能返回一张图片，相比于之前提到的各种生成模型而言，扩散模型具有相对固定的学习步骤，同时隐变量维度更高(和输入数据同样的维度)</p>

<center><img src="../assets/img/posts/20221012/2.jpg" /></center>

<p>扩散模型的早在2015年便提出了(<a href="https://arxiv.org/abs/1503.03585" target="_blank">论文链接</a>)，但在当时没有引起广泛的关注，直到2019年<a href="https://arxiv.org/abs/1907.05600" target="_blank">NCSN</a>和2020年<a href="https://arxiv.org/abs/2006.11239" target="_blank">DDPM</a>的出现才将扩散模型引入了新高度，2022年火爆的text2image模型GLIDE、DALLE2、Latent Diffusion、Imagen的相继提出，让扩散模型火出了圈，这篇博客将对扩散模型的前向计算、反向训练、训练、生成步骤及其数学原理做详细的整理，会列出很多数学公式，同时该博客也参考了很多相关资料，这里我一并列出</p>

<ul>
  <li><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/" target="_blank">Lil blog, 一篇整理相当详尽的博客，也是我主要的参考对象</a></li>
  <li><a href="https://huggingface.co/blog/annotated-diffusion" target="_blank">huggingface的一篇解释简单明了的博客</a></li>
  <li><a href="https://zhuanlan.zhihu.com/p/525106459" target="_blank">知乎上一篇中文博客</a></li>
  <li><a href="https://arxiv.org/abs/2006.11239" target="_blank">DDPM</a></li>
  <li><a href="https://arxiv.org/abs/2209.00796" target="_blank">一篇综述</a></li>
  <li><a href="https://arxiv.org/abs/2102.09672" target="_blank">Improved DDPM</a></li>
  <li><a href="https://arxiv.org/abs/2105.05233" target="_blank">Diffusion Models Beat GANs</a></li>
  <li><a href="https://arxiv.org/abs/2112.10741" target="_blank">GLIDE</a></li>
  <li><a href="https://arxiv.org/abs/2106.15282" target="_blank">Cascaded Diffusion Model</a></li>
</ul>

<h1 id="2-模型">2. 模型</h1>
<h2 id="21-前向扩散">2.1. 前向扩散</h2>
<p>从原始数据分布中采样$x_0$, 假设$x_0\sim q(x)$，前向扩散过程就是在每一个时间步都加上一个高斯噪声，这样就可以从最初的$x_0$生成长度为T的噪声序列$x_1, x_2, x_3,…, x_T$，每一步都用variance schedule$\beta_t$控制，其中$\beta_t\in (0, 1)$，每一步的后验分布(预定义好的)为:</p>

<p>
\begin{equation}
q(\mathbf{x}_t \vert \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t\mathbf{I}) \quad
q(\mathbf{x}_{1:T} \vert \mathbf{x}_0) = \prod^T_{t=1} q(\mathbf{x}_t \vert \mathbf{x}_{t-1})
\end{equation}
</p>

<p>这个前向传播的过程中有一个非常好的性质，就是我们可以在任意时间步采样得到$x_t$，为了实现这个技巧，我们需要用到reparameterization技巧(该技巧也在VAE中出现过)，重参数化技巧的本质就是将随机采样的z通过引入高斯噪声$\epsilon$变成确定性的z，也就是上面的$x_t$可以表示为$x_t=\sqrt{1-\beta_t}x_{t-1}+\sqrt{\beta_t}\epsilon$，这样有利于梯度的逆传播，那么我们可以推出以下公式:</p>

<p>
\begin{equation}
\begin{aligned}
\mathbf{x}_t 
&amp;= \sqrt{\alpha_t}\mathbf{x}_{t-1} + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon}_{t-1} \\
&amp;= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}} \bar{\boldsymbol{\epsilon}}_{t-2} \\
&amp;= \dots \\
&amp;= \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon} \\
q(\mathbf{x}_t \vert \mathbf{x}_0) &amp;= \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t)\mathbf{I})
\end{aligned}
\end{equation}
</p>

<p>其中$\epsilon_t$都是均值为0，方差为1的高斯噪声，$\alpha_t=1-\beta_t$, $\bar{\alpha_t}=\prod_{i=1}^t\alpha_i$, 注:两个均值相同高斯噪声可以合并成一个高斯噪声，方差为之前方差的平方和开根号，一般来说，$\beta_1&lt;\beta_2&lt;…&lt;\beta_T$</p>

<h2 id="22-反向扩散过程">2.2. 反向扩散过程</h2>

<center><img src="../assets/img/posts/20221012/3.jpg" /></center>

<p>如果我们可以将前向传播的过程反向，那么我们就可以获得后验分布$q(x_{t-1}|x_{t})$，那么我们就可以利用马尔科夫链的性质，输入高斯噪声，然后获得生成的照片，但是，我们无法高效地得到$q(x_{t-1}|x_{t})$，于是我们希望学习出分布$p_\theta$来模拟后验分布$q(x_{t-1}|x_{t})$，由于前向扩散的过程中我们假设后验分布是高斯分布，所以这里我们也假设$p_\theta$是高斯分布，于是我们有:</p>

<p>
\begin{equation}
p_\theta(\mathbf{x}_{0:T}) = p(\mathbf{x}_T) \prod^T_{t=1} p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) \quad
p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t))
\end{equation}
</p>

<p>其中分布$p_\theta$中的均值$\mu$和方差$\Sigma$与时间步t和输入$x_t$有关</p>

<p>虽然我们不知道$q(x_{t-1}|x_t)$的分布情况，但是我们可以知道$q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)$的分布情况，推导过程如下:</p>

<p style="font-size: 14px">
\begin{equation}
\begin{aligned}
q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right) &amp;=q\left(\mathbf{x}_t \mid \mathbf{x}_{t-1}, \mathbf{x}_0\right) \frac{q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_0\right)}{q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)} \\
&amp; \propto \exp \left(-\frac{1}{2}\left(\frac{\left(\mathbf{x}_t-\sqrt{\alpha_t} \mathbf{x}_{t-1}\right)^2}{\beta_t}+\frac{\left(\mathbf{x}_{t-1}-\sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0\right)^2}{1-\bar{\alpha}_{t-1}}-\frac{\left(\mathbf{x}_t-\sqrt{\bar{\alpha}_t} \mathbf{x}_0\right)^2}{1-\bar{\alpha}_t}\right)\right) \\
&amp;=\exp \left(-\frac{1}{2}\left(\frac{\mathbf{x}_t^2-2 \sqrt{\alpha_t} \mathbf{x}_t \mathbf{x}_{t-1}+\alpha_t \mathbf{x}_{t-1}^2}{\beta_t}+\frac{\mathbf{x}_{t-1}^2-2 \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0 \mathbf{x}_{t-1}+\bar{\alpha}_{t-1} \mathbf{x}_0^2}{1-\bar{\alpha}_{t-1}}-\frac{\left(\mathbf{x}_t-\sqrt{\bar{\alpha}_t} \mathbf{x}_0\right)^2}{1-\bar{\alpha}_t}\right)\right) \\
&amp;=\exp \left(-\frac{1}{2}\left(\left(\frac{\alpha_t}{\beta_t}+\frac{1}{1-\bar{\alpha}_{t-1}}\right) \mathbf{x}_{t-1}^2-\left(\frac{2 \sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t+\frac{2 \sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_0\right) \mathbf{x}_{t-1}+C\left(\mathbf{x}_t, \mathbf{x}_0\right)\right)\right)
\end{aligned}
\end{equation}
</p>

<p>其中函数$C(x_t, x_0)$与$x_{t-1}$无关，根据上述式子我们可以得出$q(x_{t-1}|x_t,x_0)$满足正态分布，均值和标准差分别为$\tilde{\mu_t}$和$\tilde{\beta_t}$，表达式分别为:</p>

<p>
\begin{equation}
\begin{aligned}
\tilde{\beta}_t 
&amp;= 1/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) 
= 1/(\frac{\alpha_t - \bar{\alpha}_t + \beta_t}{\beta_t(1 - \bar{\alpha}_{t-1})})
= \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t \\
\tilde{\boldsymbol{\mu}}_t (\mathbf{x}_t, \mathbf{x}_0)
&amp;= (\frac{\sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1} }}{1 - \bar{\alpha}_{t-1}} \mathbf{x}_0)/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) \\
&amp;= (\frac{\sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1} }}{1 - \bar{\alpha}_{t-1}} \mathbf{x}_0) \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t \\
&amp;= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \mathbf{x}_0\\
\end{aligned}
\end{equation}
</p>

<p>于是最终可以得到$q(x_{t-1}|x_t,x_0)$:</p>

<p>
\begin{equation}
q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1}; \tilde{\boldsymbol{\mu}}(\mathbf{x}_t, \mathbf{x}_0), \tilde{\beta}_t \mathbf{I})
\end{equation}
</p>

<p>在根据马尔可夫链我们有: $\mathbf{x}_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t)$，注意这里的$\epsilon_t$并不是任意的一个噪声，而是让$x_0$变成$x_t$的噪声，那么$\tilde{\mu_t}$可以表示为:</p>

<p>
\begin{equation}
\begin{aligned}
\tilde{\boldsymbol{\mu}}_t
&amp;= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t) \\
&amp;= \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_t \Big)
\end{aligned}
\end{equation}
</p>

<h2 id="23-损失函数">2.3. 损失函数</h2>
<p>和VAE类似，也可以用Variational Lower Bound来最大边缘似然函数$p_\theta(x_0)$:</p>

<p>
\begin{equation}
\begin{aligned}
- \log p_\theta(\mathbf{x}_0) 
&amp;\leq - \log p_\theta(\mathbf{x}_0) + D_\text{KL}(q(\mathbf{x}_{1:T}\vert\mathbf{x}_0) \| p_\theta(\mathbf{x}_{1:T}\vert\mathbf{x}_0) ) \\
&amp;= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_{\mathbf{x}_{1:T}\sim q(\mathbf{x}_{1:T} \vert \mathbf{x}_0)} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T}) / p_\theta(\mathbf{x}_0)} \Big] \\
&amp;= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_q \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} + \log p_\theta(\mathbf{x}_0) \Big] \\
&amp;= \mathbb{E}_q \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\
\text{Let }L_\text{VLB} 
&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \geq - \mathbb{E}_{q(\mathbf{x}_0)} \log p_\theta(\mathbf{x}_0)
\end{aligned}
\end{equation}
</p>

<p>由于这里取了-log，所以目标变成了最小化VLB损失函数，经过一系列漫长的推导，我们可以得到(中间步骤其后就是用马尔科夫链和贝叶斯定理把条件概率拆开):</p>

<p>
\begin{equation}
\begin{aligned}
L_\text{VLB} &amp;= L_T + L_{T-1} + \dots + L_0 \\
\text{where } L_T &amp;= D_\text{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T)) \\
L_t &amp;= D_\text{KL}(q(\mathbf{x}_t \vert \mathbf{x}_{t+1}, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_t \vert\mathbf{x}_{t+1})) \text{ for }1 \leq t \leq T-1 \\
L_0 &amp;= - \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)
\end{aligned}
\end{equation}
</p>

<p>参数化损失函数中的$L_t$: 反向扩散的目标是用神经网络来拟合后验分布$p_\theta(x_{t-1} \vert x_t) = N(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$，根据损失函数$L_t$可知，反向扩散训练的目标是: 给定t和$x_t$, $\mu_\theta$的结果和$\tilde{\mu_t}$更接近，因为任意$x_t$在给定$x_0$的情况下都可以求出，我们可以参数化高斯噪声，把反向扩散的目标变成让$\epsilon_t$和$\epsilon_\theta$更接近</p>

<p>
\begin{equation}
\begin{aligned}
\boldsymbol{\mu}_\theta(\mathbf{x}_t, t) &amp;= \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big) \\
\end{aligned}
\end{equation}
</p>

<p>损失函数$L_t$为:</p>

<p style="font-size: 20px">
\begin{equation}
\begin{aligned}
L_t 
&amp;= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{1}{2 \| \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t) \|^2_2} \| \tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0) - \boldsymbol{\mu}_\theta(\mathbf{x}_t, t) \|^2 \Big] \\
&amp;= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{1}{2  \|\boldsymbol{\Sigma}_\theta \|^2_2} \| \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_t \Big) - \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\boldsymbol{\epsilon}}_\theta(\mathbf{x}_t, t) \Big) \|^2 \Big] \\
&amp;= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{ (1 - \alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \| \boldsymbol{\Sigma}_\theta \|^2_2} \|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2 \Big] \\
&amp;= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{ (1 - \alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \| \boldsymbol{\Sigma}_\theta \|^2_2} \|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t)\|^2 \Big] 
\end{aligned}
\end{equation}
</p>

<h2 id="24-ddpm中给出的训练与采样生成过程">2.4. DDPM中给出的训练与采样(生成)过程</h2>
<center><img src="../assets/img/posts/20221012/4.jpg" /></center>

<p>训练过程:</p>
<ol>
  <li>采样一个$x_0$</li>
  <li>任选一个时间t</li>
  <li>随机采样一个高斯噪声$\epsilon$</li>
  <li>计算损失函数的梯度，更新参数$\theta$</li>
</ol>

<p>采样过程:</p>
<ol>
  <li>采样一个高斯噪声$x_T$</li>
  <li>从时间T开始，每一步采样一个高斯噪声z，利用重参数化，得到上一步的$x_{t-1}$，重复T次，最终得到生成的$x_0$</li>
</ol>

<p>注意这里还没有给出$\epsilon_\theta(x_t, t)$的网络结构，DDPM使用U-Net作为其网络结构(后面会具体展开)</p>

<h2 id="25-小结">2.5. 小结</h2>
<p>简单来说，扩散模型的前向扩散过程都是定义好的马尔可夫链，每一步都需要使用重参数化技巧来添加噪声，这里每一步的后验分布的参数都是预定义好的。反向扩散过程就是用噪声生成原始图片的过程，和VAE类似，用分布$p_\theta(x_{t-1}|x_t)$来拟合真实的后验分布$q(x_{t-1}|x_t)$，所以生成过程最重要的就是训练出合适的分布来拟合，通过VLB和重参数化的技巧，最终可以把训练过程看成给一个高斯噪声，拟合成前向扩散的噪声。这里的网络结构一般使用的是U-Net</p>

<h1 id="3-一些技巧和主要网络结构">3. 一些技巧和主要网络结构</h1>
<h2 id="31-beta_t和sigma_theta的取值">3.1. $\beta_t$和$\Sigma_\theta$的取值</h2>
<p>关于$\beta_t$的取值，DDPM的做法是$\beta_1=10^{-4}$到$\beta_T=0.02$线性取值，这样的扩散模型取得的效果不算最好，<a href="https://arxiv.org/abs/2102.09672" target="_blank">Improved DDPM</a>提出了一种新的取值方法:</p>

<p>
\begin{equation}
\beta_t = \text{clip}(1-\frac{\bar{\alpha}_t}{\bar{\alpha}_{t-1}}, 0.999) \quad\bar{\alpha}_t = \frac{f(t)}{f(0)}\quad\text{where }f(t)=\cos\Big(\frac{t/T+s}{1+s}\cdot\frac{\pi}{2}\Big)
\end{equation}
</p>

<p>关于$\Sigma_\theta$的取值方法，DDPM采用固定的$\Sigma_\theta$(不学习)，可以取$\beta_t$或者$\tilde{\beta_t}=\frac{1 - \bar{\alpha_{t-1}}}{1 - \bar{\alpha_t}} \cdot \beta_t$，Improved DDPM采用可学习的$\Sigma_\theta$参数，利用线性插值的方法:</p>

<p>
\begin{equation}
\boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t) = \exp(\mathbf{v} \log \beta_t + (1-\mathbf{v}) \log \tilde{\beta}_t)
\end{equation}
</p>

<p>由于损失函数中没有关于$\Sigma_\theta$的梯度，所以需要对损失函数进行一点更改</p>

<h2 id="32-加速扩散模型采样的技巧">3.2. 加速扩散模型采样的技巧</h2>
<p>DDPM的作者对比了扩散模型和其他生成模型的生成速度，发现DDPM的生成速度远小于其他生成模型，有一些加速模型采样的技巧:</p>
<ol>
  <li>缩短采样步骤，比如每隔T/S步才采样一次</li>
  <li><a href="https://arxiv.org/abs/2010.02502" target="_blank">DDIM</a>论文里提出的技巧，在采样过程中只需要采样一个子集的步骤便可做生成</li>
  <li><a href="https://arxiv.org/abs/2112.10752" target="_blank">Latent Diffusion Model</a>论文提出让扩散过程在隐空间中进行，而不是在像素空间中进行，这样可以让训练代价更小，推断过程更快，后续会整理LDM论文</li>
</ol>

<h2 id="33-u-net">3.3. U-Net</h2>
<p>很多扩散模型的噪声网络结构都是基于<a href="https://arxiv.org/pdf/1505.04597.pdf" target="_blank">U-Net</a>，U-Net的网络结构如下图:</p>

<center><img src="../assets/img/posts/20221012/5.jpg" /></center>

<p>模型可以分为两个部分，左边用于特征的抽取，右边部分用于上采样，由于网络结构酷似字母U而得名。U-Net网络结构又可以看成AutoEncoder的结构，它的bottleneck就是中间的低纬度特征表示，U-Net要保证输出的噪声和输入的噪声有相同的维度，是一个自回归模型。DDPM使用的是PixelCNN++的backbone，也就是基于Wide Resnet的U-Net，也就是说encoder和decoder之间是残差连接，输入$x_t$返回噪声(残差思想)</p>

<h1 id="4-条件生成">4. 条件生成</h1>
<p>条件生成就是conditioned generation，通过输入额外的conditioning information来生成图片，比如一段提示词或者生成图片的类别</p>

<h2 id="41-classifier-guided-diffusion">4.1. Classifier Guided Diffusion</h2>
<p>博客上讲解的关于classifier guidance的部分不太详尽，于是我去翻看了Classifier Guidance的论文<a href="https://arxiv.org/abs/2105.05233" target="_blank">Diffusion Models Beat GANs</a>:</p>

<p>classifier guidance的思路来源于GAN模型的条件生成，将这种条件生成应用于扩散模型后，发现效果非常好。作者提出可以训练一个分类器$p_\phi(y|x_t, t)$，然后把$\nabla_{x_t} \log p_\phi\left(y \mid x_t, t\right)$的加到总的梯度公式里面，来指导扩散模型<strong>采样的过程</strong>偏向于生成类别为y的图片</p>

<p>没有classifier guidance之前的反向扩散分布函数为: $p_\theta(x_t|x_{t+1})$，但是有了classifier guidance之后，反向扩散的后验分布函数变成了:</p>

<p>
\begin{equation}
p_{\theta, \phi}(x_t|x_{t+1}, y) = Zp_\theta(x_t|x_{t+1})p_\phi(y|x_t)
\end{equation}
</p>

<p>其中Z是正则化的常数，接下来我们需要化简上面这个公式，首先我们知道$p_\theta(x_t|x_{t+1})$本质上就是正态分布:</p>

<p>
\begin{equation}
p_\theta(x_t|x_{t+1})=\mathcal{N}(\mu, \Sigma)
\end{equation}
</p>

<p>然后我们对$log_\phi p(y|x_t)$在$x=\mu$处进行泰勒展开:</p>

<p>
\begin{equation}
\begin{aligned}
\log p_\phi(y \mid x_t) &amp; \approx log p_\phi (y \mid x_t) \mid _{x_t=\mu}+(x_t-\mu)\nabla_{x_t}logp_\phi(y \mid x_t)\mid _{x_t=\mu} \\
&amp;=(x_t-\mu)g+C_1\\
\end{aligned}
\end{equation}
</p>

<p>这里$g=\nabla_{x_t}logp_\phi(y \mid x_t)\mid _{x_t=\mu}$</p>

<p style="font-size: 18px">
\begin{equation}
\begin{aligned}
\log \left(p_\theta\left(x_t \mid x_{t+1}\right) p_\phi\left(y \mid x_t\right)\right) &amp; \approx-\frac{1}{2}\left(x_t-\mu\right)^T \Sigma^{-1}\left(x_t-\mu\right)+\left(x_t-\mu\right) g+C_2 \\
&amp;=-\frac{1}{2}\left(x_t-\mu-\Sigma g\right)^T \Sigma^{-1}\left(x_t-\mu-\Sigma g\right)+\frac{1}{2} g^T \Sigma g+C_2 \\
&amp;=-\frac{1}{2}\left(x_t-\mu-\Sigma g\right)^T \Sigma^{-1}\left(x_t-\mu-\Sigma g\right)+C_3 \\
&amp;=\log p(z)+C_4, z \sim \mathcal{N}(\mu+\Sigma g, \Sigma)
\end{aligned}
\end{equation}
</p>

<p>那么反向扩散过程就可以看成均值为$\mu+\Sigma g$，方差为$\Sigma$的正态分布，那么我们有以下采样算法:</p>

<center><img src="../assets/img/posts/20221012/6.jpg" /></center>

<p>另一种思路是修改正态分布中的噪声函数，原本的梯度为:</p>

<p>
\begin{equation}
\nabla _{x_t} log p_\theta (x_t) = - \frac{1}{\sqrt{1-\overline{\alpha_t}}} \epsilon_\theta (x_t)
\end{equation}
</p>

<p>修改反向扩散函数后的梯度为:</p>

<p>
\begin{equation}
\begin{aligned}
\nabla _{x_t} log (p_\theta (x_t) p_\phi (y \mid x_t))  &amp;= \nabla _{x_t} log p_\theta (x_t) + \nabla _{x_t} log p_\phi (y \mid x_t) \\
&amp;= - \frac{1}{\sqrt{1-\overline{\alpha_t}}} \epsilon_\theta (x_t) + \nabla _{x_t} log p_\phi (y \mid x_t)
\end{aligned}
\end{equation}
</p>

<p>那么根据梯度，我们可以定义一个新的噪声预测函数$\hat{\epsilon}$:</p>

<p>
\begin{equation}
\hat{\epsilon(x_t)} := \epsilon_\theta(x_t) - \sqrt{1-\overline{\alpha_t}} \nabla _{x_t} log p_\phi(y \mid x_t)
\end{equation}
</p>

<p>该方法对应的算法为:</p>

<center><img src="../assets/img/posts/20221012/7.jpg" /></center>

<h2 id="42-classifier-free-guidance">4.2. Classifier-Free Guidance</h2>
<p>上一小节提到的classifier guidance的技巧是需要单独使用一个分类器(参与训练或者不参与训练的情况都有)来获得$x_t$的类别，根据不同的class可以使用不同的分类器，比如resnet可以进行图片类别的guidance，CLIP可以进行文本的guidance等等。如果我们没有这个单独的分类器，我们也可以利用classifier-free guidance的技巧来实现条件生成，同样地，为了更详尽地了解这个技巧，我去翻看了<a href="https://arxiv.org/abs/2112.10741" target="_blank">GLIDE</a>论文中关于classifier-free guidance的介绍</p>

<p>classifier-free guidance并不需要模型去单独给出一个分类器，而是将条件生成与非条件生成都用同一个函数表示，即$\epsilon(x_t\mid y)$，如果我们希望这个函数表示非条件生成，那么我们只需要将y替换成空集即可，在训练过程中，我们以相同的概率随机替换y为空集。采样时，反向扩散函数为$\epsilon_\theta(x_t \mid y)$和$\epsilon_\theta(x_t \mid \emptyset)$的线性插值:</p>

<p>
\begin{equation}
\hat{\epsilon_\theta}(x_t \mid y)=\epsilon_\theta(x_t\mid \emptyset) + s \cdot (\epsilon_\theta(x_t\mid y)-\epsilon_\theta(x_t\mid \emptyset))
\end{equation}
</p>

<p>式子中的s是guidance scale，s越大代表生成的图片越靠近y，guidance-free的技巧出现后，大家发现它的效果非常好，于是后续的模型基本上都运用了该技巧，比如GLIDE、DALLE2、Imagen</p>

<h2 id="43-scale-up-generation-resolution-and-quality">4.3. Scale up Generation Resolution and Quality</h2>
<p>为了生成更高质量和更高分辨率的图片，可以将扩散模型与超分辨率的技术相结合，论文<a href="https://arxiv.org/abs/2106.15282" target="_blank">Cascaded Diffusion Model</a>中提出用层级式的扩散模型来做图片的超分辨率生成，模型的结构如下图:</p>

<center><img src="../assets/img/posts/20221012/8.jpg" /></center>

<p>模型由三个子模型组成，分别是一个基础的扩散模型和两个超分辨率扩散模型，注意这里的每个子模型都需要输入类别，超分辨率子模型还需要输入上一个子模型的低分辨率结果，这些子模型都是conditional的。超分辨率扩散模型与普通的扩散模型的区别是损失函数和反向扩散函数不同，具体来说就是U-Net的结构不同，超分辨率的U-Net的输出维度比输入维度要大，而且输入为低分辨率的图片、高分辨率的图片、类别:</p>

<center><img src="../assets/img/posts/20221012/9.jpg" /></center>

<p>一个two-stage的cascaded模型的训练算法为:</p>

<center><img src="../assets/img/posts/20221012/10.jpg" /></center>

<p>一个two-stage的cascaded模型的采样算法为:</p>

<center><img src="../assets/img/posts/20221012/11.jpg" /></center>]]></content><author><name>Quehry</name></author><category term="notes" /><summary type="html"><![CDATA[collect and arrange information and principle of diffusion model]]></summary></entry><entry><title type="html">短文本评估论文阅读整理</title><link href="http://localhost:4000/short-answer-assessment.html" rel="alternate" type="text/html" title="短文本评估论文阅读整理" /><published>2022-10-10T00:00:00+08:00</published><updated>2022-10-10T00:00:00+08:00</updated><id>http://localhost:4000/short-answer-assessment</id><content type="html" xml:base="http://localhost:4000/short-answer-assessment.html"><![CDATA[<!-- TOC -->

<ul>
  <li><a href="#1-论文简介">1. 论文简介</a></li>
  <li><a href="#2-bert-based-deep-neural-networks">2. BERT-Based Deep Neural Networks</a>
    <ul>
      <li><a href="#21-abstract">2.1. Abstract</a></li>
      <li><a href="#22-introduction">2.2. Introduction</a></li>
      <li><a href="#23-related-work">2.3. Related Work</a>
        <ul>
          <li><a href="#231-applications-of-deep-learning-in-asag-tasks">2.3.1. Applications of Deep Learning in ASAG Tasks</a></li>
          <li><a href="#232-bert-model-and-its-application-in-education">2.3.2. BERT Model and Its Application in Education</a></li>
        </ul>
      </li>
      <li><a href="#24-methodology">2.4. Methodology</a>
        <ul>
          <li><a href="#241-task-definition">2.4.1. Task Definition</a></li>
          <li><a href="#242-model">2.4.2. Model</a>
            <ul>
              <li><a href="#2421-bert-layer">2.4.2.1. BERT layer</a></li>
              <li><a href="#2422-semantic-refinement-layer">2.4.2.2. Semantic Refinement Layer</a></li>
              <li><a href="#2423-semantic-fusion-layer">2.4.2.3. Semantic Fusion Layer</a></li>
              <li><a href="#2424-prediction-layer">2.4.2.4. Prediction Layer</a></li>
              <li><a href="#2425-loss-function">2.4.2.5. Loss Function</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#25-experiments">2.5. Experiments</a>
        <ul>
          <li><a href="#251-datasets">2.5.1. Datasets</a></li>
          <li><a href="#252-experimental-settings">2.5.2. Experimental Settings</a></li>
          <li><a href="#253-ablation-studies">2.5.3. Ablation Studies</a></li>
          <li><a href="#254-comparison-with-baseline-systems">2.5.4. Comparison With Baseline Systems</a></li>
        </ul>
      </li>
      <li><a href="#26-discussions">2.6. Discussions</a></li>
      <li><a href="#27-conclusion">2.7. Conclusion</a></li>
    </ul>
  </li>
  <li><a href="#3-semantic-facets">3. Semantic Facets</a>
    <ul>
      <li><a href="#31-abstract">3.1. Abstract</a></li>
      <li><a href="#32-introduction">3.2. Introduction</a></li>
      <li><a href="#33-related-works">3.3. Related Works</a>
        <ul>
          <li><a href="#331-automated-response-evaluation">3.3.1. Automated response evaluation</a></li>
          <li><a href="#332-semantic-similarity-measurement">3.3.2. Semantic similarity measurement</a></li>
        </ul>
      </li>
      <li><a href="#34-patterns-and-indicative-powers-of-facets-matching-states">3.4. Patterns and indicative powers of facets matching states</a>
        <ul>
          <li><a href="#341-materials-and-methods">3.4.1. Materials and methods</a>
            <ul>
              <li><a href="#3411-dataset">3.4.1.1. Dataset</a></li>
              <li><a href="#3412-summary-of-facet-matching-states">3.4.1.2. Summary of facet matching states</a></li>
              <li><a href="#3413-answer-quality-prediction-with-facet-matching-states">3.4.1.3. Answer quality prediction with facet matching states</a></li>
            </ul>
          </li>
          <li><a href="#342-results-and-analysis">3.4.2. Results and analysis</a>
            <ul>
              <li><a href="#3421-facet-matching-pattern">3.4.2.1. Facet matching pattern</a></li>
              <li><a href="#3422-answer-evaluation-leveraging-facet-matching-states">3.4.2.2. Answer evaluation leveraging facet matching states</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#35-automatic-extraction-of-facets-matching-features-for-better-prediciton">3.5. Automatic Extraction of Facets Matching Features For Better Prediciton</a>
        <ul>
          <li><a href="#351-materials-and-methods">3.5.1. Materials and methods</a>
            <ul>
              <li><a href="#3511-dataset">3.5.1.1. Dataset</a></li>
              <li><a href="#3512-automatic-semantic-facet-extraction">3.5.1.2. Automatic semantic facet extraction</a></li>
              <li><a href="#3513-facet-matching-features">3.5.1.3. Facet matching features</a></li>
              <li><a href="#3514-semantic-closeness-features">3.5.1.4. Semantic closeness features</a></li>
            </ul>
          </li>
          <li><a href="#352-results-and-analysis">3.5.2. Results and analysis</a></li>
        </ul>
      </li>
      <li><a href="#36-discussion">3.6. Discussion</a></li>
      <li><a href="#37-conclusion">3.7. Conclusion</a></li>
      <li><a href="#38-小结">3.8. 小结</a></li>
    </ul>
  </li>
  <li><a href="#4-todo">4. TODO</a></li>
</ul>

<!-- /TOC -->

<h1 id="1-论文简介">1. 论文简介</h1>
<ul>
  <li><a href="https://ieeexplore.ieee.org/abstract/document/9779091" target="_blank">short answer grading model</a></li>
  <li><a href="https://ieeexplore.ieee.org/abstract/document/9860098" target="_blank">semantic facets</a></li>
</ul>

<p>这是两篇关于short-answer assessment的论文，所谓short-answer assessment就是对简答题的答案进行评估(和参考答案对比)，第一篇提出了利用BERT解决这个问题，第二篇提出了改进了评估过程，用多个semantic facets来评估short-answer，这篇博客记录一下对这两篇论文的精读</p>

<h1 id="2-bert-based-deep-neural-networks">2. BERT-Based Deep Neural Networks</h1>
<h2 id="21-abstract">2.1. Abstract</h2>
<p>Automatic short-answer grading(ASAG)，即自动短文本评分任务，是智慧辅导系统的重要组成部分。ASAG目前还存在很多挑战，作者提出了两个主要原因: 1)高精度评分任务需要对answer text有很深的语义理解; 2)ASAG任务的语料一般都很小，不能为深度学习提供足够的训练数据。为了解决这些挑战，作者提出用BERT-based网络来解决ASAG任务的挑战: 1)用预训练模型BERT来encoder答案文本就可以克服语料太小的问题。2)为了生成足够强的语义理解，作者在BERT输出层后加上了一个精炼层(由LSTM和Capsule网络串联组成) 3)作者提出一种triple-hot loss来处理ASAG的回归问题。实验结果表明模型的效果在SemEval-2013和Mohler数据集上表现比SOTA要好。模型在github上<a href="https://github.com/wuhan-1222/ASAG" target="_blank">开源</a></p>

<h2 id="22-introduction">2.2. Introduction</h2>
<p>考试和评估是智慧辅导系统(intelligent tutoring systems, ITSs)的重要组成部分，可以获得学生们的实时知识认知水平，也能为学生们提供个性化的学习方案。多选题是考试的重要组成部分，但是多选题有两个明显的短板: 1)多选题只提供部分选择 2)有些学生的答案可能是蒙出来的。ASAG可以解决上述问题，学生们为简答题提供一个short text，然后ASAG来评估short text是否正确，具体来说评估结果有五类: Correct、Partically correct、Contradictory、Irrelevant、Nondomain。</p>

<p>以往的研究中，Feature engineering是ASAG的主要解决方法，有很多稀疏特征应用于ASAG: token overlap features、syntax and dependency features、knowledge-based features(WordNet)… 但是这种特征工程为基础的方法存在以下问题: 首先，稀疏特征一般需要很多预处理步骤，这些步骤会产生一定的误差，可能会涉及到误差累积和误差传递的后果。此外，缺乏有效地encode文本句的手段</p>

<p>随着deeplearning的发展，出现了很多deep net，比如LSTM-based model、CNN and LSTM-based model、transformer-based model出现在了ASAG任务中。这些模型都从answer text中挖掘语义信息，然后将answer text转化成word enbedding，所以这些方法都是end-to-end的。但是这些方法存在以下问题: 1)学生的答案非常free，也就是说在句子结构、语言风格、段落长度这些方面可能会有很大的区别，所以作者认为需要用更先进的technique去获得text的语义理解。2)由于数据很难标注，所以ASAG任务的数据集语料很小，可能只有few thousand。所以说主要的挑战就是如何在小语料库上训练一个稳定高效的模型</p>

<p>论文的主要贡献:</p>
<ol>
  <li>提出了用预训练模型BERT微调，然后连接一个精炼层的模型表现超过SOTA(在SemEval-2013数据集和Mohler数据集上)</li>
  <li>精炼层由Bi-LSTM和Capsule network(with position information)串联组成，LSTM来抽取全局的context信息，Capsule来抽取局部context信息</li>
  <li>用多头注意力层来连接全局和局部context来生成语义表示</li>
  <li>提出了triple-hot loss策略</li>
</ol>

<h2 id="23-related-work">2.3. Related Work</h2>
<h3 id="231-applications-of-deep-learning-in-asag-tasks">2.3.1. Applications of Deep Learning in ASAG Tasks</h3>
<p>根据deep learning和训练策略的不同，作者将deeplearning在ASAG的应用分为以下三种:</p>
<ol>
  <li>Participator: deep learning参与feature-based方法中</li>
  <li>Contractor: deeplearning独立地在ASAG任务中实现end-to-end</li>
  <li>迁移学习，经典的预训练模型+scaling语料库</li>
</ol>

<p>接下来分别介绍了利用稀疏特征的方法与Deeplearning来来解决ASAG任务:</p>
<ol>
  <li>稀疏特征，也即feature engineering的应用有:
    <ul>
      <li>Marvaniya等人和Saha等人使用预训练的神经网络InferSent对答案文本进行编码，这弥补了标记重叠(token overlap)方法中上下文表示的不足，其中InferSent是使用Bi-LSTM网络的预训练句子嵌入模型</li>
      <li>Tan等人提出了一种将图卷积网络(GCNs)与几种稀疏特征相结合的评分方法。他们首先为答案文本构建了一个无向异构文本图，其中包含句子级节点、单词/bigam级节点和节点之间的边。然后，他们使用两层GCN模型对图结构进行编码，得到图的表示形式。</li>
      <li>Zhang等人使用深度信念网络作为分类器，而不是传统的机器学习，对学生由六个稀疏特征组成的答案表示进行分类</li>
    </ul>
  </li>
  <li>Deeplearning的方法有:
    <ul>
      <li>Kumar等人提出了ASAG的Bi-LSTM框架。他们的框架由三个级联的神经模块组成:分别应用于参考和学生答案的Siamese Bi-LSTMs，使用earth-mover distance(EMD)与LSTMs的隐状态交互的池化层，以及用于输出分数的回归层</li>
      <li>Uto和Uchida将LSTM网络与项目反应理论(item response theory)相结合进行短文本答案评分</li>
      <li>Tulu等人改进了基于LSTM的评分方法，通过引入感觉向量并将池化层替换为曼哈顿距离</li>
      <li>Riordan等人结合CNN和LSTM网络进行短文本答案评分</li>
      <li>Liu等人在一个大型K-12数据集上提出了一个具有多路注意的模型</li>
    </ul>
  </li>
</ol>

<p>上面提到的deeplearning方法需要大语料库支撑的数据集，但是ASAG缺少足够的大语料库，于是出现了用预训练模型来解决ASAG任务，比如ELMo、BERT、GPT、GPT-2，在这些模型中，BERT表现最好</p>

<h3 id="232-bert-model-and-its-application-in-education">2.3.2. BERT Model and Its Application in Education</h3>
<p>BERT吸收了ELMo和GPT的优点，模型如下图所示:</p>
<center><img src="../assets/img/posts/20221010/2.jpg" /></center>
<p>BERTstack了12个transformer块</p>

<p>接下来介绍了BERT在智慧教育领域的应用:</p>
<ol>
  <li>Wang等人提出了分层课程BERT模型，以更好地捕捉每门课程的课程结构质量和语言特征，预测在线教育中教师的绩效</li>
  <li>Khodeir等人将BERT与多层双向GRU相结合，构建了一个紧急分类模型，用于教师快速挑选和响应大规模开放在线课程(MOOC)论坛中最紧急的学生帖子，该模型在三个Stanford MOOC Post数据集上实现了紧急帖子分类，加权F-score分别为91.9%、91.0%和90.0%</li>
  <li>Sung等人利用BERT构建了一个多标签分类模型，用于快速评估学生在探索热力学的过程中的多模态的表征思维</li>
</ol>

<p>关于ASAG的应用有:</p>
<ol>
  <li>Sung等人分析比较了BERT与多种网络结构在short-answer grading的效果</li>
  <li>Leon等人分析比较了BERT、ALBERT、RoBERTa在short-answer grading的效果</li>
</ol>

<h2 id="24-methodology">2.4. Methodology</h2>
<h3 id="241-task-definition">2.4.1. Task Definition</h3>
<p>ASAG问题有两种形式:</p>
<ol>
  <li>回归问题: 连续的分数来评估学生的答案</li>
  <li>分类问题: 将学生的答案分为五类: Correct、Partically correct、Contradictory、Irrelevant、Nondomain</li>
</ol>

<p>作者的做法是用分数来对类别进行分类，比如0-0.5属于类别1，所以问题的本质还是分类问题，那么ASAG的预测类别$y^*$可以表示为:</p>

<p>
\begin{equation}
y^*=\underset{y \in Y}{\operatorname{argmax}}(\operatorname{Pr}(y \mid(q, p)))
\end{equation}
</p>

<p>其中Y表示类别集，Pr()表示预测的概率分布，q是学生答案，p是参考答案</p>

<h3 id="242-model">2.4.2. Model</h3>
<p>作者解释为什么即要用BERT，也要用refinement:</p>
<ol>
  <li>BERT获得word embedding结果，利用了所有词元之间的关系，但是没有考虑顺序和距离，所以需要用Bi-LSTM来生成更精细的全局context，同时弥补BERT时序信息的缺失，然后利用Capsule或者CNN来生成BERT每个隐层的局部信息</li>
  <li>BERT可以获得动态的词嵌入(对比GloVe获得静态的词嵌入)，这样可以获得更丰富的general-purpose knowledge，所以BERT即使在小语料库上也能有不错的效果</li>
  <li>一些研究表明，在BERT上应用经典的神经网络可以在小数据集上获得更好的效果，比如Liao等人结合RoBERTa和CNN来提升情感分析的效果，Yang等人在BERT上应用多头注意力层来添加距离权重在aspect polarity classification上获得更好的效果</li>
</ol>

<p>主题网络模型如下图所示:</p>
<center><img src="../assets/img/posts/20221010/4.jpg" /></center>
<p>接下来从模型的各个板块来分别介绍:</p>

<h4 id="2421-bert-layer">2.4.2.1. BERT layer</h4>
<p>首先BERT layer的参数初始化成BERTbase的参数，微调。BERT layer层的输入是学生和参考答案的token embedding，输出是BERT的隐层</p>

<p>
\begin{equation}
O_{BERT}=BERT(s)=\left\{h_1^b,h_2^b,...,h_n^b\right\}\in \mathbb{R}^{n\times d_b}
\end{equation}
</p>

<h4 id="2422-semantic-refinement-layer">2.4.2.2. Semantic Refinement Layer</h4>
<p>Refinement层由Bi-LSTM和Capsule network(with position information)串联组成，输出结果如下所示:</p>

<p>
\begin{equation}
\begin{aligned}
&amp;\overrightarrow{O_{\mathrm{LSTNS}}}=\overrightarrow{\operatorname{LSTMS}}\left(O_{\text {BERT }}\right)=\left\{\overrightarrow{h_1^L}, \overrightarrow{h_2^L}, \ldots, \overrightarrow{h_n^L}\right\} \in \mathbb{R}^{n \times d_L} \\
&amp;\overleftrightarrow{O_{\mathrm{LSTMs}}}=\overleftarrow{\operatorname{LSTMs}}\left(O_{\mathrm{BERT}}\right)=\left\{\overleftrightarrow{h_1^r}, \overleftrightarrow{h_2^r}, \ldots, \overleftrightarrow{h_n^r}\right\} \in \mathbb{R}^{n \times d_L} \\
&amp;O_{\mathrm{Caps}}=\operatorname{Capsules}\left(O_{\text {BERT }}\right)=\left\{h_1^c, h_2^c, \ldots, h_n^c\right\} \in \mathbb{R}^{n \times d_c}
\end{aligned}
\end{equation}
</p>

<p>输出结果后面都跟了一个层归一化(保证数据分布的稳定，加速收敛)</p>

<p>这里提到了Capsule network，我对Capsule network进行一定的补充: Capsule网络主要想解决卷积神经网络（Convolutional Neural Networks）存在的一些缺陷，比如说信息丢失，视角变化等。Capsule网络结构如下图所示:</p>
<center><img src="../assets/img/posts/20221010/7.jpg" /></center>
<p>以数字图片分类为例，Capsule一共包含3层，2层卷积层和1层全连接层。与普通网络的区别是输出的每个类别都是一个向量，向量的长度表示实体存在的概率大小，向量在空间中的方向表示实体的实例化参数，Capsule网络和CNN还是比较相似的</p>

<h4 id="2423-semantic-fusion-layer">2.4.2.3. Semantic Fusion Layer</h4>
<p>在refinement层后，需要有一个融合层来融合LSTM和Capsule的结果，先用矩阵来stackLSTM、Capsule的结果:</p>

<p>
\begin{equation}
X^{(e)}=\{x_1^{(e)}, x_2^{(e)},...,x_n^{(e)}\}\in \mathbb{R}^{n\times d}
\end{equation}
</p>

<p>其中$x_i^{(e)}=[h_i^L;h_i^r;h_i^c]$，然后再把矩阵X送入多头自注意力层，注意力评分函数是scaled dot-product attention，具体细节如下:</p>

<p>
\begin{equation}
\begin{aligned}
&amp; \text{MultiHead}(Q,K,V)=[\text{head}_1;\text{head}_2;...;\text{head}_h]\omega^R \\
&amp; \text{head}_i=\text{Attention}(Q_i;K_i;V_i)=\text{Attention}(Q\omega ^Q, K\omega ^K, V\omega ^V) \\
&amp; \text{Attention}(Q_i;K_i;V_i)=\text{softmax}(\frac{Q_iK_i^T}{\sqrt{d_K}})V_i \\
 X^{(h)}&amp;=\text{MultiHead}(X^{(e)}, X^{(e)}, X^{(e)}) \\
&amp;=\{x_1^{(h)}, x_2^{(h)},..., x_n^{(h)}\}
\end{aligned}
\end{equation}
</p>

<p>为了让全局context和局部context不互相干扰，作者对多头自注意力层做以下约束:</p>
<ol>
  <li>让LSTM的输出维度和Capsule的输出维度相同，即$d_c=2d_L$</li>
  <li>head数取2</li>
  <li>让局部context和全局context不互相干扰(用参数调整)，如下图所示:</li>
</ol>
<center><img src="../assets/img/posts/20221010/10.jpg" /></center>
<p>最后再连接一个层归一化</p>

<h4 id="2424-prediction-layer">2.4.2.4. Prediction Layer</h4>
<p>预测层，首先用最大池化层获得pair(q,p)的语义表示，其实就是在每个头上选择最大的值:</p>

<p>
\begin{equation}
\begin{aligned}
Z &amp;=\text{Maxpooling}(X^{(h)})={z_1,z_2,...,z_d}\in \mathbb{R}^d \\
z_j &amp;=\text{Max}(x_{1j}^{(h)}, x_{2j}^{(h)},..., x_{nj}^{(h)}), j=1,2,...,d
\end{aligned}
\end{equation}
</p>

<p>然后将语义表示Z输入线性层(加上一个dropout防止overfit)，然后用softmax表示输出的概率分布:</p>

<p>
\begin{equation}
\begin{aligned}
o &amp;=MZ+b \\
p(y\mid Z)&amp;=\frac{exp(o_y)}{\sum_{i}^{d_y}exp(o_i)}
\end{aligned}
\end{equation}
</p>

<h4 id="2425-loss-function">2.4.2.5. Loss Function</h4>
<p>为了适应两种ASAG tasks，作者提出了两种损失函数的策略:</p>
<ul>
  <li>第一种就是常规的交叉熵，分类结果用one-hot编码</li>
</ul>

<p>
\begin{equation}
L(\theta)=-\sum_{i=1}^{|\Omega|}\log \left(p\left(y_i \mid Z_i, \theta\right)\right)
\end{equation}
</p>

<ul>
  <li>第二种就是作者提出用triple-hot编码y，就是在y对应位置的左右也置1，那么损失函数为:</li>
</ul>

<p>
\begin{equation}
\begin{aligned}
L(\theta)=&amp;-\sum_{i=1}^{|\Omega|}\left(\log \left(p\left(y_i^{-1} \mid Z_i, \theta\right)\right)+\log \left(p\left(y_i \mid Z_i, \theta\right)\right)\right.\\
&amp;\left.+\log \left(p\left(y_i^{+1} \mid Z_i, \theta\right)\right)\right)
\end{aligned}
\end{equation}
</p>

<h2 id="25-experiments">2.5. Experiments</h2>
<h3 id="251-datasets">2.5.1. Datasets</h3>
<p>作者在两个ASAG主流数据集上进行评估，分别是SemEval-2013和Mohler数据集</p>
<center><img src="../assets/img/posts/20221010/16.jpg" /></center>

<ol>
  <li>SemEval-2013: 作者使用SemEval-2013中的SciEntsBank语料，SciEntsBank语料包含15个不同科学领域的197个问题和10000个答案，这个语料库是ASAG分类任务的一个benchmark，他包含三种分类类别，分别是two-way(Correct and Incorrect)，three-way (Correct, Contradictory, and Incorrect)，five-way (Correct, Partially correct, Contradictory, Irrelevant, and Non-domain)，为了提供多方面的evaluation，测试数据集分为了三个子集:
    <ul>
      <li>Unseen Answers(UA): 和训练集有相同的题目和参考答案，但是学生的回答不同</li>
      <li>Unseen Questions(UQ): 和训练集的问题不同，但是属于同一个领域</li>
      <li>Unseen Domains(UD): 和训练集的问题不同，且不属于同一个领域</li>
      <li>对于这个数据集，作者用三个性能度量(accuracy, weighted-F1, macro-average F1)来评估两个子任务(three-way, five-way)</li>
    </ul>
  </li>
  <li>Mohler dataset: 数据集<a href="http://web.eecs.umich.edu/?mihalcea/downloads/ ShortAnswerGrading_v2.0.zip" target="_blank">开源</a>。数据集由Mohler团队从University of North Texas的一门计算机科学课程的两个考试和十个测试收集整理。它包含80个问题和2273个学生的答案，每个答案都由两名老师打分(0-5, integer)，由于是平均而来，所以一共由11种分类结果，Mohler数据集同样是ASAG任务的一个benchmark，作者可以将数据集变成了11个类别的分类数据集。</li>
</ol>

<p>由于数据集只有2273个答案对，太小，所以需要对数据集进行扩充，Kumar等人通过把训练集中正确的学生答案作为额外的参考答案，这样就把数据集的答案-问题对扩充到30000对。作者为了避免过拟合，采取了折中的策略，对每个问题只挑选一个学生的正确答案作为额外的参考答案，这样就把2083个答案对扩充至3300个答案对。针对Mohler数据集，作者采用了12折交叉验证的方法，用来评估的性能度量有Cohen’s kappa coefficient(kappa), Pearson correlation coefficient(Pearson’s r), mean absolute error(MAE), root-mean-square error(RMSE)，Mohler的标签只有11类，作者既可以把它当作了回归任务来评估(就是把分类结果用分数表示)，也可以把它当作分类任务来评估，其中kappa系数是分类任务的性能度量，其他的性能度量都是回归任务的性能度量</p>

<h3 id="252-experimental-settings">2.5.2. Experimental Settings</h3>
<p>BERT采用base版本(12层，768个单元，12个head，110M参数)，LSTM的隐层个数设置为200并且在最后一个时间步返回所有的hidden state，Capsule的卷积核个数设置为400，卷积核大小为3，dynamic route设置为3。在融合层，attention head设置为2，每个头400维参数，dropout参数都设置为0.1，使用adam优化器，学习率设置为2e-5，一个小批量64个输入，训练周期为10</p>

<h3 id="253-ablation-studies">2.5.3. Ablation Studies</h3>
<p>为了分析每一层的作用，从六个角度来做ablation studies:</p>
<ol>
  <li>W/O refinement: 无refienment</li>
  <li>W/O multihead: 无multihead</li>
</ol>

<p>以此类推，得到如下结果:</p>
<center><img src="../assets/img/posts/20221010/17.jpg" /></center>

<h3 id="254-comparison-with-baseline-systems">2.5.4. Comparison With Baseline Systems</h3>
<p>与众多模型进行对比，主要的实验结果如下:</p>
<ul>
  <li>Mohler数据集</li>
</ul>
<center><img src="../assets/img/posts/20221010/18.jpg" /></center>

<ul>
  <li>SemEval-2013:</li>
</ul>
<center><img src="../assets/img/posts/20221010/19.jpg" /></center>

<ul>
  <li>PR曲线:</li>
</ul>
<center><img src="../assets/img/posts/20221010/20.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20221010/21.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20221010/22.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20221010/23.jpg" /></center>

<ul>
  <li>AUC值和PR曲线平衡点:</li>
</ul>
<center><img src="../assets/img/posts/20221010/24.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20221010/25.jpg" /></center>

<h2 id="26-discussions">2.6. Discussions</h2>
<p>从Ablation实验结果可以看出，refinement层提升了模型的在Sem-UQ和Mohler数据集上的精度，说明refinement层提高了BERT模型在相同问题领域的泛化性，同时也可以看出LSTM在refinement层也很重要，可以提取更丰富的全局context信息。Capsule的有无也说明了它可以提取局部context信息，同时发现它的效果比一般的CNN要好。Triple-loss的设计也确实提升了模型的性能</p>

<p>接着简单分析了一下表4(Mohler数据集)与表5(SemEval-2013)的结果，其实就是对比了不同模型的性能度量，说哪个模型更好什么的</p>

<p>然后分析PR曲线的结果，作者认为在大多数情况下，模型的PR曲线远高于其他模型的PR曲线，这与表6中模型在所有图中AUC最大的结论是一致的。除此之外，平衡点的值也更高，说明模型性能最好</p>

<p>模型可以应用于智慧教育系统的两个场景:</p>
<ol>
  <li>ITSs领域，即智慧辅导系统，可以让评估变成自动化的</li>
  <li>MOOC线上平台，可以替代老师的手动评估，快速精准地为大量的free-text answer进行评分</li>
</ol>

<h2 id="27-conclusion">2.7. Conclusion</h2>
<p>作者提出了一种新的BERT-based网络结构来解决ASAG问题，进行了大量的实验，得出了一下的结论:</p>
<ol>
  <li>基于词嵌入的网络，如CNN、LSTM、Capsule无法在小数据集上取得很好的结果</li>
  <li>预训练网络BERT可以很好的适配ASAG任务</li>
  <li>利用LSTM和Capsule网络可以进一步挖掘语义信息</li>
</ol>

<p>模型局限性:</p>
<ol>
  <li>在开放领域的问答中，小数据集训练出来的模型无法取得预期的效果，比如Sem-UD</li>
  <li>目前来说，模型无法消除或者替代学生答案中的大量的代词，作者计划在后续通过BERT模型来消除学生答案中的代词来提升模型的性能</li>
</ol>

<h1 id="3-semantic-facets">3. Semantic Facets</h1>
<p>论文全称为Leveraging Semantic Facets for Automatic Assessment of Short Free Text Answers，接下来将逐段阅读并整理论文</p>

<h2 id="31-abstract">3.1. Abstract</h2>
<p>短文本问答能反映出学生对于知识的掌握情况，由于自然语言的复杂性，简答题的自动评估任务仍具有挑战性。现有的自动评估模型的做法是预测答案的分数来评估学生的答案，他们一般不关心参考答案的语义面，这限制了预测的表现。该篇论文的关注点是短文本答案的不同的语义面(semantic facets)，每个语义面对应着需要掌握的知识。利用带有语义面标注的数据集，作者首先展示了语义面状态与答案质量(一个答案的好坏)的对应关系，然后展示了语义面在自动评估答案质量的重要性。作者接着将工作拓展到不包含语义面的数据集上，证明了作者的工作在自动评估短文本答案方面的有效性，这些工作包括语义面提取、预测语义面状态和使用语义面的特征工程。</p>

<p>论文的贡献有:</p>
<ol>
  <li>论文提出的方法提升了短文本答案评估的SOTA的表现</li>
  <li>论文深入研究短文本答案的语义面组成，让短文本评估模型的可解释性更高</li>
</ol>

<h2 id="32-introduction">3.2. Introduction</h2>
<p>评估学生的答案非常重要，在网上学习中，实现手动评估非常困难，加速了关于自动评估的研究。研究着重于学生的短文本答案，与多选题相比，答案更不被定义且不具备结构化，所以自动评估很困难。此外，为了正确回答问题，一个短文本的回答可能传达了学生对知识的更深层次的思考，并且可能包含多个从属的知识。有了语义面之后，一个更详细的评估方法出现了，可以分析学生答案的不同语义部分，而不是简单的给出答案的分数。</p>

<p>最近的研究基本上都采取了黑盒的模式(black box)，即从一端输入学生的答案和参考答案，另一端直接输出答案的分数，这中间发生了什么我们并不知道。虽然说对于评估系统来说，分数很重要，但是参考答案涉及到的多个知识点与学生答案的匹配情况我们却一概不知。为了提升评估任务的表现，作者将关注点从黑盒转移到分解评估的过程。为了简便，作者将参考答案的知识组成称为语义面(Semantic Facets)，给定一段文本，这段本文的语义面是由文本的短语组成的集合</p>

<p>论文的主要实验和工作有两个，分别在SciEntsBank数据集和Beetle数据集上展开</p>
<ol>
  <li>第一个工作数据集是SciEntsBank，每个问题的语义面都标注好了，学生答案与问题的语义面匹配状态(matching state)也给出了，这样我们就可以得到不同评分等级(correct, incorrect…)的答案的语义面匹配状态的分布情况。有了分布情况后，我们便可以回答以下问题: 1)是否能根据学生答案的语义面匹配状态来确定答案的评分? 2)分布情况对自动评估系统是否有帮助? 除此之外，我们还可以构建模型来通过学生的答案和语义面来预测语义面的匹配状态</li>
  <li>为了泛化第一个工作，第二个工作使用的数据集是Bettle数据集，这个数据集既没有语义面的标注，也没有语义面的匹配状态的标注。作者首先提出了一种从参考答案提取语义面的方法: 利用词汇统计(lexical statistics)和语法信息(syntax information)。接着利用第一个工作中训练好的预测语义面的匹配状态的网络来预测这个数据集的语义面匹配状态，然后再利用工作一中发现的pattern来通过学生答案的语义面匹配状态来获取features(后续用于对答案进行评分，所以这一步就是feature engineering)，最后，利用这些feature来预测答案的评分</li>
</ol>

<p>贡献:</p>
<ol>
  <li>部分程度上打开了自动评估模型的black box</li>
  <li>发现了matching state与不同评分等级的对应关系，即发现了pattern，这对于自动和手动评估都有帮助</li>
  <li>提出了一种从参考答案抽取语义面的方法</li>
</ol>

<h2 id="33-related-works">3.3. Related Works</h2>
<p>该小节介绍了论文的两个相关工作: 1)自动评估系统的不同任务及对应方法 2)量化一对文本的语义相似度的方法</p>

<h3 id="331-automated-response-evaluation">3.3.1. Automated response evaluation</h3>
<p>根据自动评估系统目标的不同进行分类:</p>
<ol>
  <li>为了评估学习者的语言使用能力，许多评估系统从语言和语法使用、内容组织等方面评估写作质量，这样的系统有ETS(educational testing services)、E-Rator 、Coh-metrics、AcaWriter</li>
  <li>评估学生答案时要求学生的答案涵盖特定的知识，只有涵盖了最关键的部分，学生才能获得满分。为了这个目标，许多系统训练了一个预测模型，有运用词重叠(word overlapping)，语义和语法相似等特征的模型，也有预训练模型来做embedding的模型</li>
</ol>

<p>论文工作属于第二类</p>

<h3 id="332-semantic-similarity-measurement">3.3.2. Semantic similarity measurement</h3>
<p>量化两段文本的相似度是自然语言处理的基本步骤，短文本自动评估系统通过文段相似度的测量来量化学生答案和参考答案的相似度。测量方法有term matching(术语匹配)技术和涉及外部知识的语义计算(semantic computation)</p>
<ol>
  <li>term matching技术基于真实文本和预测文本的公共单词，基于term matching的方法有BLUE和Rouge。</li>
  <li>term matching有个明显的短板就是无法处理近义词或者同义词，可以用WordNet来解决。除此之外，一个单词或者短语的意思可以被分解成量化的语义块，这样测量起来才是数字化的(非二进制)，这样的方法有LSA(Latent Semantic Analysis)、Word2vec、GloVe。但即使是Word2vec也无法解决一词多义的问题，所以诞生了单词的动态语义嵌入(即考虑了context)，这样的模型有RNN-based ELMo、Bert等等</li>
</ol>

<h2 id="34-patterns-and-indicative-powers-of-facets-matching-states">3.4. Patterns and indicative powers of facets matching states</h2>
<p>也就是intro里提到的第一个工作，着眼于发现state和response type的pattern，然后利用这个pattern来做预测(通过答案的语义面匹配状态来预测答案的评分)</p>

<h3 id="341-materials-and-methods">3.4.1. Materials and methods</h3>
<h4 id="3411-dataset">3.4.1.1. Dataset</h4>
<p>数据集使用的是SciEntsBank，数据集大约有10000个学生答案和197个问题，学生答案分为五类(5-ways，见表格1)，训练集和测试集分别有4969和5835个样本，同样地，根据问题的不同分为: UA, UQ, UD。数据集中每一个问题都包含语义面的标注，正确的学生答案应该cover这些语义面，数据集中同样包含语义面匹配状态的标注，语义面的状态一共有八种，见表格2</p>

<center><img src="../assets/img/posts/20221010/26.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20221010/27.jpg" /></center>

<p>为了更直观地了解样本和语义面及语义面匹配状态，这里举了一个例子:</p>

<center><img src="../assets/img/posts/20221010/28.jpg" /></center>
<center><img src="../assets/img/posts/20221010/29.jpg" /></center>

<p>这个例子的语义面及两个学生答案对应的语义面匹配状态见表格3:</p>

<center><img src="../assets/img/posts/20221010/30.jpg" /></center>

<p>通过表格3我们可以发现语义面关注相关对象的特定属性或状态，这里可以发现相对正确的答案A基本上与所有的语义面都匹配，但是相对不正确的答案B与某些语义面冲突</p>

<h4 id="3412-summary-of-facet-matching-states">3.4.1.2. Summary of facet matching states</h4>
<p>每个语义面只有一个语义面匹配状态，不同问题的语义面数量不同，可以用语义面匹配状态的分布情况来总结一个问题的总体的语义面匹配状态，这样我们就可以比较不同评分等级的答案的匹配状态，比如我们可以比较答案A和B的分布，见表格4:</p>

<center><img src="../assets/img/posts/20221010/31.jpg" /></center>

<h4 id="3413-answer-quality-prediction-with-facet-matching-states">3.4.1.3. Answer quality prediction with facet matching states</h4>
<p>不同答案的语义面匹配状态的分布不同，可以将八种匹配状态的分布权重视为feature，答案的类型作为label，那么就可以进行分类。作者采用Gradient Boosting Tree(GBT)来当作预测模型。这样就可以通过答案的匹配状态分布来预测答案的评分</p>

<h3 id="342-results-and-analysis">3.4.2. Results and analysis</h3>
<h4 id="3421-facet-matching-pattern">3.4.2.1. Facet matching pattern</h4>
<p>数据集总体的语义面匹配状态分布见表格5，利用卡方检测，可以发现答案的类型与语义面匹配状态的权重(即分布)有关</p>

<center><img src="../assets/img/posts/20221010/32.jpg" /></center>

<p>归一化每个匹配状态的权重，得到下图的分布，可以发现不同答案类型的匹配状态分布不同:</p>

<center><img src="../assets/img/posts/20221010/33.jpg" /></center>

<p>观察发现，Correct的答案基本上express语义面，non domain的答案基本上unaddress语义面，不同类型答案的匹配状态分布情况就是一个pattern，用来连接一个答案的匹配状态和类型</p>

<h4 id="3422-answer-evaluation-leveraging-facet-matching-states">3.4.2.2. Answer evaluation leveraging facet matching states</h4>
<p>接下来评估以下GBT模型(通过匹配状态来预测类型)的表现情况，结果见表格6，性能度量是Macro F1</p>

<center><img src="../assets/img/posts/20221010/34.jpg" /></center>

<p>通过表格6可以发现，这个分类任务是具有挑战性的，基本上所有的模型都取得了相对较低的F1值，比较不同模型发现，GBT取得了最好的结果。总的来说，现实任务中不太可能会知道一个问题的语义面或者语义面匹配状态，所以作者将工作拓展到更一般的情况，也就是3.5节将介绍的内容</p>

<h2 id="35-automatic-extraction-of-facets-matching-features-for-better-prediciton">3.5. Automatic Extraction of Facets Matching Features For Better Prediciton</h2>
<p>对于语义面和语义面匹配状态都没有的情况下，作者提出了抽取语义面和预测语义面匹配状态的方法，然后利用特征抽取的方法挖掘出语义面匹配状态分布与pattern的关系，再结合语义相似性来预测答案的类型，这种方法大大提高了预测的表现</p>

<h3 id="351-materials-and-methods">3.5.1. Materials and methods</h3>
<h4 id="3511-dataset">3.5.1.1. Dataset</h4>
<p>数据集使用的是Beetle数据集，56个问题，5000个学生答案，标签有5-way和3-way，训练集和测试集分别有3941和1258个样本，测试集分为UA, UQ</p>

<h4 id="3512-automatic-semantic-facet-extraction">3.5.1.2. Automatic semantic facet extraction</h4>
<p>Beetle数据集的参考答案不包含语义面，但是一个问题会有多个参考答案，他们之间有细微的差别，一个例子:</p>

<p>问题是: Why does measuring voltage help you locate a burned out bulb?</p>

<p>参考答案:</p>
<ul>
  <li>Measuring voltage indicates the place where the electrical state changes due to a damaged bulb</li>
  <li>Measuring voltage indicates the place where theelectrical state changes due to a gap</li>
  <li>Measuring voltage indicates whether two terminals are connected to each other</li>
  <li>Measuring voltage indicates whether two terminals are separated by a gap</li>
</ul>

<p>接下来将介绍作者如何从参考答案集中抽取出语义面:</p>
<ol>
  <li>关键词提取: 从问题和参考答案中抽取出现次数超过两次的词，这些词就是关键词(pivotal word)</li>
  <li>基于语法的expression提取: 从参考答案的语法树(dependency parsing tree)中获取与语法相关的术语来形成更完整的expression，下面这张图展示了例子中四个参考答案的语法树:</li>
</ol>

<center><img src="../assets/img/posts/20221010/35.jpg" /></center>

<p>语法树建立句子中单词的语法关系，从中心词往外伸展，一个句子的中心词就是它的谓语。有两种生成语义面的方法，第一种就是连接关键词和树上与它相邻的词，比如voltage和measuring构成了一个语义面measuring voltage。第二种方法是针对一对关键词，找到它们的最小公共节点构成语义面，比如terminals和gap的最小公共节点是separated，那么它们可以构成语义面terminals separated gap。第一种方法的出发点是一个关键词可能是一个expression的一部分，第二种方法的出发点是两个关键词可以覆盖较大的语义区域，再结合它们的公共节点，便可包含多个语义面，成为一个新的语义面。</p>

<p>通过这两种方法可能会生成意义不明的语义面，但是这也是后续算法需要考虑的部分，增强了算法的泛化性</p>

<h4 id="3513-facet-matching-features">3.5.1.3. Facet matching features</h4>
<p>有了学生答案的语义面后，接下来就需要实现语义面匹配状态的预测。为了实现预测模型，作者用带匹配状态标签的SciEntsBank数据集进行训练。模型的细节在Appendix A中具体展开。模型的结构如下图所示:</p>

<center><img src="../assets/img/posts/20221010/36.jpg" /></center>

<p>模型的左边代表学生答案的输入，模型的右边代表语义面的输入，它们的每个词元都经过Bi-LSTM(embedding选择的是Glove)，然后输出隐状态，然后用注意力机制获得$\tilde{h_i^F}$，查询是语义面的hidden state，K和V是答案的hidden state，注意力权重为:</p>

<p>
\begin{equation}
a_{i,j}=\frac{e^{(h_i^F)^T\cdot h_j^R}}{\sum_{j'=1}^{N_R}e^{(h_i^F)^T\cdot h_{j'}^R}}
\end{equation}
</p>

<p>为了获取facet更全面的信息，作者将$\tilde{h_i^F}$、$h_i^F-\tilde{h_i^F}$、$h_i^F\odot \tilde{h_i^F}$、$h_i^F$连结了起来:</p>

<p>
\begin{equation}
\mathbf{c}_i=\left[\tilde{\mathbf{h}}_i^F ; \mathbf{h}_i^F-\tilde{\mathbf{h}}_i^F ; \mathbf{h}_i^F \odot \tilde{\mathbf{h}}_i^F ; \mathbf{h}_i^F\right]
\end{equation}
</p>

<p>接着对C进行取平均和最大的操作，concat之后输入MLP作预测，MLP这里取了三层，神经元数量分别为64、32和8，激活函数用ReLU:</p>

<p>
\begin{equation}
\begin{aligned}
&amp;\mathbf{c}_{\max }=\max (\mathbf{C}) \\
&amp;\mathbf{c}_{\min }=\operatorname{avg}(\mathbf{C}) \\
&amp;\mathbf{c}_{\mathrm{agg}}=\left[\mathbf{c}_{\max } ; \mathbf{c}_{\mathrm{avg}}\right] \\
&amp;\hat{\mathbf{y}}=\operatorname{softmax}\left(\operatorname{MLP}\left(\mathbf{c}_{\mathrm{agg}}\right)\right)
\end{aligned}
\end{equation}
</p>

<p>模型定义完后，作者比较了三种GBT的效果，GBT-Gold代表GBT在标注好的匹配状态和语义面上训练，GBT-Predict表示GBT在预测的匹配状态和标注好的语义面上训练，GBT-Approx表示GBT在预测的匹配状态和语义面上训练，性能度量同样是Macro F1，数据集用的也是SciEntsBank:</p>

<center><img src="../assets/img/posts/20221010/37.jpg" /></center>

<p>从表格中可以看出，GBT-Predict效果和GBT-Gold的效果差不多，根据预测的语义面匹配状态，我们有:</p>
<ul>
  <li>Aggregated facet matching states: 一个学生答案的预测语义面有很多，预测的语义面匹配状态需要聚合在一起。作者提出了两种聚合方法: 第一种软的是平均了所有语义面的预测匹配状态的概率，第二种硬的做法是针对每个语义面，只保留概率最高的匹配状态，两种方法都可以获得匹配状态的分布</li>
  <li>Pattern matching: 将网络结构的输出aggregate之后，与五种类型的真实匹配状态分布对比后，了解该答案的预测匹配状态分布属于哪一种类型。具体的对比方法是选取KL散度最小的作为该答案的类型，KL散度能测量两个分布的差距，0代表两个分布相似度最高，假如预测的分布为$\tilde{p(x)}$，那么KL散度为:</li>
</ul>

<p>
\begin{equation}
D(p_k(x)\|\tilde{p(x)}=\sum_{x\in C}p_k(x)log\frac{p_k(x)}{\tilde{p(x)}})
\end{equation}
</p>

<ul>
  <li>Confidence of prediction: 除了pattern matching外，匹配状态的confidence level也包含了很多信息。通过aggregate获得语义面的匹配状态分布后，取每个语义面预测概率值最高的概率值作为该语义面的confidence level。那么我们可以计算出Noisy-OR score:</li>
</ul>

<p>
\begin{equation}
Noisy-OR=1-\prod_{i=1}^{N_F}(1-\tilde{p_i})
\end{equation}
</p>

<p>其中$N_F$是语义面的个数，$\tilde{p_i}$就是语义面i的confidence level。如果所有的预测概率都是1，那么Noisy-OR为1，如果所有的预测概率都是0，那么Noisy-OR为0。Noisy-OR衡量了模型中至少有一个预测是合适的可能性有多大。Noisy-OR同样可以对某一个语义面匹配状态进行计算，这样得到的特征更好配合后续的使用</p>

<h4 id="3514-semantic-closeness-features">3.5.1.4. Semantic closeness features</h4>
<p>除了3.5.1.3小节中提到的基于feature的分类方法，基于语义相似度的分类方法也适用。接下来会介绍一些计算参考答案和学生答案语义相似度的方法，如果有多个参考答案，取平均值即可:</p>
<ol>
  <li>Term Matching Features: 用这些指数来计算语义相似度: N-gram overlapping, Rouge, Rouge-1, Rouge-2, Rouge-l, BLUE</li>
  <li>Fixed and dynamic embedding features: Glove, LSA, BERT。对参考答案和学生答案编码后计算相似度</li>
  <li>Semanic entailment features: 使用预训练的text entailment model: Decomposable Attention Model。输入文本对后，模型预测这两段文本的关系，有entailment, contradict, neutral</li>
</ol>

<h3 id="352-results-and-analysis">3.5.2. Results and analysis</h3>
<p>为了评估3.5.1.3.和3.5.1.4.这两节提出的features，可以用GBT来测试。GBT可以看成随机森林，GBT在不同的特征上进行训练，表格7给出了不同特征上训练的结果:</p>

<center><img src="../assets/img/posts/20221010/38.jpg" /></center>

<p>GBT(Full)表示上面提到的所有feature都运用了，包括aggregated matching state、KL散度、Noisy-OR、语义相似度和语义推断(semantic entailment)。可以发现将所有的信息都运用后，GBT(Full)模型是表现最好的模型。然后作者希望了解facet feature是否真的有效，GBT(Facets)就是运用了Facets所有特征的模型，横向对比GBT(Sem.Sim)和GBT(Sem.Entail)，发现facet的表现最好，不止如此，将这些特征全部结合得到的效果会更好。最后对比以下facet三个特征: Nosiy-OR、KL散度、aggregated matching states。发现Noisy-OR的效果最好。</p>

<p>为了更深入地了解facet的三个特征，作者画出了三种特征的importance scores，如下图所示:</p>

<center><img src="../assets/img/posts/20221010/39.jpg" /></center>

<p>importance score表明了数的预测结果相对于特征值的变化有多大，值越高说明该特征对于GBT来说越重要，作者将这些值归一化。观察发现，facet的三个特征中，Noisy-OR最重要，其次是KL散度，最后是匹配状态，这和表格7得出的结果一致。同时也发现语义相似度作为特征来说表现其实已经很好了，比但看facet的任意一个特征都强，但是却不如facet的三个特征加起来使用，变相证明了作者工作的有效性。还有就是虽然Semantic entailment作为特征来说表现不佳，但是也能将模型的整体性能提升一点</p>

<h2 id="36-discussion">3.6. Discussion</h2>
<p>总的来说，作者用两个数据集进行了两个实验，第一个实验首先得到了五种类型的答案的分布情况，然后用GBT实现了通过语义面匹配状态的分布来预测答案的类型。第二个实验首先给出了生产语义面的方法，然后提出了预测语义面匹配状态的网络，有了语义面匹配状态后，就可以得到facet的三个特征: state分布、KL散度和Noisy-OR。实验发现Noisy的效果很好，并且利用confidence进行预测是一种新思路，可能会对后续研究有所帮助。</p>

<p>然后作者分析实验结果发现，模型目前能明显区分出correct和non domain、irrelevant，但是与partially correct、contradictory相比却并不能很好的区分开。作者认为可能是partially和correct在语义上可能并不冲突导致。</p>

<p>接着，作者着眼于强调论文研究的重要性。论文里提出的facet不仅能提高模型的性能，更重要的是它们可以为更详细的反馈提供相关信息，这是教育系统为学习者提供反馈不可缺少的部分。具体来说，facet的出现让评分的可解释性更强。这样我们就可以分析学生答案是哪个知识点没有答对，或者是哪个知识点没有出现在答案中。这样，教育系统就能为学习者提供有效的反馈，可以提供点对点的反馈，比如这个facet为什么没有expressed等等。facet的实用价值高，它除了作为feature外，还可以使答案分析的可解释性更强。</p>

<h2 id="37-conclusion">3.7. Conclusion</h2>
<p>之前的许多研究往往关注评估学生回答的模型的表现，我们将待评估问题的知识点分解为从属的语义单元，称为语义面。每一个语义面都代表知识的某个方面，而它们共同构成参考答案的语义。然后作者实现了两个实验来说明研究的有效性，具体内容在discussion中已经说明。</p>

<p>future work: larger corpora, 优化语义面提取的算法, 预测state的算法使用更新的网络(比如bert及其衍生网络), facet的实用价值(比如提高解释性和用作feedback)</p>

<h2 id="38-小结">3.8. 小结</h2>
<p>facet这篇论文的着重点就是提出了语义面，这篇论文的出发点其实很好想到，就是评估模型的性能可能无法有很大的提升了，那么我将答案分成好几个小部分进行评估是否能提升模型的性能？于是便有了这篇论文，facet可以理解成参考答案的知识点，它是否在学生答案中表达出就是它的states。论文做了两个工作，第一个是直接基于有facet标注和state标注的数据集上进行实验，因为不同问题的facet数量不一样，所以用state的分布来表达可能会更好，首先通过统计得到了不同类型答案的state分布，这为后续KL散度这一特征有帮助。然后使用GBT作为预测模型，通过state的分布来预测答案的类型，得到了较好的效果。第二个实验基于正常的数据集，就是不包含facet和state的标签，这也是比较一般的情况，毕竟标注facet和state非常贵。首先每个问题没有了facet，那么首先就得设计算法来得到问题的facet，作者提出了一种基于Dependency parsing tree得到facet的方法，并在附录B对这个算法进行了评价。得到facet后还是没有state，所以得设计一个网络来得到facet的状态，模型的输入是facet和学生的response，利用LSTM来获得隐状态，并用注意力机制找到facet的近似表示，然后连结了facet的隐状态的各类信息，最后加个MLP得到state。到目前为止，已经有了facet和state，那么就可以得到facet的特征来作预测，相当于特征工程。facet的特征使用到的有: state分布, 与第一个工作中真实分布对比的KL散度, 运用到confidence的Noisy-OR。除此之外，作者还对比了其余的特征，比如语义相似度和semantic entailment(这是已有的工作)。最后将这些特征fusion之后的效果比较好</p>

<h1 id="4-todo">4. TODO</h1>
<ul>
  <li>看GBT, GPT, ELMo</li>
  <li>深入了解一下ASAG用特征工程解决的思路</li>
  <li>想想改进方向</li>
  <li>代码</li>
</ul>]]></content><author><name>Quehry</name></author><category term="notes" /><summary type="html"><![CDATA[read and arrange paper about short answer assessment]]></summary></entry><entry><title type="html">AutoEncoder系列整理</title><link href="http://localhost:4000/AutoEncoder-Series.html" rel="alternate" type="text/html" title="AutoEncoder系列整理" /><published>2022-10-08T00:00:00+08:00</published><updated>2022-10-08T00:00:00+08:00</updated><id>http://localhost:4000/AutoEncoder-Series</id><content type="html" xml:base="http://localhost:4000/AutoEncoder-Series.html"><![CDATA[<!-- TOC -->

<ul>
  <li><a href="#1-ae简介">1. AE简介</a></li>
  <li><a href="#2-dae">2. DAE</a></li>
  <li><a href="#3-vae">3. VAE</a>
    <ul>
      <li><a href="#31-数学原理">3.1. 数学原理</a>
        <ul>
          <li><a href="#311-variational-lower-bound">3.1.1. variational lower bound</a></li>
          <li><a href="#312-sgvb-estimator-and-aevb-algorithm">3.1.2. SGVB estimator and AEVB algorithm</a></li>
        </ul>
      </li>
      <li><a href="#32-vae模型">3.2. VAE模型</a></li>
      <li><a href="#33-总结">3.3. 总结</a></li>
    </ul>
  </li>
  <li><a href="#4-vqvae">4. VQVAE</a>
    <ul>
      <li><a href="#41-简介">4.1. 简介</a></li>
      <li><a href="#42-vqvae模型">4.2. VQVAE模型</a>
        <ul>
          <li><a href="#421-离散隐变量">4.2.1. 离散隐变量</a></li>
          <li><a href="#422-模型">4.2.2. 模型</a></li>
          <li><a href="#423-生成过程">4.2.3. 生成过程</a></li>
        </ul>
      </li>
      <li><a href="#43-vqvae2">4.3. VQVAE2</a></li>
      <li><a href="#44-其他">4.4. 其他</a></li>
    </ul>
  </li>
</ul>

<!-- /TOC -->

<h1 id="1-ae简介">1. AE简介</h1>
<p>AutoEncoder，即AE，自编码器，是一类在半监督学习和非监督学习中使用的人工神经网络，其功能是通过将输入信息作为学习目标，对输入信息进行表征学习(representation learning)，编码其实就是特征表示</p>

<p>半监督学习(semi-supervised learning)的训练数据一部分是有标签的，另一部分没有标签，而没标签的数量一般大于有标签数据的数量</p>

<p>自编码器的原理如下图所示，encoder首先读取input，将输入转换成高效的内部表示(code)，然后再由decoder输出输入数据的类似物</p>
<center><img src="../assets/img/posts/20221008/1.jpg" /></center>

<p>自编码器属于自监督学习的范畴，算法把输入作为监督信号来学习，encoder的作用其实就是对输入向量进行特征降维，常见的降维算法有主成分分析法PCA，但PCA本质上是一种线性变换，提取特征的能力有限</p>

<p>自编码器利用神经网络来学习输入的特征表达，AE利用数据x本身作为监督信号来指导神经网络的训练，即希望神经网络能学到映射$f_\theta$:x-&gt;x</p>
<center><img src="../assets/img/posts/20221008/2.jpg" /></center>
<p>把网络切分为两个部分，前面的子网络尝试学习映射关系$g_{\theta1}:x-&gt;z$，后面的子网络尝试学习映射关系$h_{\theta2}:z-&gt;x$，即编码器和解码器，编码器和解码器共同完成了输入数据x的编码、解码过程，把整个网络模型叫做AutoEncoder，模型根据输出与输入的距离函数作为损失函数来优化AE，随机梯度下降</p>

<p>假设输入为x，中间层为y，最终输出为z，那么y=s(Wx+b)，s是激活函数，z=s(W’y+b’)</p>

<p>接下来我将整理AE家族的一些模型，有DAE、VAE、VQVAE，当然不可能涵盖所有的模型，尽量介绍一些使用较多的模型</p>

<h1 id="2-dae">2. DAE</h1>
<p>通过Auto-Encoder得到的模型往往存在过拟合的风险，为了学习到较鲁棒的特征，可以在网络的输入层引入随机噪声，这种方法称为降噪自编码器(Denoising autoencoder, DAE)，为了更了解模型的原理和架构，我去阅读了DAE的<a href="https://dl.acm.org/doi/abs/10.1145/1390156.1390294" target="_blank">论文</a></p>

<p>作者的想法是让网络从corrputed的输入还原出原始输入，通过这个方法来提高模型的鲁棒性。corrputed的方法: 对于每一个输入x，随机选取$v_d$个元素置零，其他的部分保持不变，那么网络的目标就变成了对这些位置进行填空(fill-in)，这和BERT中Masked LM的思想差不多</p>
<center><img src="../assets/img/posts/20221008/3.jpg" /></center>
<p>论文的其他部分着重介绍为什么这种denoising的思想有用以及背后的数学原理</p>

<h1 id="3-vae">3. VAE</h1>
<p>AutoEncoder被指责只能简单地记住数据，在生成数据的能力上很差，于是变分自编码器VAE(Variational auto-encoder)出现了。<a href="https://arxiv.org/abs/1312.6114" target="_blank">论文链接</a></p>

<p>作者提出了一种autoencoding variational bayesian(AEVB)算法，在AEVB算法中，通过使用SGVB(stochastic gradient variational bayes)估计器优化识别模型，使推断和学习更加有效，该识别模型允许我们使用简单的采样来获得非常有效的近似后验分布</p>
<h2 id="31-数学原理">3.1. 数学原理</h2>
<p>数据集X由独立同分布采样的N个x组成，即$X={x^{(i)}}_{i=1}^N$。我们假设x的生成过程由两部分组成:</p>
<ul>
  <li>$z^{(i)}$采样自先验分布$p_{\theta*}(z)$</li>
  <li>$x^{(i)}$由似然函数$p_{\theta*}(x|z)$生成</li>
</ul>

<p>作者说不会对边缘概率分布和后验概率分布做一般的近似假设，所以一些常用的方法可能不行，作者提出用辨别模型$q_\Phi(z|x)$作为真实后验概率$p_\theta(z|x)$的近似，这里的$\Phi$也就是变分参数(variational parameters)，variational有两个作用，一个是可以用q(z|x)来近似p(z|x)，另一个是优化了lower bound的梯度计算</p>

<h3 id="311-variational-lower-bound">3.1.1. variational lower bound</h3>
<p>通过最大边缘似然函数$p_\theta(x)$来获得参数$\theta$的估计值，对数似然函数log$p_\theta(x)$可写成(x都指$x^{(i)}$):</p>

<p>
\begin{equation}
logp_\theta(x^{(i)})=D_{KL}(q_\phi(z\mid x^{(i)})\|p_\theta(z\mid x^{(i)}))+\mathcal{L}(\theta, \phi;x^{(i)})
\end{equation}
</p>

<p>推导过程为:</p>

<p style="font-size: 18px">
\begin{equation}
\begin{aligned}
logp_\theta(x)&amp;=E_{z\sim q_\phi(z\mid x)}[logp_\theta(x)] \\
&amp;=E_{z\sim q_\phi(z\mid x)}[logq_\phi(z\mid x)-logp_\theta(z\mid x)]+E_{z\sim q_\phi(z\mid x)}[-logq_\phi(z\mid x)-logp_\theta(x, z)] \\
&amp;=D_{KL}(q_\phi(z\mid x)\|p_\theta(z\mid x))+\mathcal{L}(\theta,\phi;x)
\end{aligned}
\end{equation}
</p>

<p>等式右边的第一项是KL散度，第二项是Evidence lower bound(ELBO)，因为KL散度非负，所以有:</p>
<center><img src="../assets/img/posts/20221008/6.jpg" /></center>
<p>ELBO可以进一步推导，有:</p>
<center><img src="../assets/img/posts/20221008/7.jpg" /></center>
<p>推导和前面类似，省略</p>

<p>我们希望最大化ELBO来获得参数$\Phi$和$\theta$，可以用梯度上升法，然而对ELBO求梯度有点困难，作者提出了SGVB estimator来解决这个问题</p>

<h3 id="312-sgvb-estimator-and-aevb-algorithm">3.1.2. SGVB estimator and AEVB algorithm</h3>
<p>首先介绍一下蒙特卡洛gradient estimator:</p>
<center><img src="../assets/img/posts/20221008/8.jpg" /></center>
<p>简单来说，蒙特卡洛就是将期望外的梯度符号移到了期望内</p>

<p>接下来我们需要应用一种再参数化(reparameterization)的trick来实现似然函数梯度的计算，具体来说就是服从q(z|x)分布的随机变量z可以写成可微的形式:</p>
<center><img src="../assets/img/posts/20221008/9.jpg" /></center>
<p>其中$\epsilon$就是噪声，那么再经过一系列的推导，就可以得出似然函数的梯度</p>

<p>AEVB算法:</p>
<center><img src="../assets/img/posts/20221008/10.jpg" /></center>

<h2 id="32-vae模型">3.2. VAE模型</h2>
<p>VAE是AEVB算法的一个实例，VAE在AEVB算法的基础上做了以下约束:</p>
<ul>
  <li>使用encoder来模拟后验分布$q_\Phi(z|x)$，并假设其满足多元混合高斯</li>
</ul>
<center><img src="../assets/img/posts/20221008/11.jpg" /></center>
<p>其中$\mu^{(i)}$和$\sigma^{(i)}$是输入$x^{(i)}$经过MLP后得到的结果，模型使用两个网络分别来估计每个样本对应的隐状态$z^{(i)}$的均值和方差</p>
<ul>
  <li>假设先验概率$p_\theta(z)$满足多元正态分布模型，即$p_\theta(z)~N(z;0,I)$</li>
  <li>用decoder来模拟$p_\theta(x|z)$</li>
  <li>使用重参数的trick来获得z，因为这里假设的是正态分布，所以z可以简单理解成$z=\mu+\sigma * \epsilon$，其中$\epsilon$采样自均值为0，方差为1的正态分布
这样我们就获得了VAE模型</li>
</ul>
<center><img src="../assets/img/posts/20221008/13.jpg" /></center>

<h2 id="33-总结">3.3. 总结</h2>
<center><img src="../assets/img/posts/20221008/12.jpg" /></center>
<p>这是我自己画的一张VAE模型图，encoder和decoder可以都是MLP。encoder的目的是从输入数据x中学习到z重参数化需要的变量$\mu$和$\sigma$，之后我们就可以采样噪声来获得z的先验分布，然后经过decoder得到重构的输出x，训练的过程其实就是学习x分布的过程。训练完成后，我们就可以得到生成模型$p_\theta(x|z)p_\theta(z)$，其中$p_\theta(x|z)$就是decoder，先验分布$p_\theta(z)$为正态分布，从先验分布$p_\theta(z)$随机采样一个z送入decoder，就可以得到与训练数据类似的输出，所以VAE是一个生成模型</p>

<p><a href="https://zhuanlan.zhihu.com/p/452743042" target="_blank">一篇介绍VAE很详细的博客</a></p>

<h1 id="4-vqvae">4. VQVAE</h1>
<h2 id="41-简介">4.1. 简介</h2>
<p><a href="https://proceedings.neurips.cc/paper/2017/hash/7a98af17e63a0ac09ce2e96d03992fbc-Abstract.html" target="_blank">论文链接</a>，VQVAE是DeepMind于2017年提出的一种基于离散隐变量(Discrete Latent variables)的生成模型，相比于VAE，VQVAE有两个重要的区别: 首先VQVAE采用离散隐变量(VAE采用的是连续隐变量)，其次VQVAE需要单独训练一个基于自回归的模型(比如PixelCNN)来学习先验概率，而不是像VAE那样采用一个固定的先验分布。VQVAE是一个强大的无监督表征学习模型，它学习的离散编码有很强的表征能力，DALLE第一版就是基于VQVAE的</p>

<h2 id="42-vqvae模型">4.2. VQVAE模型</h2>
<p>VQ-VAE的全称是Vector Quantised Variational AutoEncoder，与VAE的主要区别是使用了离散的隐变量和学习出来的prior(非固定)</p>

<h3 id="421-离散隐变量">4.2.1. 离散隐变量</h3>
<p>首先定义一个embedding space，记为e$\in R^{K*D}$，K就是embedding space的大小，D就是每个embedding vector的大小，embedding space由K个长度为D的向量组成。</p>
<center><img src="../assets/img/posts/20221008/15.jpg" /></center>
<p>原始输入x经过encoder后变成$z_e(x)$，然后我们需要向量化$z_e(x)$，即把它变成一个向量，这里就需要embedding space发挥作用，我们从embedding space的K个向量中选择一个作为$z_e(x)$向量化的结果，作者的做法是最临近查找(nearest neighbour look-up，即选择欧式距离最小的向量$e_{k}$作为向量化结果)，将向量化的结果$z_q(x)$输入decoder:</p>
<center><img src="../assets/img/posts/20221008/16.jpg" /></center>
<p>模型在训练过程中需要调整的参数就是encoder的参数、decoder的参数以及embedding space的参数。在训练过程中VQ-VAE其实没有用到先验分布prior，所以后面需要单独训练一个先验模型来生成数据。这里的z对于不同的任务是不同维度的，为了简便，用一维来举例，那么z的后验分布$q(z|x)$可以看成一个多类分布:</p>
<center><img src="../assets/img/posts/20221008/17.jpg" /></center>

<h3 id="422-模型">4.2.2. 模型</h3>
<p>模型如下图所示:</p>
<center><img src="../assets/img/posts/20221008/14.jpg" /></center>
<p>由于上面提到的argmin操作不可导，所以梯度就无法逆传播到encoder，论文采用了一种straight-through estimator的方法来解决这个问题，所谓straight-through estimator其实就是计算梯度时，忽略它而采用上游得到的梯度，在这里，就是用$z_q(x)$的梯度作为$z_e(x)$的梯度。损失函数的定义如下:</p>
<center><img src="../assets/img/posts/20221008/18.jpg" /></center>
<p>损失函数的第一项是重建误差，它用来优化encoder和decoder的参数，由于在计算梯度时采用了straight-through estimator的方法，所以重建误差不涉及embedding space的参数的更新，为了学习embedding space的参数，用L2误差来移动embedding space的特征向量$e_i$，也就是损失函数的第二项，这里的sg指的时stop gradient的操作，意味着这个L2损失只会更新embedding space的参数，不会传递到encoder。除此之外，论文还额外增加了一个commitment loss(损失函数第三项)，其主要目的是约束encoder的输出和embedding space保持一致，$\beta$的取值对算法的效果不会产生很大的影响，论文中取值0.25</p>

<p>关于先验模型prior，在训练VQVAE的主体过程中保持一致，在VQVAE训练完成后，作者为prior训练一个自回归分布p(z)，对于z是图片的情况下，用PixelCNN，对于z是音频的情况下，用WaveNet。VQVAE适用于多种模态的数据。embedding space也叫做codebook。</p>

<h3 id="423-生成过程">4.2.3. 生成过程</h3>
<p>VAE的目的是训练完成后, 丢掉encoder, 在prior上直接采样, 再加上decoder就能做生成。如果我们现在独立地采样HxW个z, 然后查表(codebook)得到维度为HxWxD的$z_q(x)$, 那么生成的图片在空间上的每块区域之间几乎就是独立的。因此我们需要让各个z之间有关系, 因此用PixelCNN, 对这些z建立一个autoregressive model: $p(z_1, z_2, z_3, …)=p(z_1)p(z_2|z_1)p(z_3|z_1, z_2)…$</p>

<h2 id="43-vqvae2">4.3. VQVAE2</h2>
<p>VQVAE2是VQVAE的升级版, 可以生成非常清晰的高分辨率图片. 主要变化就是把VQ-VAE的encoder和decoder进行了分层, bottom层对local feature进行建模, top层对global feature进行建模; 为了让top层能更有效地提取global信息, 在网络中加入了self attention</p>

<h2 id="44-其他">4.4. 其他</h2>
<ul>
  <li>知乎上两个讲解很详细的博客:
    <ul>
      <li><a href="https://zhuanlan.zhihu.com/p/91434658" target="_blank">知乎1</a></li>
      <li><a href="https://zhuanlan.zhihu.com/p/463043201" target="_blank">知乎2</a></li>
    </ul>
  </li>
  <li>VQVAE的特点是可学习的prior和codebook作离散化的设计，影响了很多后续的模型，包括BEiT和DALLE</li>
</ul>]]></content><author><name>Quehry</name></author><category term="notes" /><summary type="html"><![CDATA[Information about autoencoder series]]></summary></entry><entry><title type="html">概率统计</title><link href="http://localhost:4000/Probability-and-Statistics.html" rel="alternate" type="text/html" title="概率统计" /><published>2022-09-27T00:00:00+08:00</published><updated>2022-09-27T00:00:00+08:00</updated><id>http://localhost:4000/Probability-and-Statistics</id><content type="html" xml:base="http://localhost:4000/Probability-and-Statistics.html"><![CDATA[<h1 id="1-链接">1. 链接</h1>
<ul>
  <li><a href="https://blog.csdn.net/guleileo/article/details/80971601" target="_blank">贝叶斯、先验、后验、似然等基础知识</a></li>
</ul>

<h1 id="2-kl散度">2. KL散度</h1>
<h2 id="21-简介">2.1. 简介</h2>
<p>KL散度就是相对熵，是两个概率分布间差异的非对称性度量</p>

<h2 id="22-定义">2.2. 定义</h2>
<p>设$P(x)$与$Q(x)$是随机变量X上的两个概率分布，则在离散和连续变量的情形下，KL散度的定义分别为:</p>

<p>$KL(P||Q)=\sum P(x)log\frac{P(x)}{Q(x)}$</p>

<p>$KL(P||Q)=\int P(x)log\frac{P(x)}{Q(x)}dx$</p>]]></content><author><name>Quehry</name></author><category term="notes" /><summary type="html"><![CDATA[Information about autoencoder series]]></summary></entry><entry><title type="html">GAN</title><link href="http://localhost:4000/GAN.html" rel="alternate" type="text/html" title="GAN" /><published>2022-09-27T00:00:00+08:00</published><updated>2022-09-27T00:00:00+08:00</updated><id>http://localhost:4000/GAN</id><content type="html" xml:base="http://localhost:4000/GAN.html"><![CDATA[<h1 id="目录">目录</h1>

<!-- TOC -->

<ul>
  <li><a href="#目录">目录</a></li>
  <li><a href="#1-博客简介">1. 博客简介</a></li>
  <li><a href="#2-gan简介">2. GAN简介</a></li>
  <li><a href="#3-adversarial-nets">3. Adversarial nets</a></li>
  <li><a href="#4-理论原理">4. 理论原理</a></li>
  <li><a href="#5-其他">5. 其他</a></li>
</ul>

<!-- /TOC -->

<h1 id="1-博客简介">1. 博客简介</h1>
<p>GAN的全称是generative adversarial nets，是Goodfellow于2014年提出的新的生成模型框架，这种全新的生成模型框架有很多应用和变种，这篇博客主要介绍最开始的GAN的原理和论文整理，这里阅读的论文不是最终版(区别在于related work不同)，下面列出一些链接</p>
<ul>
  <li><a href="https://arxiv.org/abs/1406.2661" target="_blank">论文链接</a></li>
  <li><a href="https://www.bilibili.com/video/BV1rb4y187vD/?spm_id_from=333.788&amp;vd_source=64c99329fc39a0e3f42825a4c837e2a5" target="_blank">李沐讲解</a></li>
</ul>

<h1 id="2-gan简介">2. GAN简介</h1>
<p>GAN是一种全新的生成模型框架，它包含两个部分，生成模型G和辨别模型D，G的作用是捕捉数据的分布，D的作用是辨别数据来源于真实数据分布还是G生成的数据分布。生成模型训练过程就是让D犯错的可能性更高。GAN框架其实就是一个minmax game，如果G和D都是MLP的话，那么整个系统可以用逆传播机制训练。GAN的作者举了一个简单的例子介绍模型训练过程，生成模型可以看成印假钞的团伙，辨别模型可以看成警察，双方都在训练中提升自己的能力，最终希望达到的效果是警察无法分辨出一张假钞是真币还是假币。论文只介绍了一种特殊情况，就是G和D都是MLP的情况，作者把这种情况称为Adversarial nets</p>

<h1 id="3-adversarial-nets">3. Adversarial nets</h1>
<p>为了让生成模型学习到分布$p_g$(分布尽量和原始数据x的分布一致)，需要定义输入噪音的先验分布$p_z(z)$，$G(z;\theta_g)$表示噪音z输入生成模型的结果，G是一个可微分的函数，这里是MLP，参数为$\theta_g$。$D(x;\theta_d)$表示输入x后的辨别模型的结果，输出是一个标量，表示x来自于真实数据分布的概率。</p>

<p>也就是说，D和G的价值函数V(G, D)可表示为:</p>
<center><img src="../assets/img/posts/20220927/2.jpg" /></center>
<p>辨别模型D的目标是最大化价值函数的值，D(x)的取值在0-1之间，所以价值函数越大说明辨别模型D的效果越好，生成模型G的目标是最小化价值函数的值。GAN训练生成模型和辨别模型的过程为:</p>
<center><img src="../assets/img/posts/20220927/3.jpg" /></center>
<p>绿色的线是生成模型，蓝色虚线是辨别模型，黑色的散点线是原始数据分布</p>

<h1 id="4-理论原理">4. 理论原理</h1>
<p>算法原理由下面这一张图片展示:</p>
<center><img src="../assets/img/posts/20220927/4.jpg" /></center>
<p>在每个迭代周期的每个批量中，我们有m个取自先验分布的噪音z，其中z$\sim$ $p_g(z)$和m个取自真实分布的x，其中x$\sim$ $p_{data}(x)$，先训练辨别器D，沿着梯度上升的方向更新参数，然后在沿着log(1-D(G($z^{(i)}$)))的梯度下降的方向更新参数。</p>

<p>接下来介绍了一些命题和证明和一些定理，证实了GAN用到的价值函数和目标函数的可行性</p>

<h1 id="5-其他">5. 其他</h1>
<ul>
  <li>GAN在刚提出的时候还是有很多缺点的，比如模型还是比较难训练的，但是后续有很多很多的工作来优化原始的GAN模型，所以GAN更像是抛出了一个引子，让后续模型来优化它</li>
  <li>GAN本质上就是左右手互博，目标函数设计的也很好</li>
</ul>]]></content><author><name>Quehry</name></author><category term="note" /><summary type="html"><![CDATA[arrange notes]]></summary></entry><entry><title type="html">重要时间点及事件</title><link href="http://localhost:4000/Important-Event.html" rel="alternate" type="text/html" title="重要时间点及事件" /><published>2022-09-26T00:00:00+08:00</published><updated>2022-09-26T00:00:00+08:00</updated><id>http://localhost:4000/Important-Event</id><content type="html" xml:base="http://localhost:4000/Important-Event.html"><![CDATA[<!-- 2022.9.23 报9月工资 -->
<!-- 2022.10.10 选3pi的项目 -->
<!-- 2022.10.16 二十大 -->]]></content><author><name>Quehry</name></author><category term="daily" /><summary type="html"><![CDATA[for query]]></summary></entry><entry><title type="html">T5模型</title><link href="http://localhost:4000/T5%E6%A8%A1%E5%9E%8B.html" rel="alternate" type="text/html" title="T5模型" /><published>2022-09-19T00:00:00+08:00</published><updated>2022-09-19T00:00:00+08:00</updated><id>http://localhost:4000/T5%E6%A8%A1%E5%9E%8B</id><content type="html" xml:base="http://localhost:4000/T5%E6%A8%A1%E5%9E%8B.html"><![CDATA[<!-- TOC -->

<ul>
  <li><a href="#1-t5简介">1. T5简介</a></li>
  <li><a href="#2-读论文">2. 读论文</a>
    <ul>
      <li><a href="#21-introduction">2.1. Introduction</a></li>
      <li><a href="#22-setup">2.2. Setup</a>
        <ul>
          <li><a href="#221-model">2.2.1. Model</a></li>
          <li><a href="#222-the-colossai-clean-crawled-corpusc4">2.2.2. THE Colossai Clean Crawled Corpus(C4)</a></li>
          <li><a href="#223-downstream-tasks">2.2.3. Downstream Tasks</a></li>
          <li><a href="#224-input-and-output-format">2.2.4. Input and Output Format</a></li>
        </ul>
      </li>
      <li><a href="#23-experiments">2.3. Experiments</a>
        <ul>
          <li><a href="#231-baseline">2.3.1. Baseline</a>
            <ul>
              <li><a href="#2311-model">2.3.1.1. Model</a></li>
              <li><a href="#2312-training">2.3.1.2. Training</a></li>
              <li><a href="#2313-vocabulary">2.3.1.3. Vocabulary</a></li>
              <li><a href="#2314-unsupervised-objective">2.3.1.4. Unsupervised Objective</a></li>
              <li><a href="#2315-baseline-performance">2.3.1.5. Baseline Performance</a></li>
            </ul>
          </li>
          <li><a href="#232-architectures">2.3.2. Architectures</a>
            <ul>
              <li><a href="#2321-model-structures">2.3.2.1. Model Structures</a></li>
              <li><a href="#2322-comparing-different-model-structures">2.3.2.2. Comparing Different Model Structures</a></li>
              <li><a href="#2323-objectives">2.3.2.3. Objectives</a></li>
              <li><a href="#2324-results">2.3.2.4. Results</a></li>
            </ul>
          </li>
          <li><a href="#233-unsupervised-objectives">2.3.3. Unsupervised Objectives</a></li>
          <li><a href="#234-pre-training-data-set">2.3.4. Pre-training Data Set</a></li>
          <li><a href="#235-training-strategy">2.3.5. Training Strategy</a></li>
          <li><a href="#236-scaling">2.3.6. Scaling</a></li>
          <li><a href="#237-putting-it-all-together">2.3.7. Putting It All Together</a></li>
        </ul>
      </li>
      <li><a href="#24-reflection">2.4. Reflection</a></li>
    </ul>
  </li>
  <li><a href="#3-个人总结">3. 个人总结</a></li>
</ul>

<!-- /TOC -->

<h1 id="1-t5简介">1. T5简介</h1>
<p>T5的全称是text-to-text transfer transformer，是google于2019年推出的NLP领域的大型预训练模型，T5模型将NLP领域的任务均看成text to text类型，在众多任务的表现十分优异，模型本身的结构就是transformer的encoder-decoder结构，但是预训练目标以及其他细节有所区别</p>

<p>相关链接:</p>
<ul>
  <li><a href="https://arxiv.org/abs/1910.10683" target="_blank">论文</a></li>
  <li><a href="https://github.com/google-research/text-to-text-transfer-transformer" target="_blank">github</a></li>
  <li><a href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html" target="_blank">google博客</a></li>
  <li><a href="https://huggingface.co/docs/transformers/model_doc/t5" target="_blank">huggingface文档</a></li>
</ul>

<h1 id="2-读论文">2. 读论文</h1>
<p>摘要: 将所有的以文本为基础的语言任务变成text to text格式的任务，论文比较了不同的预训练目标、架构、无标签数据集、迁移方式在NLU任务上的表现。论文还新建了数据集C4，T5模型在很多benchmark上能做到SOTA，包括总结、QA、文本分类等。此外，T5模型和C4数据集均开源</p>

<h2 id="21-introduction">2.1. Introduction</h2>
<p>把所有的文本处理问题看成”text-to-text”问题，也即输入一段文本，输出一段文本。</p>

<center><img src="../assets/img/posts/20220919/2.jpg" /></center>

<h2 id="22-setup">2.2. Setup</h2>
<h3 id="221-model">2.2.1. Model</h3>
<p>Transformer架构一开始用于机器翻译任务，自注意力可以看成将一段序列的每个词元替换成其他词元的加权平均。T5模型的架构和Transformer的encoder-decoder结构基本一致，区别在于T5模型去除了层归一偏差，将层归一化放在残差路径外，使用了一种不同的位置嵌入方案。</p>

<h3 id="222-the-colossai-clean-crawled-corpusc4">2.2.2. THE Colossai Clean Crawled Corpus(C4)</h3>
<p>这一部分主要介绍了C4数据集的相关内容。Common Crawl是一个公开的<a href="https://commoncrawl.org/" target="_blank">数据集网站</a>，它可以提供从网页爬取的文本，但是这些文本数据存在很多问题，论文提出了以下的几种方法来让数据集更clean:</p>
<ul>
  <li>只保留以终点符号(即句点，感叹号，问号或引号)结尾的行</li>
  <li>丢弃少于五个句子的page，只保留超过3个单词的句子</li>
  <li>删除任何包含有在<a href="https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words" target="_blank">List-of-Dirty</a>网站中出现的单词的网页</li>
  <li>删除包含Javascript的行</li>
  <li>删除出现“lorem ipsum”短语的page</li>
  <li>删除所有包含大括号的页面</li>
  <li>对数据集进行重复数据删除，当连续的三句话重复出现时只保留一个</li>
  <li>使用langdetect工具过滤掉非英文的页面</li>
</ul>

<h3 id="223-downstream-tasks">2.2.3. Downstream Tasks</h3>
<p>T5模型为了测量总体的语言学习能力，在很多benchmark上测试性能，比如机器翻译、QA、摘要总结、文本分类。在GLUE和SuperGLUE上测试文本分类能力，在CNN/Daily Mail上测试摘要总结能力，在SQuAD上测试QA能力…</p>

<h3 id="224-input-and-output-format">2.2.4. Input and Output Format</h3>
<p>正如在introduction中提及的一样，论文将所有的task看成text-to-text格式。这种框架为预训练和微调提供了一致的训练目标。模型用极大似然目标训练(教师强制)。为了区分不同任务，给input前加上task-specific前缀。比如为英翻德加上前缀“translate English to German: ”，论文附录里有各种任务的前缀与相关处理方法。</p>

<h2 id="23-experiments">2.3. Experiments</h2>
<p>论文搭建模型的出发点是比较不同的预训练目标、模型架构、无标签数据集等方面，从中选择表现最好的部分组成T5模型。每次只改变baseline的一部分，其余部分保持不变。BERT不太好做生成任务，比如机器翻译和摘要总结</p>

<h3 id="231-baseline">2.3.1. Baseline</h3>
<p>也即基准</p>
<h4 id="2311-model">2.3.1.1. Model</h4>
<p>模型选用Transformer的Encoder-Decoder架构，相比于只使用Encoder来说，该架构在分类和生成任务上取得更好的效果</p>

<h4 id="2312-training">2.3.1.2. Training</h4>
<p>所有的任务都是text-to-text类型，这让作者能用极大似然法和交叉熵损失来训练模型，优化器选择AdaFactor。在测试阶段，选用概率最高的词元作为输出。在预训练阶段，采用逆平方根学习率策略，即学习率会随着迭代周期下降。预训练阶段，模型迭代524288步。在微调阶段，模型迭代262144步，同时使用固定的学习率。</p>

<h4 id="2313-vocabulary">2.3.1.3. Vocabulary</h4>
<p>由于模型任务包含了翻译任务，所以词表不仅包含了英语词汇，还包括德语、法语和罗马尼亚语词汇。词表是预定义的，所以模型输出不会出现超出词表的词汇</p>

<h4 id="2314-unsupervised-objective">2.3.1.4. Unsupervised Objective</h4>
<p>模型预训练过程需要无标签的数据。过往的预训练模型训练过程都采用masked language modeling(denosing objectives)作为预训练目标，大家发现这种处理方式能取得很好的结果。对于去噪目标，模型需要预测被遮掩的词元。借鉴于BERT的经验，模型随机采样并选择丢弃了15%的词元(作为masked)，并且连续的掩蔽词元只被一个sentinel词元替代。下面展示了一个掩蔽的例子</p>

<center><img src="../assets/img/posts/20220919/3.jpg" /></center>

<h4 id="2315-baseline-performance">2.3.1.5. Baseline Performance</h4>
<p>展示了baseline模型在不同benchmark上的表现，不同的benchmark使用不同的指标</p>

<center><img src="../assets/img/posts/20220919/4.jpg" /></center>

<h3 id="232-architectures">2.3.2. Architectures</h3>
<p>比较不同框架在benchmark上的表现</p>

<h4 id="2321-model-structures">2.3.2.1. Model Structures</h4>
<p>作者选择了三种不同的架构进行对比，第一种架构是传统的Transformer的encoder-decoder架构，第二种是language modeling(encoder)架构，BERT用的就是这个架构，下一步的输出依赖于前一步的预测，第三种是Prefix Language Model，为text-to-text任务提供任务的前缀，比如翻译任务就是加上前缀translate English to German:</p>

<center><img src="../assets/img/posts/20220919/5.jpg" /></center>

<h4 id="2322-comparing-different-model-structures">2.3.2.2. Comparing Different Model Structures</h4>
<p>比较了不同模型的层数，参数和FLOPS</p>

<h4 id="2323-objectives">2.3.2.3. Objectives</h4>
<p>除了架构的区别外，还比较了不同预训练目标带来的区别，比如使用Denosing Objectives时，LM架构需要把输入和输出连接起来进行连续的预测，使用LM目标时，LM架构需要从头预测到尾</p>

<h4 id="2324-results">2.3.2.4. Results</h4>
<p>直接看表格，可以发现第一种encoder-decoder架构的表现最好</p>

<center><img src="../assets/img/posts/20220919/6.jpg" /></center>

<h3 id="233-unsupervised-objectives">2.3.3. Unsupervised Objectives</h3>
<p>本章从以下几个角度比较Unsupervised Objectives，实验得出结论，选取BERT-style，Corruption Strategies选择Replace spans，Corruption rate选择15%，Corrupted span length选择对每个词元都决定是否corrupted(独立)，也即i.i.d.，这样得出的效果最好</p>

<center><img src="../assets/img/posts/20220919/7.jpg" /></center>

<h3 id="234-pre-training-data-set">2.3.4. Pre-training Data Set</h3>
<p>最终选择了全size的C4数据集作为预训练数据集</p>

<h3 id="235-training-strategy">2.3.5. Training Strategy</h3>
<p>比较了微调的不同方案、比较了多任务同时训练和单任务训练的效果，最终发现baseline的效果最好，即预训练加下游任务微调</p>

<h3 id="236-scaling">2.3.6. Scaling</h3>
<p>尝试了扩大模型规模的几种方式，最后发现baseline选择的预训练规模是最合适的，使用较大的模型可能会使下游的微调和推断变得更加昂贵</p>

<h3 id="237-putting-it-all-together">2.3.7. Putting It All Together</h3>
<p>这一部分介绍了模型最终的一些调整内容</p>
<ul>
  <li>预训练目标: 掩蔽片段平均长度为3，同时掩蔽比率为15%</li>
  <li>更长的训练过程: C4数据集够大，让训练过程可以不用重复数据，因此增加批量大小、增加训练步数会更好</li>
  <li>模型大小: 有好几个版本的T5模型，Base、Small、Large、3B and 11B</li>
  <li>多任务预训练: 使用多任务预训练会为下游任务带来好处
展示一下最终的效果</li>
</ul>

<center><img src="../assets/img/posts/20220919/8.jpg" /></center>

<h2 id="24-reflection">2.4. Reflection</h2>
<p>这一部分总结了模型的创新部分，同时提出了模型的缺点以及展望</p>

<h1 id="3-个人总结">3. 个人总结</h1>
<p>T5模型是google继bert之后推出的一个大型预训练模型，先说说T5模型的特点，T5模型的架构是transformer的encoder-decoder架构，预训练数据集选用google自制的C4数据集，数据集也相当大，作者希望做出一个大统一的预训练模型，所以采用text-to-text任务类型也是它的一大特点，具体来说就是把所有的NLP任务变成输入一段文本，模型输出一段文本的形式，模型的预训练目标也很有特色，采用了类似bert的掩蔽预训练目标。论文做了很多很多很贵的实验，对比了很多方面，最后得到了这个模型，论文里的实验都说明的很详细，同时它也刷了很多榜，比如GLUE等，效果是比之前的预训练模型都好，是google财大气粗的表现。</p>

<p>模型在github上开源，在tensorflow上可以直接实现</p>]]></content><author><name>Quehry</name></author><category term="paper" /><summary type="html"><![CDATA[arrange notes]]></summary></entry><entry><title type="html">动手学深度学习</title><link href="http://localhost:4000/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html" rel="alternate" type="text/html" title="动手学深度学习" /><published>2022-09-05T00:00:00+08:00</published><updated>2022-09-05T00:00:00+08:00</updated><id>http://localhost:4000/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0</id><content type="html" xml:base="http://localhost:4000/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html"><![CDATA[<!-- TOC -->

<ul>
  <li><a href="#0-简介">0. 简介</a></li>
  <li><a href="#1-预备知识">1. 预备知识</a></li>
  <li><a href="#2-线性神经网络">2. 线性神经网络</a></li>
  <li><a href="#3-多层感知机">3. 多层感知机</a></li>
  <li><a href="#5-卷积神经网络">5. 卷积神经网络</a></li>
  <li><a href="#6-现代卷积神经网络">6. 现代卷积神经网络</a></li>
  <li><a href="#7-循环神经网络">7. 循环神经网络</a></li>
  <li><a href="#8-现代循环神经网络">8. 现代循环神经网络</a></li>
  <li><a href="#9-注意力机制">9. 注意力机制</a></li>
  <li><a href="#12-计算机视觉">12. 计算机视觉</a></li>
  <li><a href="#13-自然语言处理-预训练">13. 自然语言处理: 预训练</a></li>
  <li><a href="#14-自然语言处理-应用">14. 自然语言处理: 应用</a></li>
</ul>

<!-- /TOC -->

<h1 id="0-简介">0. 简介</h1>
<ul>
  <li>《动手学深度学习》的笔记</li>
  <li>各种链接:
    <ul>
      <li><a href="https://space.bilibili.com/1567748478" target="_blank">bilibili</a></li>
      <li><a href="https://zh-v2.d2l.ai/index.html" target="_blank">book_zh</a></li>
      <li><a href="https://d2l.ai/index.html" target="_blank">book_en</a></li>
    </ul>
  </li>
  <li>这本书笼统的介绍了深度学习所需要的各种知识，从线性神经网络开始讲起，然后到CNN，最后到RNN，介绍了CV和NLP领域的较新的网络结构。同时这本书不止有理论内容，每一小节都有代码实践内容，可以边写代码边了解知识，同时bilibili上有李沐老师的网课配合学习，很适合初学者进行学习。</li>
</ul>

<h1 id="1-预备知识">1. 预备知识</h1>
<p>这一章主要介绍了深度学习的一些前置知识，这里对比较重要的点做备注</p>
<ul>
  <li>张量(Tensor)包含了一维张量(向量)和二维张量(矩阵)</li>
  <li>torch中A*B是哈达玛积，表示矩阵元素按元素相乘</li>
  <li>torch.dot()是点积</li>
  <li>torch.cat(…, dim=0)表示在行上延伸，比如(3, 4)和(3, 4)变成(6, 4)</li>
  <li>A.sum(axis=0)表示把每一列的数据都相加，比如(5, 4)变成(4)</li>
  <li>范数是norm，L1范数为每个元素的绝对值相加，L2范数为元素的平方和开根号，torch中默认L2范数，一般也是L2范数用的最多</li>
  <li>梯度: 连接多元函数的所有偏导数:</li>
</ul>

<center><img src="../assets/img/posts/20220905/2.jpg" /></center>

<ul>
  <li>梯度是一个向量</li>
  <li>常用的梯度计算公式:</li>
</ul>

<center><img src="../assets/img/posts/20220905/3.jpg" /></center>

<ul>
  <li>torch中自动求导的步骤:
    <ul>
      <li>第一步 为x分配内存空间: x.requires_grad_(True)</li>
      <li>第二步 链式反向传播，希望求哪个函数的梯度，就对那个函数反向传播，比如y.backward()</li>
      <li>第三步 求x的梯度，x.grad，如果我们需要重新求梯度，需要清零梯度，x.grad.zero_()</li>
      <li>注意torch中只能对标量输出求梯度，所以常见操作是sum</li>
    </ul>
  </li>
  <li>标量对向量的偏导是向量，向量对向量的偏导是矩阵</li>
  <li>贝叶斯公式: P(A|B)P(B)=P(B|A)P(A)</li>
</ul>

<h1 id="2-线性神经网络">2. 线性神经网络</h1>
<p>本章主要介绍了线性回归网络和softmax回归网络，接下来是一些笔记</p>
<ul>
  <li>随机梯度下降和梯度下降的区别: 梯度下降一般而言是针对所有的样本而言，而随机梯度下降是针对单个样本而言，同样地，小批量随机梯度下降是针对一个批量的样本而言</li>
  <li>可以调整但是在训练过程中不更新的参数叫做超参数</li>
  <li>极大似然法: $\theta$是需要估计的值，在写似然函数时只需要把$\theta$看成参数，最大化似然函数即$\theta$的估计值</li>
  <li>每个输入与每个输出相连的层成为全连接层</li>
  <li>with torch.no_grad()的作用是让输出结果之后不构建计算图</li>
  <li>本章的训练过程: 计算y的预测值-&gt;计算损失函数-&gt;累加loss并反向传播(记得每个批量在梯度更新前需要清零梯度并反向传播loss)-&gt;更新参数</li>
  <li>训练过程中重要的组成部分: 数据迭代器、损失函数、优化器(updater/trainer)、网络(记得初始化参数)</li>
  <li>softmax为分类服务，softmax本质上是将输出规范成概率数值，方便选取预测概率最大的类作为预测类:</li>
</ul>

<center><img src="../assets/img/posts/20220905/4.jpg" /></center>

<ul>
  <li>分类的标签可以用独热编码定义</li>
  <li>网络模型用nn.sequential()定义</li>
  <li>softmax回归的损失函数可以用极大似然法推出，普通的极大似然法是最大化似然函数，但是在这里我们加上-log就变成了最小化损失函数</li>
  <li>softmax回归的损失函数是交叉熵损失:</li>
</ul>

<center><img src="../assets/img/posts/20220905/5.jpg" /></center>

<h1 id="3-多层感知机">3. 多层感知机</h1>
<p>本小节主要介绍了多层感知机的实现以及面对各种问题的解决方法，比如解决过拟合的权重衰退(weight decay)和暂退法(dropout)，解决梯度爆炸与消失的Xavier初始化。</p>
<ul>
  <li>激活函数的作用是将线性网络变成非线性，常见的有ReLU、Sigmoid、tanh</li>
  <li>ReLU: max(x, 0)</li>
  <li>Sigmoid: $\frac{1}{1+e^{-x}}$</li>
  <li>tanh: $\frac{1-e^{-2x}}{1+e^{-2x}}$</li>
  <li>在torch中可以用@来简单表示矩阵乘法</li>
  <li>用nn.Sequential()来实例化网络时，nn.ReLU()单独算一层</li>
  <li>过拟合问题可以用正则化技术解决，比如权重衰退</li>
  <li>权重衰退就是L2正则化，它在计算损失函数时增加了权重的惩罚项，比如L($\omega$, b)+$\frac{\lambda}{2}$||$\omega$||，其中$\lambda$是超参数</li>
  <li>torch框架中把权重衰退放在优化器的实例化中(torch.optim)，只需要将weight_decay的超参数输入即可</li>
  <li>暂退法(Dropout): 在前向传播中，计算每一内部层的同时注入噪音，就好像在训练过程中丢弃了一些神经元</li>
  <li>中间层活性值:</li>
</ul>

<center><img src="../assets/img/posts/20220905/6.jpg" /></center>

<ul>
  <li>只有在训练过程中才有权重衰退和暂退法</li>
  <li>在torch中简单实现dropout的方法: 在构建net时将nn.Dropout(dropout)加入nn.Sequential()，其中dropout作为丢弃概率输入Dropout中</li>
  <li>网络架构顺序: linear-&gt;relu-&gt;dropout</li>
  <li>torch中实现tensor对tensor求梯度的方法是在backward()里面加入torch.ones_like()</li>
  <li>不正常的参数初始化可能会导致梯度爆炸和梯度消失</li>
  <li>Xavier初始化是解决梯度爆炸和消失的好手段</li>
</ul>

<h1 id="5-卷积神经网络">5. 卷积神经网络</h1>
<p>这章主要介绍了CNN的基础知识，包括卷积计算以及汇聚层和简单的卷积神经网络LeNet</p>
<ul>
  <li>卷积运算即互相关运算，卷积核函数沿着输入矩阵滑动计算，一般的卷积层除了核运算外，还需要加上偏置</li>
</ul>

<center><img src="../assets/img/posts/20220905/7.jpg" /></center>

<ul>
  <li>二维卷积层的输入格式: (批量大小, 通道数, 高, 宽)，卷积层又被称为特征映射(feature map)</li>
  <li>感受野(Receptive Field)的定义是卷积神经网络每一层输出的特征图上的像素点在输入图片上映射的区域大小，也就是一个像素点对应的上一层图像的区域大小</li>
  <li>填充(padding)与步幅(stride):
    <ul>
      <li>填充的作用是在输入图像的边界填充元素(通常为0)，添加$p_h$行与$p_w$列，基本是一半在左一半在右</li>
      <li>一般在定义卷积层nn.Convd()时可以加上填充与步幅</li>
      <li>步幅包括垂直步幅$S_h$与水平步幅$S_w$</li>
      <li>在经过卷积层后，二维图像变成了$[(n_h - k_h + p_h + 1)/S_h, (n_w - k_w + p_w + 1)/S_w]$</li>
    </ul>
  </li>
  <li>多通道输入，只需把各通道输出结果加起来即可</li>
  <li>多通道输出，为每个输出通道创建一个卷积核函数$(c_i, k_h, k_w)$，假设输入通道个数$c_i$，输出通道个数为$c_o$，那么卷积核形状为$(c_o, c_i, k_h, k_w)$</li>
  <li>torch.stack(): 沿一个新维度对输入张量进行连接</li>
  <li>汇聚层(pooling)包括最大汇聚层和平均汇聚层，汇聚层是直接返回输入图像的一个小窗口的最大值或者平均值</li>
  <li>汇聚层没有可学习的参数</li>
  <li>汇聚层同样有填充与步幅，默认情况下步幅与窗口大小相同，nn.MaxPool2d()</li>
  <li>每个卷积块的基本单元是: 卷积层-&gt;激活函数-&gt;汇聚层</li>
  <li>nn.Conv2d(1, 6, kernel_size=5)其中1表示输入通道数，6表示输出通道数</li>
  <li>在CNN的最后都需要连接全连接层来变成预测类别</li>
  <li>在训练过程中如果想好好利用GPU，那么需要将网络的参数与数据集数据传入GPU，具体方法是net.to(device)、X,y.to(device)</li>
  <li>多输入多输出通道的图片示例:</li>
</ul>

<center><img src="../assets/img/posts/20220905/40.jpg" /></center>

<h1 id="6-现代卷积神经网络">6. 现代卷积神经网络</h1>
<p>这一节主要介绍了CNN的各种网络的发展历程，LeNet之后，于2012年出现深度CNN网络AlexNet，之后出现了NiN与VGG，然后是GoogleNet，之后有很大进步的网络是ResNet，直到现在，ResNet用的也很多，残差思想也持续影响后续模型的搭建</p>
<ul>
  <li>促进CV有更深的网络的两大关键因素: 数据与硬件(主要是GPU)</li>
  <li>AlexNet(深度卷积网络)于2012年ImageNet挑战赛上夺冠，第一次学习到的特征超越了手工设计的特征</li>
  <li>相比于LeNet而言，AlexNet更深、激活函数用ReLU、对训练数据进行了增广</li>
  <li>VGG(使用块的网络): VGG块由一系列卷积层(包含ReLU)+汇聚层组成，VGG网络由VGG块组成</li>
  <li>NiN(网络中的网络): NiN块结构是卷积层(含ReLU)+两个1x1卷积层(相当于全连接层)，NiN网络结构是: NiN块+汇聚层+NiN块+汇聚层+…+平均汇聚层</li>
  <li>GoogleNet(含并行连结的网络)是google花费了很多money实验出的网络，特点是参数值特殊，参数以及网络结构都是经过了很多实验得出的结果</li>
  <li>GoogleNet中基本的卷积块被称为Inception块，Inception块的架构如下图所示:</li>
</ul>
<center><img src="../assets/img/posts/20220905/41.jpg" /></center>
<ul>
  <li>GoogleNet架构: 卷积块+Inception块+最大汇聚层+Inception块+最大汇聚层+Inception块+平均汇聚层+全连接层</li>
  <li>批量规范化(Batch Normalization)是一种trick，可加速深层网络的收敛速度</li>
  <li>正则化在深度学习中非常重要</li>
  <li>对于一个批量来说，首先规范化输入(减去其均值并除以标准差)，再应用比例系数与比例偏移，就是对当前批量进行了批量规范化</li>
</ul>
<center><img src="../assets/img/posts/20220905/42.jpg" /></center>
<p>上述式子中x是输入，$\hat{\mu}_B$是这个批量的均值，$\hat{\sigma}_B$是批量的标准差，$\gamma$是比例系数，$\beta$是比例偏移，$\gamma$与$\beta$与x的形状相同，是需要学习的参数</p>
<ul>
  <li>应用于全连接层的BN: $h=\Phi(BN(Wx+b))$</li>
  <li>应用于卷积层的BN: 在每个输出通道的m*p*q个元素上同时执行BN</li>
  <li>可以发现，BN的作用位置为权重层后，激活函数前</li>
  <li>BN在训练和预测时有所不同，在预测时，直接使用模型传入的移动平均所得的均值与方差</li>
  <li>用pytorch架构简单实现BN: nn.BatchNorm2d(通道数)</li>
  <li>直观地说，BN可以使优化更加平滑</li>
  <li>残差网络ResNet于2015年在ImageNet上夺冠</li>
  <li>残差思想: 每个附加层都应该更容易地包含原始函数作为其元素之一，残差块不是为了学习输出f(x)，而是学习输出与输入的差别f(x)-x</li>
  <li>残差块的架构:</li>
</ul>
<center><img src="../assets/img/posts/20220905/43.jpg" /></center>
<ul>
  <li>ResNet的架构: 和GoogleNet很像，就是Inception变成了残差块，同时多了BN</li>
  <li>稠密链接网络DenseNet: 是ResNet的继承，DenseNet的输出是连结，而不是如ResNet那样的简单相加</li>
</ul>
<center><img src="../assets/img/posts/20220905/44.jpg" /></center>

<h1 id="7-循环神经网络">7. 循环神经网络</h1>
<p>这小节主要介绍了文本数据集如何制作，RNN的网络结构与实现</p>
<ul>
  <li>序列数据就是与时间相关的数据</li>
  <li>马尔可夫模型: 用定时间跨度的观测序列预测$x_t$</li>
  <li>$P(x_1,…,x_T)=\prod_{t=1}^TP(x_t|x_{t-1},…,x_{t-\tau})$</li>
  <li>一些名词: 文本序列、词元(token)、词表(vocabulary)、语料(corpus)</li>
  <li>文本预处理过程: 读取数据集成列表-&gt;将列表词元化，变成包含多行的词元列表-&gt;构建词表(词表将词元与数字对应)</li>
  <li>文本预处理中的词元可以是单词，也可以是字符，这里采用字符</li>
  <li>语言模型(language model)的目标是估计联合概率$P(x_1,…,x_T)$</li>
  <li>涉及一个、两个、三个变量的概率公式分别被称为一元语法、二元语法、三元语法</li>
  <li>zip()的作用是将可迭代对象打包成一个个元组，然后返回元组组成的列表</li>
  <li>构建文本序列数据集的两种方法:
    <ul>
      <li>随机采样: 随机选取，特征是原始序列，标签是原始序列右移一位</li>
      <li>顺序分区: 保证每个批量中子序列再原语料中相邻</li>
    </ul>
  </li>
  <li>相比与马尔可夫模型，隐变量模型更能体现过往序列的影响:
  $P(x_t|x_{t-1},…,x_1)=P(x_t|h_{t-1})$</li>
  <li>RNN的示意图以及推导公式:</li>
</ul>

<center><img src="../assets/img/posts/20220905/8.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20220905/9.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20220905/10.jpg" /></center>

<ul>
  <li>循环神经网络中循环的是H(Hidden state)</li>
  <li>度量语言模型的质量的性能度量是困惑度(perplexity): 一个序列中n个词元的交叉熵损失来衡量语言模型的质量</li>
</ul>

<center><img src="../assets/img/posts/20220905/11.jpg" /></center>

<ul>
  <li>最好的情况下，困惑度为1，最差的情况下，困惑度为无穷大</li>
  <li>独热编码将(批量大小, 时间步数)转变成(批量大小, 时间步数, 词表大小)，但为了方便计算，最终转变成(时间步数, 批量大小, 词表大小)</li>
  <li>梯度裁剪的作用是保证梯度不会爆炸</li>
</ul>

<center><img src="../assets/img/posts/20220905/12.jpg" /></center>

<ul>
  <li>RNN的网络结构与之前差别不大，只是在更新梯度前需要进行梯度裁剪</li>
  <li>隐藏状态形状: (隐藏层个数, 批量大小, 隐层参数个数)</li>
  <li>nn.RNN()返回的Y为隐层参数个数，需要再加上全连接层</li>
</ul>

<h1 id="8-现代循环神经网络">8. 现代循环神经网络</h1>
<p>这一章介绍了拥有记忆单元的LSTM模型，以及后续新的NLP任务机器翻译，介绍了数据集处理过程和编码器解码器结构的网络seq2seq，用来处理序列转换任务</p>
<ul>
  <li>长短期记忆网络LSTM(long short term memory)</li>
  <li>LSTM相较于普通的RNN多了很多元素，最主要的设计是记忆单元，它可以影响下一步的隐藏状态:</li>
</ul>

<center><img src="../assets/img/posts/20220905/13.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20220905/14.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20220905/15.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20220905/16.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20220905/17.jpg" /></center>
<p><br /></p>

<ul>
  <li>输入、输出、遗忘门均与$H_{t-1}$和$X_t$有关</li>
  <li>记忆单元C类似于隐状态，时时更新</li>
  <li>总的来说，LSTM中$H_t$与$H_{t-1}$、$X_t$、$C_t$都有关</li>
  <li>RNN的延伸: 多层与双向RNN，其中多层很好理解，就是把单向隐藏层的神经网络变成多层，双向的作用是让序列用到上下文信息，在预测下一个词元的任务中
双向RNN表现不佳，但是在NER中表现很好</li>
  <li>nn.LSTM(num_inputs, num_hiddens, num_layers)</li>
  <li>接下来的内容变成了机器翻译任务(序列转换)</li>
  <li>机器翻译中使用单词级词元化</li>
  <li>机器翻译数据集处理过程: 读取数据集-&gt;词元化列表-&gt;将数据集分割成source(源语言)与target(目标语言)-&gt;序列末端加上&lt;eos&gt;，同时针对长短不一的序列填充&lt;pad&gt;与截断</li>
  <li>处理序列转换任务可以用编码器-解码器结构</li>
  <li>编码器的作用是将长短可变序列变成固定形状的状态，解码器的作用是将固定形状的状态变成长度可变序列</li>
  <li>编码器为解码器输入一个状态，在seq2seq中是编码器编码过程中的隐状态，这个隐状态既作为解码器的初始state，在每个时间步中也作为上下文变量和输入concatenate之后一起输入解码器</li>
  <li>采用嵌入层将词元进行向量化，嵌入层是一个矩阵，(词表大小，特征向量维度)</li>
  <li>编码器与解码器是两个GRU</li>
  <li>permute()可以改变张量维度的位置</li>
  <li>rnn()的输入形状一般为(num_steps, batch_size, embed_size)</li>
  <li>解码器的最后同样需要一个全连接层输出</li>
  <li>解码器的第一个输入为&lt;bos&gt;</li>
  <li>由于序列存在很多&lt;pad&gt;，计算损失时不能计算pad那一部分，可以mask这一部分，所以损失函数需要重新改一下</li>
  <li>在seq2seq训练时，解码器net的输入为cat(&lt;bos&gt;，真实序列少一时间步)，这种训练机制叫做强制教学</li>
  <li>预测的时候解码器net的输入仅为&lt;bos&gt;，用每一步的预测作为下一步的输入</li>
  <li>机器翻译的性能度量为BLEU(bilingual evaluation understudy)，可用来预测输出序列的质量，当预测序列与标签序列完全相同时，BLEU为1，公式如下:</li>
</ul>

<center><img src="../assets/img/posts/20220905/18.jpg" /></center>

<ul>
  <li>编码器的功能主要是为解码器提供上下文变量c和解码器的初始隐状态</li>
</ul>

<h1 id="9-注意力机制">9. 注意力机制</h1>
<p>这章主要介绍了注意力机制，介绍了注意力机制的组成部分，比如查询、键、值、评分函数，后面又介绍了与RNN结合的Bahdanau注意力以及自注意力和多头注意力，最后介绍了transformer</p>
<ul>
  <li>注意力机制的主要成分是查询(query)、键(key)、值(value)，q和k交互形成注意力权重，然后与v相乘得到注意力汇聚结果</li>
</ul>

<center><img src="../assets/img/posts/20220905/19.jpg" /></center>

<ul>
  <li>注意力汇聚结果计算公式:</li>
</ul>

<center><img src="../assets/img/posts/20220905/20.jpg" /></center>

<p>其中x是查询，$x_i$是key，$y_i$是value，$\alpha$的作用是将x与$x_i$之间的关系建模，且权重总和为1，有点像softmax</p>

<ul>
  <li>unsqueeze()的作用是在指定位置添加一个维度，squeeze()的作用是在指定位置删除一个维度，torch.bmm()是批量矩阵乘法</li>
  <li>评分函数a同样是对q和k的关系进行建模，q、k、v都可以是向量，而且长度可以不同</li>
</ul>

<center><img src="../assets/img/posts/20220905/21.jpg" /></center>
<p><br /></p>
<center><img src="../assets/img/posts/20220905/22.jpg" /></center>
<p><br /></p>

<ul>
  <li>这里介绍了两种评分函数: 加性注意力和缩放点积注意力
    <ul>
      <li>加性注意力: 可以处理长度不同的q与k</li>
    </ul>

    <center><img src="../assets/img/posts/20220905/23.jpg" /></center>

    <ul>
      <li>缩放点积注意力(计算效率高): 要求q与k长度相同</li>
    </ul>

    <center><img src="../assets/img/posts/20220905/24.jpg" /></center>
  </li>
  <li>Bahdanau注意力模型也是编码器解码器结构，与之前的seq2seq不同，这里的上下文变量在解码器的每一步都不相同，上下文变量$c_{t’}$与解码器的上一步隐状态有关，同时在解码器和编码器的输入位置都有嵌入层</li>
</ul>

<center><img src="../assets/img/posts/20220905/25.jpg" /></center>

<ul>
  <li>多头注意力: 对q、k、v使用线性变换得到h组不同的q-k-v来输入h个注意力汇聚层，得到h个输出，这h个输出再线性变换得到最终输出</li>
</ul>

<center><img src="../assets/img/posts/20220905/26.jpg" /></center>

<ul>
  <li>自注意力就是q-k-v都是相同的一组元素</li>
  <li>自注意力无法使用序列的位置信息，可以给输入concatenate一个位置编码，比如X∈$R^{nxd}$表示n个词元的d维嵌入，P∈$R^{nxd}$表示位置嵌入矩阵，那么X+P即输入，位置编码可以基于正弦函数和余弦函数的固定位置编码</li>
</ul>

<center><img src="../assets/img/posts/20220905/27.jpg" /></center>

<ul>
  <li>transformer模型与Bahdanau模型不同，它完全基于注意力机制来构建模型</li>
  <li>transformer每块都由多头注意力和基于位置的前馈神经网络组成，其中还有残差连接，即x+sublayer(x)，再层规范化(层规范化和批量规范化类似，都是使得网络中每层输入数据的分布相对稳定，加速模型学习，批量规范化是一组输入数据对一个神经元而言，层规范化是一个输入数据对多个神经元而言)。在解码器的注意力层中，q是上个解码器层的输出，k和v是编码器输出(每个源序列的位置的编码代表一个键值对)。基于位置的前馈神经网络，简称ffn，即两层MLP</li>
</ul>

<center><img src="../assets/img/posts/20220905/28.jpg" /></center>

<h1 id="12-计算机视觉">12. 计算机视觉</h1>
<p>这一章主要介绍了计算机视觉领域的两大任务: 目标检测于语义分割。目标检测从boundingbox讲起，然后介绍如何生成锚框和锚框的标签，然后介绍了SSD、RCNN等实现目标检测的网络，语义分割主要介绍了定义以及网络，最后介绍了风格迁移的一种实现方法</p>
<ul>
  <li>就目前的趋势来说，数据集越大，模型的表现效果越好</li>
  <li>图像增广的作用是扩大数据集的规模，图像增广在对训练图像进行一系列的随机变换后，生成相似但不同的训练样本</li>
  <li>常见的图像增广的方法有两种:
    <ul>
      <li>翻转和裁剪: 降低模型对目标位置的敏感性</li>
      <li>改变颜色(这里指改变RGB): 亮度、饱和度、对比度</li>
    </ul>
  </li>
  <li>torchvision.transforms.RandomVerticalFlip() 上下翻转</li>
  <li>torchvision.transforms.RandomHorizontalFlip() 左右翻转</li>
  <li>torchvision.transforms.RandomResizedCrop() 裁剪，但最终的图片大小都相同</li>
  <li>torchvision.transforms.ColorJitter()</li>
  <li>微调(fine-tune)约等于迁移学习(transfer learning)，从源数据集学到的知识迁移到目标数据集</li>
  <li>源模型的输出层从头训练，其余层微调，技巧就是让输出层的学习率变大</li>
</ul>
<center><img src="../assets/img/posts/20220905/45.jpg" /></center>
<ul>
  <li>torchvision.datasets里包含很多常用的数据集</li>
  <li>torchvision.models里包含很多常用的模型和预训练模型</li>
  <li>数据集实例化后一般还需要load到内存中变成iterator</li>
  <li>图像分类只是基础的CV任务，接下来介绍新的CV任务: 目标检测</li>
  <li>目标检测(object detection/recognition): 不仅想知道类别，还想知道它们在图像中具体位置</li>
  <li>边界框(bounding box)有两种表示方法:
    <ul>
      <li>由矩形左上角及右下角的横纵坐标决定(corner表示法)</li>
      <li>用中心点+高宽表示(center表示法)</li>
    </ul>
  </li>
  <li>对于一张图像来说，左上角的点为原点，向右为x轴正方向，向下为y轴正方向</li>
  <li>锚框(anchor box): 为了预测目标位置，在输入图像中采样大量的区域，然后判断这些区域中是否包含感兴趣的目标，这些区域就是锚框</li>
  <li>这一节主要关注采样方法，也就是锚框的生成方法，以每个像素为中心，生成多个缩放比和宽高比的boundingbox，这些边界框被称为锚框</li>
  <li>torch.meshgrid()的作用是让输入的两个向量变成网格状矩阵，一个作为x轴坐标，另一个作为y轴坐标</li>
  <li>交互比IoU: 量化锚框与真实boundingbox的相似性，杰卡德系数的定义如下:</li>
</ul>

<center>$J(A, B)=\frac{\|A\cap B\|}{\|A\cup B\|}$</center>
<p><br />
对于两个bbox而言，将它们的杰卡德系数称为交互比IoU(intersection over union)</p>
<ul>
  <li>如何利用训练集中的标签标注锚框(标注锚框的类别和偏移量): 数据集中含有真实边界框的位置及类别，对于任意生成的锚框而言，可以利用真实边界框的信息去标注锚框，得到锚框的类别和偏移量(offset)，其中一种将真实边界框的类别分配给锚框的算法:</li>
</ul>
<center><img src="../assets/img/posts/20220905/46.jpg" /></center>
<p>简单来说就是先找IoU值最大的一组真实边界框和锚框，然后删除它的行和列，直到真实边界框分配完，然后遍历没有分配的锚框的行，找到IoU最大的真实边界框，然后判断是否大于阈值，只有大于阈值时，才将真实边界框分配给该锚框</p>
<ul>
  <li>除了显而易见的锚框的类别，还需要标注锚框的偏移量，偏移量即该锚框与真实边界框的偏移，可以用下面这个式子来表示:</li>
</ul>
<center><img src="../assets/img/posts/20220905/47.jpg" /></center>
<p>其中$\mu$和$\sigma$都是常量</p>
<ul>
  <li>如果一个锚框没有被分配真实边界框，则将它标记为background(即负类锚框)</li>
  <li>在生成锚框的时候，还会返回掩码，掩码的作用是去掉不关心的负类锚框的偏移量</li>
  <li>当有许多锚框时，会输出许多相似但有明显重叠的预测边界框，为了简化计算，用非极大值抑制(non-maxmum suppression, NMS)来合并属于同一目标的类似预测边界框。对于一个预测边界框B，目标检测模型会计算每个类别的预测概率。假设最大的预测概率为p，则该概率所对应的类别B即为预测的类别。具体来说，我们将p称为预测边界框B的置信度(confidence)。在同一张图像中，所有预测的非背景边界框都按置信度降序排序，以生成列表L。然后我们通过以下步骤操作排序列表L:
    <ul>
      <li>从L中选取置信度最高的预测边界框$B_1$作为基准，然后将所有与$B_1$的IoU超过预定阈值$\epsilon$的非基准预测边界框从L中移除。这时，L保留了置信度最高的预测边界框，去除了与其太过相似的其他预测边界框。简而言之，那些具有非极大值置信度的边界框被抑制了</li>
      <li>从L中选取置信度第二高的预测边界框$B_2$作为又一个基准，然后将所有与$B_2$的IoU大于$\epsilon$的非基准预测边界框从L中移除</li>
      <li>重复上述过程，直到L中的所有预测边界框都曾被用作基准。此时，L中任意一对预测边界框的IoU都小于阈值$\epsilon$；因此，没有一对边界框过于相似</li>
      <li>输出列表L中的所有预测边界框</li>
    </ul>
  </li>
  <li>由于逐个像素生成锚框太多了，可以有针对性地多尺度生成锚框，检测较小物体时，用小锚框，采样更多的区域，检测较大物体时，用大锚框，采样更少的区域</li>
  <li>目标检测数据集领域里，没有小型数据集，所以李沐团队自行标注了1000张大小角度不同的banana图像，然后在一些背景图片上的随机位置放一张香蕉的图片，然后为这些图像标记边界框和类别</li>
  <li>batch[0]图片(x): (批量大小，通道数，h，w)</li>
  <li>batch[1]标签(y): (批量大小，m，5)</li>
  <li>上面式子中m表示所有图片中最多可能出现的锚框数，如果一张图片的锚框数少于m个，用非法锚框填充(类别为-1)</li>
  <li>5表示边界框的信息，分别为类别, $x_min$, $y_min$, $x_max$, $y_max$</li>
  <li>单发多框检测SSD(single-shot detection)的模型如下图所示:</li>
</ul>
<center><img src="../assets/img/posts/20220905/48.jpg" /></center>
<ul>
  <li>模型由基础网络(比如VGG、ResNet等等)和多尺度特征块组成，基础网络的输出将高宽扩大，这样就可以生成更多的锚框(可用于检测尺寸较小的物体)，然后后续的多尺度特征块将高宽缩小，这样便可以实现多尺度的目标检测，每一层都预测每个锚框的类别与offset，接下来介绍一下类别预测层和offset预测层
    <ul>
      <li>类别预测层: 用卷积层的通道来输出类别预测的方法，比如一个特征图像素上有a个锚框，则输出a(q+1)个通道</li>
      <li>offset预测层: 与类别预测层的设计思路类似，但每个锚框预测4个偏移量</li>
    </ul>
  </li>
  <li>可以通过合并多个通道的预测来实现不同尺度预测的简化</li>
  <li>网络记录每个块的前向输出Y，生成的锚框anchors以及类别预测结果cls(Y)，offset预测bbox(Y)，最后合并不同层的anchors(Y)、cls(Y)、bbox(Y)</li>
  <li>这个网络的损失函数为: 有关锚框类别的损失(用交叉熵)，有关正类偏移量的损失(回归问题，用L1范数损失)，掩码变量可以让负类锚框与填充锚框不参与计算</li>
  <li>训练时，真实值来源于Y的标签信息为每个锚框生成的类别和offset，然后用预测出来的锚框的类别和offset进行损失函数的计算</li>
  <li>预测阶段，输入x，得到anchors，cls_pred，bbox_pred，然后用NMS来去掉相似的锚框，得到最终的预测结果，output的形状: (批量大小, 锚框个数, 6)，6代表类别、概率、bbox的四个坐标</li>
  <li>接下来介绍目标检测的另一类算法: 区域卷积神经网络R-CNN系列(Region-based CNN)，模型如下图所示:</li>
</ul>
<center><img src="../assets/img/posts/20220905/49.jpg" /></center>
<ul>
  <li>RCNN的四个步骤:
    <ol>
      <li>对输入图像选取多个高质量的提议区域，标注其类别和真实bbox</li>
      <li>选择一个预训练的卷积神经网络，并将其在输出层之前截断。将每个提议区域变形为网络需要的输入尺寸，并通过前向传播输出抽取的提议区域特征</li>
      <li>将每个提议区域的特征连同其标注的类别作为一个样本。训练多个支持向量机对目标分类，其中每个支持向量机用来判断样本是否属于某一个类别</li>
      <li>将每个提议区域的特征连同其标注的边界框作为一个样本，训练线性回归模型来预测真实边界框</li>
    </ol>
  </li>
  <li>庞大的计算量使R-CNN在现实中难以广泛应用，于是出现了Fast R-CNN:</li>
</ul>
<center><img src="../assets/img/posts/20220905/50.jpg" /></center>
<p>与R-CNN的区别在于，Fast R-CNN在整张图上执行CNN前向传播来抽取特征</p>
<ul>
  <li>还有Faster R-CNN:</li>
</ul>
<center><img src="../assets/img/posts/20220905/51.jpg" /></center>
<p>与Fast R-CNN区别在于: 将选择性搜索替换成区域提议网络</p>
<ul>
  <li>接下来介绍语义分割任务: 语义分割(semantic segmentation)就是将图像分割成属于不同语义类别的区域(像素级)</li>
  <li>语义分割数据集: Pascal VOC 2012
    <ul>
      <li>feature x: 图像</li>
      <li>label y: 尺寸与图像相同，但是每个像素的RGB值表示它们所属的类别，类别相同的颜色也相同</li>
    </ul>
  </li>
  <li>转置卷积(上采样): 与卷积核运算相反(卷积核运算是用核窗口滑动输入图像)</li>
</ul>
<center><img src="../assets/img/posts/20220905/52.jpg" /></center>
<p>转置卷积是输入图像的每个像素的核函数上滑动，而卷积核运算时用核窗口在输入图像上滑动，转置卷积相当于使图像的高宽变大</p>
<ul>
  <li>转置卷积可以通过nn.ConvTranspose2d()简单实现</li>
  <li>接下来介绍解决语义分割的网络: 全卷积网络(fully convolutional network, FCN)</li>
  <li>语义分割本质上就是对图像的每个像素进行分类，FCN实现了像素到像素的变换，FCN将中间层特征图的高宽变换回输入图像的尺寸(用转置卷积实现)，输出的类别预测与输入图像在像素级别上有一一对应的关系</li>
  <li>FCN模型结构如下图:</li>
</ul>
<center><img src="../assets/img/posts/20220905/53.jpg" /></center>
<p>FCN先用卷积神经网络(可以用ResNet)抽取图像特征，然后通过1x1卷积层将通道变换为类别个数，最后通过转置卷积将特征图的高宽变换为输入图像的尺寸</p>
<ul>
  <li>转置卷积是一种上采样(upsampling)方法，双线性插值也是上采样方法之一，可以用转置卷积实现双线性插值(通过改变核函数)</li>
  <li>风格迁移(style transfer): 将一个图像中的风格应用于另一个图像上，即风格迁移，输入是一张内容图像(content)和一张风格图像(style)</li>
</ul>
<center><img src="../assets/img/posts/20220905/54.jpg" /></center>
<p>从content中用预训练模型抽取图像的内容特征(不更新参数)，从style图像中抽取风格特征，损失函数的设计很有意思</p>

<h1 id="13-自然语言处理-预训练">13. 自然语言处理: 预训练</h1>
<p>这一章主要介绍了NLP领域的预训练模型，NLP领域的预训练模型都是encoder，即用文本特征来表示词元(一般都是单词)，首先介绍了word2vec，然后介绍了全局向量的词嵌入，之后介绍了子词嵌入模型fastText与字节对编码(BPE)，之后介绍了BERT(双向Transformer编码器)</p>
<ul>
  <li>在介绍RNN模型时，介绍了用独热向量来表示词元，但是这有个很严重的缺点: 不同词的独热向量的余弦相似度为0。所以接下来会介绍很多词嵌入模型，即用一个词向量来表示单词</li>
  <li>word2vec: 将词映射到固定长度的向量，这里介绍了两种模型: 跳元模型(skip-gram)与连续词袋CBOW
    <ul>
      <li>跳元模型: 假设一个词可以用来在文本序列中生成其周围的词，对于每个索引为i的单词，可以用$u_i$与$v_i$分别表示其作为上下文词和中心词的向量，可以用softmax对生成概率进行建模，对于给定中心词$w_c$，生成上下文词$w_o$的概率为:</li>
    </ul>

    <center><img src="../assets/img/posts/20220905/29.jpg" /></center>

    <p>那么跳元模型的似然函数为(上下文窗口大小为m):</p>

    <center><img src="../assets/img/posts/20220905/30.jpg" /></center>

    <p>然后通过极大似然估计法来训练</p>
    <ul>
      <li>连续词袋: 与跳元模型相反，CBOW是基于上下文词生成中心词，连续词袋模型用$v_i$和$u_i$分别表示一个词的上下文词向量与中心词向量(与跳元模型相反)，同样用softmax建模(上下文词向量相加):</li>
    </ul>

    <center><img src="../assets/img/posts/20220905/31.jpg" /></center>

    <p>连续词袋模型的似然函数:</p>

    <center><img src="../assets/img/posts/20220905/32.jpg" /></center>
  </li>
  <li>由于词表过大，使用softmax来建模的话计算成本过大，可采用两种近似训练办法来优化: 负采样与分层softmax
    <ul>
      <li>负采样建模: 直接用内积加上激活函数来表示概率，负采样即在似然函数中加上负例(从预定义分布中采样噪声词)</li>
    </ul>

    <center><img src="../assets/img/posts/20220905/33.jpg" /></center>

    <ul>
      <li>层序softmax: 用二叉树来表示概率模型，同样使用了激活函数sigmoid，时间复杂度变低</li>
    </ul>
  </li>
  <li>接下来用负采样跳元模型训练(自监督训练)来展示word2vec的效果，数据集用PTB，语料库取自华尔街时报。数据集处理时用到了下采样方法: 高频词有概率被丢弃:</li>
</ul>

<center><img src="../assets/img/posts/20220905/34.jpg" /></center>

<p>上述式子中f($w_i$)是词在整个语料库中出现的比率，t是超参数。这样高频词就不会太影响模型效果，毕竟不太关注类似a和the与其他词共同出现的概率</p>
<ul>
  <li>在下采样与负采样完毕后，一个小批量中第i个样本包括中心词及其$n_i$个上下文词和$m_i$个噪声词，数据集还需要返回mask与label，分别用来遮掩&lt;pad&gt;与标记正例</li>
  <li>word2vec本质上其实是训练一个权重矩阵(词表大小, 嵌入维度)，就是一个nn.Embedding()。跳元模型的前向传播就是计算内积矩阵torch.bmm(embed_v, embed_u)
损失函数是带掩码的交叉熵损失</li>
  <li>跳元模型在预训练完毕后，可以用来找出语义相似的单词，即计算中心词与其余所有词的余弦相似度，计算结果最高的词即为语义最相似的单词</li>
  <li>无论是word2vec的哪个模型，都着眼于中心词与上下文词的关系</li>
  <li>全局向量的词嵌入GloVe: word2vec只考虑了局部的上下文词，GloVe则考虑了全局语料库统计来设计模型，训练GloVe是为了降低以下损失函数:</li>
</ul>

<center><img src="../assets/img/posts/20220905/35.jpg" /></center>

<p>上述式子中，$x_{ij}$是中心词i与上下文词j在一个上下文窗口出现的次数，h($x_{ij}$)是每个损失项的权重，当x小于c时，h(x)=$\frac{x}{c}^\alpha$，当x大于c时h(x)=1，$b_i$与$c_j$是可学习的偏置</p>
<ul>
  <li>子词嵌入模型: 对词的内部结构进行研究(比如dog和dogs的关系)
    <ul>
      <li>fastText模型: 每个中心词由其子词的向量之和表示(子词就是单词的某些连续字符)</li>
    </ul>

    <center><img src="../assets/img/posts/20220905/36.jpg" /></center>

    <p>其余部分与跳元模型相同</p>
    <ul>
      <li>字节对编码(Byte Pair Encoding, BPE): 一种算法，用来提取子词。BPE的本质就是对训练数据集进行统计分析，找出单词的公共符号，这些公共符号将作为划分子词的依据，对于每个单词，都将返回最长的子词划分结果(这样就可以获得任意长度的子词)</li>
    </ul>
  </li>
  <li>从大型语料库中训练的词向量可用于下游的自然语言处理任务，预训练的词向量可应用到词的类比性和相似性任务中，比如GloVe和fastText</li>
  <li>torch.topk(k)的作用是返回列表中的最大值(前k个)</li>
  <li>词相似: 利用余弦相似度</li>
  <li>词类比: a:b::c:d，比如man:woman::son:daughter，词类比任务就是给出a、b、c，找到d，即让d的词向量尽量靠近vec(c)+vec(b)-vec(a)</li>
  <li>word2vec于GloVe都是上下文无关的，即对于一个词元编码，只需要输入该词元即可</li>
  <li>NLP的六种任务: 情感分析、自然语言推断、语义角色标注、共指消解，NER和QA</li>
  <li>GPT的缺点: 自回归，单向</li>
  <li>BERT使用双向Transformer编码器来编码文本，BERT同样是预训练模型，可以基于双向上下文来表示任意词元</li>
  <li>针对不同的上下文任务，BERT需要对架构进行微调</li>
  <li>BERT可输入单个文本，也可以输入文本序列对，当输入单个文本时，BERT的输入序列是&lt;cls&gt;文本&lt;sep&gt;；当输入文本对时，BERT的输入序列是&lt;cls&gt;文本1&lt;sep&gt;文本2&lt;sep&gt;</li>
  <li>在BERT中，有三个嵌入层，分别是词元嵌入(普通的embedding)、段嵌入(两个片段序列的输入，用来区分不同的句子)和位置嵌入(可学习)，之后再把结果输入encoder中</li>
</ul>

<center><img src="../assets/img/posts/20220905/37.jpg" /></center>

<ul>
  <li>BERT通过两个预训练任务来优化双向Transformer编码器，分别是掩蔽语言模型(masked language modeling 即填空)和下一句预测(next sentence predicition)
    <ul>
      <li>掩遮语言模型: 随机掩蔽词元并使用来自双向上下文的词元以自监督的方式预测掩蔽词元。预测阶段使用单隐藏层的MLP来进行预测，输入BERT的编码结果和用于预测词元的位置，然后根据预测词元的位置得到预测词元的编码结果，然后输入mlp中得到预测结果</li>
      <li>下一句预测: 二分类任务，判断文本序列对是否是连续句子，预测时同样使用MLP，输入编码后的&lt;cls&gt;词元</li>
      <li>这两个任务在制作数据集的时候都需要加上一些负例或者噪声</li>
    </ul>
  </li>
  <li>BERT的预训练数据集有很多(针对不同的应用领域，使用不同的数据集进行训练)，最开始使用的是图书语料库和wiki</li>
  <li>BERT本质上就是一个双向Transformer编码器</li>
</ul>

<h1 id="14-自然语言处理-应用">14. 自然语言处理: 应用</h1>
<p>这一章主要介绍了如何将自然语言预处理模型应用到下游任务中，首先是传统的GloVe模型和子词嵌入模型，针对这种预训练模型，需要设计特定的网络结构在适配任务，但是BERT的出现，让下游任务应用更简单，有时候只需要加一个全连接层就行，参数也只需要微调，这一章主要介绍了两个下游任务，分别是情感分析和自然语言推断</p>
<ul>
  <li>情感分析任务(sentiment analysis): 本质上就是文本序列分类任务，数据集采用Imdb的电影评论集(评论+情感)</li>
  <li>处理长短不一的序列时，使用截断与填充来预处理数据集，可以将其变成长短一致的序列</li>
  <li>一般的预训练模型应用于下游任务的方式都是: 预训练模型(词元的文本表示embed)+架构(网络)+应用(各种任务)</li>
</ul>

<center><img src="../assets/img/posts/20220905/38.jpg" /></center>

<ul>
  <li>这里介绍了两种非BERT的架构，分别是用双向LSTM和CNN来处理情感分析任务:
    <ul>
      <li>双向LSTM: 双向LSTM的初始与最终步的隐状态连结起来作为文本序列的表示，然后连接一个全连接层，输出</li>
      <li>CNN: 这里使用了一种名为textCNN的网络架构，把文本序列看成一维图像进行处理，采用一维卷积来获得局部特征</li>
      <li>一维卷积是二维卷积的一个特例，同样是核函数沿着输入滑动。多通道输入的一维互相关等同于单输入通道的二维互相关</li>
    </ul>

    <center><img src="../assets/img/posts/20220905/39.jpg" /></center>
  </li>
  <li>自然语言推断(nature language inference, NLI)任务是文本对分类任务，对文本对进行判断，决定一个句子能否由另一个句子推断出，即假设(hypothesis)能否由前提(premise)推出</li>
  <li>两个句子的三种关系:
    <ul>
      <li>蕴涵(entailment): 假设可以从前提推出</li>
      <li>矛盾(contradiction): 假设的否定可以从前提推出(我感觉本质上就是假设不能由前提推出)</li>
      <li>中性(neutral): 所有其他的情况</li>
    </ul>
  </li>
  <li>NLI使用的数据集是斯坦福自然语言推断数据集(SNLI)</li>
  <li>接下来介绍两种进行NLI的方法，分别是使用注意力机制(包含MLP)和BERT微调:
    <ul>
      <li>使用注意力机制: 利用注意力机制将两个文本序列的词元对齐，然后比较、聚合这些信息，那么本质上就是三个步骤：注意、比较、聚合:
        <ul>
          <li>注意: 与attention机制类似</li>
          <li>比较: 比较软对齐的hypothesis与premise相比较</li>
          <li>聚合: 将比较结果concat之后送入mlp</li>
          <li>这中间涉及到很多mlp层</li>
        </ul>
      </li>
      <li>另一种方法就是利用BERT进行微调，后面会具体介绍</li>
    </ul>
  </li>
  <li>这种使用非BERT的应用都是将嵌入层的权重替换成预训练模型的权重</li>
  <li>BERT可处理的一些下游任务:
    <ul>
      <li>单文本分类(比如情感分析、句子在语法上是否可接受)</li>
      <li>文本对分类/回归(NLI、语义文本相似度)</li>
      <li>词元级任务: 比如文本标注(每个词元经过相同的全连接层后，返回词性标签)、问答(QA, 使用数据集SQuAD，给定段落与问题后，预测用段落的哪个片段进行回答(也即文本片段的开始与结束位置的预测))</li>
    </ul>
  </li>
  <li>加载bert模型时，可以将预训练好的参数直接放到定义好的网络架构中</li>
  <li>之前很多预训练模型在处理下游任务时，都需要为下游任务设定特定的框架，但是BERT却并不需要设置特定的框架，有时只需要添加一个额外的全连接层即可</li>
  <li>微调只更新部分参数</li>
</ul>]]></content><author><name>Quehry</name></author><category term="note" /><summary type="html"><![CDATA[d2l note]]></summary></entry><entry><title type="html">Web速成</title><link href="http://localhost:4000/Web%E9%80%9F%E6%88%90.html" rel="alternate" type="text/html" title="Web速成" /><published>2022-08-03T00:00:00+08:00</published><updated>2022-08-03T00:00:00+08:00</updated><id>http://localhost:4000/Web%E9%80%9F%E6%88%90</id><content type="html" xml:base="http://localhost:4000/Web%E9%80%9F%E6%88%90.html"><![CDATA[<h1 id="1-html学习">1. HTML学习</h1>

<center><img src="../assets/img/posts/20220803/2.jpg" /></center>
<p><br /></p>

<center><img src="../assets/img/posts/20220803/3.jpg" /></center>
<p><br /></p>

<center><img src="../assets/img/posts/20220803/4.jpg" /></center>

<h1 id="2-css学习">2. CSS学习</h1>

<center><img src="../assets/img/posts/20220803/5.jpg" /></center>
<p><br /></p>

<center><img src="../assets/img/posts/20220803/6.jpg" /></center>
<p><br /></p>

<center><img src="../assets/img/posts/20220803/7.jpg" /></center>
<p><br /></p>

<center><img src="../assets/img/posts/20220803/8.jpg" /></center>
<p><br /></p>

<center><img src="../assets/img/posts/20220803/9.jpg" /></center>
<p><br /></p>

<h1 id="3-js学习">3. JS学习</h1>
<center><img src="../assets/img/posts/20220803/10.jpg" /></center>
<p><br /></p>

<center><img src="../assets/img/posts/20220803/11.jpg" /></center>
<p><br /></p>]]></content><author><name>Quehry</name></author><category term="note" /><summary type="html"><![CDATA[速成HTML、CSS、JS]]></summary></entry></feed>