<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-12-21T15:59:17+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Quehry</title><subtitle>Artificial Intelligence trends and concepts made easy.</subtitle><author><name>Quehry</name></author><entry><title type="html">计算机图形学</title><link href="http://localhost:4000/Computer_Graphics.html" rel="alternate" type="text/html" title="计算机图形学" /><published>2021-12-21T00:00:00+08:00</published><updated>2021-12-21T00:00:00+08:00</updated><id>http://localhost:4000/Computer_Graphics</id><content type="html" xml:base="http://localhost:4000/Computer_Graphics.html">&lt;h1 id=&quot;计算机图形学&quot;&gt;计算机图形学&lt;/h1&gt;
&lt;h2 id=&quot;lecture-01-overview-of-computer-graphics&quot;&gt;Lecture 01 Overview of Computer Graphics&lt;/h2&gt;
&lt;h3 id=&quot;什么是好的画面&quot;&gt;什么是好的画面&lt;/h3&gt;
&lt;p&gt;画面&lt;strong&gt;亮&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;应用场景&quot;&gt;应用场景&lt;/h3&gt;
&lt;p&gt;电影，游戏，动画，设计，可视化，虚拟现实，增强现实，模拟，GUI图形用户接口。&lt;/p&gt;

&lt;p&gt;电影中里程碑：阿凡达，大量应用面部捕捉技术。&lt;/p&gt;
&lt;h3 id=&quot;rasterization-光栅化&quot;&gt;Rasterization 光栅化&lt;/h3&gt;
&lt;p&gt;实时，FPS&amp;gt;30&lt;/p&gt;

&lt;p&gt;离线, FPS&amp;lt;30&lt;/p&gt;
&lt;h3 id=&quot;计算机视觉&quot;&gt;计算机视觉&lt;/h3&gt;
&lt;p&gt;计算机图形学离不开计算机视觉，但是视觉一般是对图像的处理。&lt;/p&gt;</content><author><name>Quehry</name></author><category term="note" /><summary type="html">计算机图形学 Lecture 01 Overview of Computer Graphics 什么是好的画面 画面亮 应用场景 电影，游戏，动画，设计，可视化，虚拟现实，增强现实，模拟，GUI图形用户接口。</summary></entry><entry><title type="html">制作类RACE数据集</title><link href="http://localhost:4000/RACElike-datasets.html" rel="alternate" type="text/html" title="制作类RACE数据集" /><published>2021-12-21T00:00:00+08:00</published><updated>2021-12-21T00:00:00+08:00</updated><id>http://localhost:4000/RACElike-datasets</id><content type="html" xml:base="http://localhost:4000/RACElike-datasets.html">&lt;h1 id=&quot;自制类race数据集&quot;&gt;自制类RACE数据集&lt;/h1&gt;
&lt;h2 id=&quot;race数据集&quot;&gt;RACE数据集&lt;/h2&gt;
&lt;p&gt;RACE数据集包含了中国初高中阅读理解题目，最初发布在2017年，一共含有28k短文和100k个问题，最开始发布的目的是为了&lt;strong&gt;阅读理解&lt;/strong&gt;任务。它的特点是包含了&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;原RACE数据集&lt;a href=&quot;http://www.cs.cmu.edu/~glai1/data/race/&quot;&gt;地址&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;下载地址&lt;a href=&quot;http://www.cs.cmu.edu/~glai1/data/race/RACE.tar.gz&quot;&gt;url&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;论文地址：&lt;a href=&quot;https://arxiv.org/abs/1704.04683&quot;&gt;RACE: Large-scale ReAding Comprehension Dataset From Examinations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;race数据集格式&quot;&gt;RACE数据集格式&lt;/h2&gt;
&lt;p&gt;Each passage is a JSON file. The JSON file contains following fields:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;article: A string, which is the passage.&lt;/li&gt;
  &lt;li&gt;questions: A string list. Each string is a query. We have two types of questions. First one is an interrogative sentence. Another one has a placeholder, which is represented by _.&lt;/li&gt;
  &lt;li&gt;options: A list of the options list. Each options list contains 4 strings, which are the candidate option.&lt;/li&gt;
  &lt;li&gt;answers: A list contains the golden label of each query.&lt;/li&gt;
  &lt;li&gt;id: Each passage has a unique id in this dataset.&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Quehry</name></author><category term="work" /><summary type="html">自制类RACE数据集 RACE数据集 RACE数据集包含了中国初高中阅读理解题目，最初发布在2017年，一共含有28k短文和100k个问题，最开始发布的目的是为了阅读理解任务。它的特点是包含了</summary></entry><entry><title type="html">推荐系统</title><link href="http://localhost:4000/Recommender_system.html" rel="alternate" type="text/html" title="推荐系统" /><published>2021-12-16T00:00:00+08:00</published><updated>2021-12-16T00:00:00+08:00</updated><id>http://localhost:4000/Recommender_system</id><content type="html" xml:base="http://localhost:4000/Recommender_system.html">&lt;h1 id=&quot;推荐系统&quot;&gt;推荐系统&lt;/h1&gt;
&lt;h2 id=&quot;1矩阵分解-matrix-factorization&quot;&gt;1.矩阵分解 Matrix Factorization&lt;/h2&gt;
&lt;h3 id=&quot;11-the-matrix-factorization-model&quot;&gt;1.1 The Matrix Factorization Model&lt;/h3&gt;
&lt;p&gt;R是user-item矩阵，行数是用户数量，列数是物品数量,那么R∈R&lt;sup&gt;mxn&lt;/sup&gt;。P是user latent matrix，P∈R&lt;sup&gt;mxk&lt;/sup&gt;，Q是item latent matrix，Q∈R&lt;sup&gt;nxk&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;矩阵分解就是把R分解成P和Q，那么预测的评分就是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211216/2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是上面这个式子没有考虑偏置，我们会有下面这个完整的式子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211216/3.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么&lt;strong&gt;目标函数&lt;/strong&gt;可以定义为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211216/4.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;右边那一串是正则项，为了避免过拟合&lt;/p&gt;

&lt;p&gt;下面这张图值观的展示了矩阵分解过程：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211216/5.jpg&quot; /&gt;&lt;/p&gt;</content><author><name>Quehry</name></author><category term="note" /><summary type="html">推荐系统 1.矩阵分解 Matrix Factorization 1.1 The Matrix Factorization Model R是user-item矩阵，行数是用户数量，列数是物品数量,那么R∈Rmxn。P是user latent matrix，P∈Rmxk，Q是item latent matrix，Q∈Rnxk</summary></entry><entry><title type="html">Robotics</title><link href="http://localhost:4000/Robotics.html" rel="alternate" type="text/html" title="Robotics" /><published>2021-12-13T00:00:00+08:00</published><updated>2021-12-13T00:00:00+08:00</updated><id>http://localhost:4000/Robotics</id><content type="html" xml:base="http://localhost:4000/Robotics.html">&lt;h1 id=&quot;报告&quot;&gt;报告&lt;/h1&gt;
&lt;h2 id=&quot;报告内容&quot;&gt;报告内容&lt;/h2&gt;
&lt;p&gt;用solidworks设计一个至少三个自由度的机械臂，并且描述它的动能，移动能力等等。提交的是截图，源文件等等。&lt;/p&gt;
&lt;h2 id=&quot;报告格式&quot;&gt;报告格式&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;标题，下面有姓名学号电话等等&lt;/li&gt;
  &lt;li&gt;摘要&lt;/li&gt;
  &lt;li&gt;正文&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Quehry</name></author><category term="note" /><summary type="html">报告 报告内容 用solidworks设计一个至少三个自由度的机械臂，并且描述它的动能，移动能力等等。提交的是截图，源文件等等。 报告格式 标题，下面有姓名学号电话等等 摘要 正文</summary></entry><entry><title type="html">数据挖掘</title><link href="http://localhost:4000/datamining.html" rel="alternate" type="text/html" title="数据挖掘" /><published>2021-12-10T00:00:00+08:00</published><updated>2021-12-10T00:00:00+08:00</updated><id>http://localhost:4000/datamining</id><content type="html" xml:base="http://localhost:4000/datamining.html">&lt;!-- TOC --&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#总体情况&quot;&gt;总体情况&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#第一章-开始数据挖掘之旅&quot;&gt;第一章 开始数据挖掘之旅&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#11-亲和性分析&quot;&gt;1.1 亲和性分析&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#12-分类&quot;&gt;1.2 分类&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#第二章-用scikit-learn估计器分类&quot;&gt;第二章 用scikit-learn估计器分类&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#21-scikit-learn&quot;&gt;2.1 scikit-learn&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#22-邻近算法knn&quot;&gt;2.2 邻近算法KNN&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#第三章-用决策树预测获胜球队&quot;&gt;第三章 用决策树预测获胜球队&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#31-决策树&quot;&gt;3.1 决策树&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#32-随机森林&quot;&gt;3.2 随机森林&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#第四章-用亲和性分析方法推荐电影&quot;&gt;第四章 用亲和性分析方法推荐电影&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#41-亲和性分析&quot;&gt;4.1 亲和性分析&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#42-apriori算法&quot;&gt;4.2 Apriori算法&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#第五章-用转换器抽取特征&quot;&gt;第五章 用转换器抽取特征&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#51-抽取特征&quot;&gt;5.1 抽取特征&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#52-特征选择&quot;&gt;5.2 特征选择&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#53-创建特征&quot;&gt;5.3 创建特征&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#第六章-使用朴素贝叶斯进行社会媒体挖掘&quot;&gt;第六章 使用朴素贝叶斯进行社会媒体挖掘&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#61-消歧&quot;&gt;6.1 消歧&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#62-文本转换器&quot;&gt;6.2 文本转换器&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#63-朴素贝叶斯&quot;&gt;6.3 朴素贝叶斯&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#64-f1值&quot;&gt;6.4 F1值&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#第九章-作者归属问题&quot;&gt;第九章 作者归属问题&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#91-作者归属&quot;&gt;9.1 作者归属&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#92-支持向量机&quot;&gt;9.2 支持向量机&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#93-基础svm的局限性&quot;&gt;9.3 基础SVM的局限性&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#第十章-新闻语料分类&quot;&gt;第十章 新闻语料分类&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#101-新闻语料聚类&quot;&gt;10.1 新闻语料聚类&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#102-k-means算法&quot;&gt;10.2 K-means算法&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;!-- /TOC --&gt;

&lt;h1 id=&quot;总体情况&quot;&gt;总体情况&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;书籍:Python数据挖掘入门与实践&lt;/li&gt;
  &lt;li&gt;github_url:https://github.com/LinXueyuanStdio/PythonDataMining&lt;/li&gt;
  &lt;li&gt;配套代码和笔记，很适合迅速上手&lt;/li&gt;
  &lt;li&gt;这篇博客主要记录一些比较重要的算法&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;第一章-开始数据挖掘之旅&quot;&gt;第一章 开始数据挖掘之旅&lt;/h2&gt;
&lt;h3 id=&quot;11-亲和性分析&quot;&gt;1.1 亲和性分析&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;亲和性分析根据样本个体（物体）之间的&lt;strong&gt;相似度&lt;/strong&gt;，确定它们关系的亲疏。&lt;/li&gt;
  &lt;li&gt;例子：商品推荐。&lt;/li&gt;
  &lt;li&gt;我们要找出“如果顾客购买了商品X，那么他们可能愿意购买商品Y”这样的规则。简单粗暴的做法是，找出数据集中所有同时购买的两件商品。找出规则后，还需要判断其优劣，我们挑好的规则用。&lt;/li&gt;
  &lt;li&gt;规则的优劣有多种判断标准，常用的有支持度(support)和置信度(confidence)&lt;/li&gt;
  &lt;li&gt;支持度：数据集中规则应验的次数，统计起来很简单。有时候，还需要对支持度进行规范化，即再除以规则有效前提下的总数量。&lt;/li&gt;
  &lt;li&gt;置信度是衡量规则的准确性如何。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;12-分类&quot;&gt;1.2 分类&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;根据特征分出类别&lt;/li&gt;
  &lt;li&gt;例子：Iris植物分类数据集，通过四个特征分出三个类别&lt;/li&gt;
  &lt;li&gt;特征连续值变成离散值&lt;/li&gt;
  &lt;li&gt;OneR算法：它根据已有数据中，具有相同特征值的个体最可能属于哪个类别进行分类。比如对于某一个特征值来说，属于A的类别有80个，属于B的类别有20个，那么对于这个特征值来说，取值为1代表为A类别，错误率有20％。给出所有特征值，找出错误率最小的特征值作为判断标准。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;第二章-用scikit-learn估计器分类&quot;&gt;第二章 用scikit-learn估计器分类&lt;/h2&gt;
&lt;h3 id=&quot;21-scikit-learn&quot;&gt;2.1 scikit-learn&lt;/h3&gt;
&lt;p&gt;scikit-learn里面已经封装好很多数据挖掘的算法&lt;/p&gt;

&lt;p&gt;现介绍数据挖掘框架的搭建方法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;转换器（Transformer）用于数据预处理，数据转换&lt;/li&gt;
  &lt;li&gt;流水线（Pipeline）组合数据挖掘流程，方便再次使用（封装）&lt;/li&gt;
  &lt;li&gt;估计器（Estimator）用于分类，聚类，回归分析（各种算法对象）
    &lt;ul&gt;
      &lt;li&gt;所有的估计器都有下面2个函数
        &lt;ul&gt;
          &lt;li&gt;fit() 训练
            &lt;ul&gt;
              &lt;li&gt;用法：estimator.fit(X_train, y_train)，&lt;/li&gt;
              &lt;li&gt;estimator = KNeighborsClassifier() 是scikit-learn算法对象&lt;/li&gt;
              &lt;li&gt;X_train = dataset.data 是numpy数组&lt;/li&gt;
              &lt;li&gt;y_train = dataset.target 是numpy数组&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;predict() 预测
            &lt;ul&gt;
              &lt;li&gt;用法：estimator.predict(X_test)&lt;/li&gt;
              &lt;li&gt;estimator = KNeighborsClassifier() 是scikit-learn算法对象&lt;/li&gt;
              &lt;li&gt;X_test = dataset.data 是numpy数组&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;22-邻近算法knn&quot;&gt;2.2 邻近算法KNN&lt;/h3&gt;
&lt;p&gt;邻近算法，或者说K最邻近（KNN，K-NearestNeighbor）分类算法是数据挖掘分类技术中最简单的方法之一。所谓K最近邻，就是K个最近的邻居的意思，说的是每个样本都可以用它最接近的K个邻近值来代表。近邻算法就是将数据集合中每一个记录进行分类的方法。&lt;/p&gt;

&lt;p&gt;例子：分类，Ionosphere数据集&lt;/p&gt;

&lt;h2 id=&quot;第三章-用决策树预测获胜球队&quot;&gt;第三章 用决策树预测获胜球队&lt;/h2&gt;

&lt;h3 id=&quot;31-决策树&quot;&gt;3.1 决策树&lt;/h3&gt;
&lt;p&gt;例子：预测NBA球队获胜情况&lt;/p&gt;

&lt;p&gt;决策树是一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试输出，每个叶节点代表一种类别。&lt;/p&gt;

&lt;p&gt;分类树（决策树）是一种十分常用的分类方法。它是一种监督学习，所谓监督学习就是给定一堆样本，每个样本都有一组属性和一个类别，这些类别是事先确定的，那么通过学习得到一个分类器，这个分类器能够对新出现的对象给出正确的分类。这样的机器学习就被称之为监督学习。&lt;/p&gt;

&lt;p&gt;scikit-learn库实现了分类回归树（Classification and Regression Trees，CART）算法并将其作为生成决策树的默认算法，它支持连续型特征和类别型特征。&lt;/p&gt;

&lt;h3 id=&quot;32-随机森林&quot;&gt;3.2 随机森林&lt;/h3&gt;
&lt;p&gt;随机森林指的是利用多棵树对样本进行训练并预测的一种分类器。&lt;/p&gt;

&lt;p&gt;在机器学习中，随机森林是一个包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。&lt;/p&gt;

&lt;h2 id=&quot;第四章-用亲和性分析方法推荐电影&quot;&gt;第四章 用亲和性分析方法推荐电影&lt;/h2&gt;
&lt;h3 id=&quot;41-亲和性分析&quot;&gt;4.1 亲和性分析&lt;/h3&gt;
&lt;p&gt;亲和性分析就是分析两个样本之间的疏密关系，常用的算法有Apriori，Apriori算法的一大特点是根据最小支持度生成&lt;strong&gt;频繁项集&lt;/strong&gt;（frequent itemest），它只从数据集中频繁出现的商品中选取共同出现的商品组成频繁项集。其他亲和性分析算法有Eclat和频繁项集挖掘算法（FP-growth）。&lt;/p&gt;

&lt;h3 id=&quot;42-apriori算法&quot;&gt;4.2 Apriori算法&lt;/h3&gt;
&lt;p&gt;Apriori算法主要有两个阶段，第一个阶段是根据最小支持度生成频繁项集，第二个阶段是根据最小置信度选择规则，返回规则。&lt;/p&gt;

&lt;p&gt;本章的例子是电影推荐。&lt;/p&gt;

&lt;p&gt;第一个阶段，算法会先生成长度较小的项集，再将这个项集作为超集寻找长度较大的项集。&lt;/p&gt;

&lt;p&gt;第二个阶段是从频繁项集中抽取关联规则。把其中几部电影作为前提，另一部电影作为结论。组成如下形式的规则：如果用户喜欢前提中的所有电影，那么他们也会喜欢结论中的电影。&lt;/p&gt;

&lt;h2 id=&quot;第五章-用转换器抽取特征&quot;&gt;第五章 用转换器抽取特征&lt;/h2&gt;
&lt;h3 id=&quot;51-抽取特征&quot;&gt;5.1 抽取特征&lt;/h3&gt;
&lt;p&gt;抽取数据集的特征是重要的一步，在之前的学习中我们都获得了数据集的特征，但很多没有处理的文本特征并不是很明显，比如一段文本等等。特征值可以分为连续特征，序数特征，类别型特征。&lt;/p&gt;

&lt;h3 id=&quot;52-特征选择&quot;&gt;5.2 特征选择&lt;/h3&gt;
&lt;p&gt;通常特征有很多，但我们只想选择其中一部分。&lt;strong&gt;选用干净的数据，选取更具描述性的特征。&lt;/strong&gt;判断特征相关性：书中列举的例子是判断一个人的收入能不能超过五万，利用单变量卡方检验(或者皮尔逊相关系数)判断各个特征的相关性，然后给出了三个最好的特征，分别是年龄，资本收入和资本损失。&lt;/p&gt;

&lt;h3 id=&quot;53-创建特征&quot;&gt;5.3 创建特征&lt;/h3&gt;
&lt;p&gt;主成分分析算法（Principal Component Analysis，PCA）的目的是找到能用较少信息描述数据集的特征组合。&lt;/p&gt;

&lt;h2 id=&quot;第六章-使用朴素贝叶斯进行社会媒体挖掘&quot;&gt;第六章 使用朴素贝叶斯进行社会媒体挖掘&lt;/h2&gt;
&lt;h3 id=&quot;61-消歧&quot;&gt;6.1 消歧&lt;/h3&gt;
&lt;p&gt;本章我们将处理文本，文本通常被称为无结构格式。文本挖掘的一个难点来自于歧义，比如bank一词多义。本章将探讨区别Twitter消息中Python的意思。&lt;/p&gt;

&lt;h3 id=&quot;62-文本转换器&quot;&gt;6.2 文本转换器&lt;/h3&gt;
&lt;p&gt;Python中处理文本的库NLTK(Natural Language Toolkit)。据作者说很好用，可以作自然语言处理。N元语法是指由连续的词组成的子序列。&lt;/p&gt;

&lt;h3 id=&quot;63-朴素贝叶斯&quot;&gt;6.3 朴素贝叶斯&lt;/h3&gt;
&lt;p&gt;朴素贝叶斯概率模型是以对贝叶斯统计方法的朴素解释为基础。&lt;/p&gt;

&lt;p&gt;贝叶斯定理公式如下：&lt;/p&gt;

&lt;p&gt;$ P(A|B) = \frac {P(B|A)P(A)}{P(B)} $&lt;/p&gt;

&lt;p&gt;贝叶斯公式可以用它来计算个体属于给定类别的概率。朴素贝叶斯算法假定了各个特征之间相互独立，那么我们计算文档D属于类别C的概率为P(D|C)=P(D1|C)*P(D2|C)…P(Dn|C)。贝叶斯分类器是输入数据来更新贝叶斯的先验概率和后验概率，输入贝叶斯模型后，返回不同类别中概率的最大值。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;举例说明下计算过程，假如数据集中有以下一条用二值特征表示的数据：[1, 0, 0, 1]。&lt;br /&gt;
训练集中有75%的数据属于类别0，25%属于类别1，且每个特征属于每个类别的似然度如下。&lt;br /&gt;
类别0：[0.3, 0.4, 0.4, 0.7] &lt;br /&gt;
类别1：[0.7, 0.3, 0.4, 0.9] &lt;br /&gt;
拿类别0中特征1的似然度举例子，上面这两行数据可以这样理解：类别0中有30%的数据，特征1的值为1。&lt;br /&gt;
我们来计算一下这条数据属于类别0的概率。类别为0时，P(C=0) = 0.75。&lt;br /&gt;
朴素贝叶斯算法用不到P(D)，因此我们不用计算它。我们来看下计算过程。&lt;br /&gt;
P(D|C=0) = P(D1|C=0) x P(D2|C=0) x P(D3|C=0) x P(D4|C=0)&lt;br /&gt;
= 0.3 x 0.6 x 0.6 x 0.7 &lt;br /&gt;
= 0.0756 &lt;br /&gt;
现在，我们就可以计算该条数据从属于每个类别的概率。需要提醒的是，我们没有计算P(D)，因此，计算结果不是实际的概率。由于两次都不计算P(D)，结果具有可比较性，能够区分出大小就足够了。来看下计算结果。&lt;br /&gt;
P(C=0|D) = P(C=0) P(D|C=0) &lt;br /&gt;
= 0.75 * 0.0756 &lt;br /&gt;
= 0.0567&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;64-f1值&quot;&gt;6.4 F1值&lt;/h3&gt;
&lt;p&gt;F1值是一种评价指标。F1值是以每个类别为基础进行定义的，包括两大概念：准确率（precision）和召回率（recall）。准确率是指预测结果属于某一类的个体，实际属于该类的比例。召回率是指被正确预测为某个类别的个体数量与数据集中该类别个体总量的比例。F1值是准确率和召回率的调和平均数。&lt;/p&gt;

&lt;h2 id=&quot;第九章-作者归属问题&quot;&gt;第九章 作者归属问题&lt;/h2&gt;
&lt;h3 id=&quot;91-作者归属&quot;&gt;9.1 作者归属&lt;/h3&gt;
&lt;p&gt;作者归属（authorship attribution）是作者分析的一个细分领域，研究目标是从一组可能的作者中找到文档真正的主人。利用功能词进行分类，功能词是指本身含义很少，但是是组成句子必不可少的部分。&lt;/p&gt;

&lt;h3 id=&quot;92-支持向量机&quot;&gt;9.2 支持向量机&lt;/h3&gt;
&lt;p&gt;支持向量机（SVM）分类算法背后的思想很简单，它是一种二类分类器（扩展后可用来对多个类别进行分类）。假如我们有两个类别的数据，而这两个类别恰好能被一条线分开，线上所有点为一类，线下所有点属于另一类。SVM要做的就是找到这条线，用它来做预测，跟线性回归原理很像。&lt;/p&gt;

&lt;p&gt;下图中有三条线，那么哪一条线的分类效果最好呢？直觉告诉我们从左下到右上的这一条线效果最好，因为每一个点到这条线的距离最远，那么寻找这条线就变成了最优化问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211210/2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于多种类别的分类问题，我们创建多个SVM分类器，其中每个SVM分类器还是二分类。连接多个分类器的方法有很多，比如说我们可以将每个类别创建一对多分类器。把训练数据分为两个类别——属于特定类别的数据和其他所有类别数据。对新数据进行分类时，从这些类别中找出最匹配的。&lt;/p&gt;

&lt;h3 id=&quot;93-基础svm的局限性&quot;&gt;9.3 基础SVM的局限性&lt;/h3&gt;
&lt;p&gt;最基础的SVM只能区分线性可分的两种类别，如果数据线性不可分，就需要将其置入更高维的空间中，加入更多伪特征直到数据线性可分。寻找最佳分隔线时往往需要计算个体之间的内积。我们把内核函数定义为数据集中两个个体函数的点积。&lt;/p&gt;

&lt;p&gt;常用的内核函数有几种。线性内核最简单，它无外乎两个个体的特征向量的点积、带权重的特征和偏置项。多项式内核提高点积的阶数（比如2）。此外，还有高斯内核（rbf）、Sigmoind内核。&lt;/p&gt;

&lt;h2 id=&quot;第十章-新闻语料分类&quot;&gt;第十章 新闻语料分类&lt;/h2&gt;
&lt;h3 id=&quot;101-新闻语料聚类&quot;&gt;10.1 新闻语料聚类&lt;/h3&gt;
&lt;p&gt;之前我们研究的都是监督学习，在已经知道类别的情况下进行分类。本章着眼于无监督学习，聚类。&lt;/p&gt;

&lt;h3 id=&quot;102-k-means算法&quot;&gt;10.2 K-means算法&lt;/h3&gt;
&lt;p&gt;k-means聚类算法迭代寻找最能够代表数据的聚类质心点。算法开始时使用从训练数据中随机选取的几个数据点作为质心点。k-means中的k表示寻找多少个质心点，同时也是算法将会找到的簇的数量。例如，把k设置为3，数据集所有数据将会被分成3个簇。&lt;/p&gt;

&lt;p&gt;k-means算法分为两个步骤：为每一个数据点分配簇标签，更新各簇的质心点。k-means算法会重复上述两个步骤；每次更新质心点时，所有质心点将会小范围移动。这会
轻微改变每个数据点在簇内的位置，从而引发下一次迭代时质心点的变动。这个过程会重复执行直到条件不再满足时为止。通常是在迭代一定次数后，或者当质心点的整体移动量很小时，就可以终止算法的运行。有时可以等算法自行终止运行，这表明簇已经相当稳定——数据点所属的簇不再变动，质心点也不再改变时。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211210/3.jpg&quot; /&gt;&lt;/p&gt;</content><author><name>Quehry</name></author><category term="note" /><summary type="html"></summary></entry><entry><title type="html">RACE数据集相关文献</title><link href="http://localhost:4000/RACE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE.html" rel="alternate" type="text/html" title="RACE数据集相关文献" /><published>2021-11-30T00:00:00+08:00</published><updated>2021-11-30T00:00:00+08:00</updated><id>http://localhost:4000/RACE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE</id><content type="html" xml:base="http://localhost:4000/RACE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE.html">&lt;h1 id=&quot;目录&quot;&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot;&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#文献整理&quot;&gt;文献整理&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#要求&quot;&gt;要求&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#搜集到相关文献标题和地址&quot;&gt;搜集到相关文献标题和地址&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#第一篇&quot;&gt;第一篇&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#title&quot;&gt;Title&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#author&quot;&gt;Author&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#abstract&quot;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bert-distractor-generation&quot;&gt;BERT distractor generation&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1bert-based-distractor-generationbdg&quot;&gt;1)BERT-based distractor generation(BDG)&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2multi-task-with-parallel-mlm&quot;&gt;2)Multi-task with Parallel MLM&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3answer-negative-regularization&quot;&gt;3)Answer Negative Regularization&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#multiple-distractor-generation&quot;&gt;Multiple Distractor Generation&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1selecting-distractors-by-entropy-maximization&quot;&gt;1)Selecting Distractors by Entropy Maximization&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2bdg-em&quot;&gt;2)BDG-EM&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#performance-evaluation&quot;&gt;Performance Evaluation&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1datasets&quot;&gt;1)datasets&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2implementation-details&quot;&gt;2)implementation details&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3compared-methods&quot;&gt;3)compared methods&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#4token-score-comparison&quot;&gt;4)token score comparison&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#5mcq-model-accuracy-comparison&quot;&gt;5)MCQ Model Accuracy Comparison&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#6parameter-study-on-γ&quot;&gt;6）Parameter Study on γ&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#我的看法&quot;&gt;我的看法&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#第二篇&quot;&gt;第二篇&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#title-1&quot;&gt;Title&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#author-1&quot;&gt;Author&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#abstract-1&quot;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#method&quot;&gt;Method&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1question-generation&quot;&gt;1)question generation&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2distractor-generation&quot;&gt;2)distractor generation&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3qa-filtering&quot;&gt;3)QA filtering&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#results&quot;&gt;Results&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1quantitative-evaluation&quot;&gt;1)quantitative evaluation&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2question-answering-ability&quot;&gt;2)question answering ability&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3human-evaluation&quot;&gt;3)human evaluation&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#第三篇&quot;&gt;第三篇&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#title-2&quot;&gt;Title&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#author-2&quot;&gt;Author&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#abstract-2&quot;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#framework-description-网络结构&quot;&gt;Framework Description 网络结构&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1task-definition&quot;&gt;1)Task Definition&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2framework-overview&quot;&gt;2)Framework overview&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3hierarchical-encoder&quot;&gt;3)Hierarchical encoder&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#4static-attention-mechanism&quot;&gt;4)static attention mechanism&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#5encoding-layer&quot;&gt;5)encoding layer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#6matching-layer&quot;&gt;6)matching layer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#7nomalization-layer&quot;&gt;7)nomalization layer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#8distractor-decoder&quot;&gt;8)distractor decoder&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#9question-based-initializer&quot;&gt;9)question-based initializer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#10dynamic-hierarchical-attention-mechanism&quot;&gt;10)dynamic hierarchical attention mechanism&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#11training-and-inference&quot;&gt;11)training and inference&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#experimental-setting-实验设置&quot;&gt;experimental setting 实验设置&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1dataset&quot;&gt;1)dataset&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2implementation-details-1&quot;&gt;2)implementation details&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3baselines-and-ablations&quot;&gt;3)baselines and ablations&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#results-and-analysis-结果与分析&quot;&gt;results and analysis 结果与分析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#我的看法-1&quot;&gt;我的看法&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#第四篇&quot;&gt;第四篇&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#title-3&quot;&gt;Title&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#author-3&quot;&gt;Author&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#abstract-3&quot;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#proposed-framework-网络结构&quot;&gt;Proposed Framework 网络结构&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1notations-and-task-definition&quot;&gt;1)notations and task definition&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2model-overview&quot;&gt;2)model overview&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3encoding-article-and-question&quot;&gt;3)encoding article and question&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#4co-attention-between-article-and-question&quot;&gt;4)Co-attention between article and question&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#5merging-sentence-representation&quot;&gt;5)Merging sentence representation&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#6question-initialization&quot;&gt;6)question initialization&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#7hierarchical-attention&quot;&gt;7)hierarchical attention&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#8semantic-similarity-loss&quot;&gt;8)semantic similarity loss&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#experimental-settings&quot;&gt;Experimental Settings&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1dataset-1&quot;&gt;1)dataset&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2baselines-and-evaluation-metrics&quot;&gt;2)baselines and evaluation metrics&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3implementation-details&quot;&gt;3)implementation details&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#results-and-analysis-结果与分析&quot;&gt;Results and Analysis 结果与分析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#我的看法-2&quot;&gt;我的看法&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#补充&quot;&gt;补充&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#race数据集简介&quot;&gt;RACE数据集简介&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bleu&quot;&gt;BLEU&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#rouge&quot;&gt;ROUGE&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;文献整理&quot;&gt;文献整理&lt;/h1&gt;

&lt;h2 id=&quot;要求&quot;&gt;要求&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/requirements.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;搜集到相关文献标题和地址&quot;&gt;搜集到相关文献标题和地址&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2010.05384.pdf&quot;&gt;A BERT-based Distractor Generation Scheme with Multi-tasking and Negative Answer Training Strategies&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2010.09598.pdf&quot;&gt;Better Distractions: Transformer-based Distractor Generation and Multiple Choice Question Filtering&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ojs.aaai.org//index.php/AAAI/article/view/4606&quot;&gt;Generating Distractors for Reading Comprehension Questions from Real Examinations&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ojs.aaai.org/index.php/AAAI/article/view/6522&quot;&gt;Co-attention hierarchical network: Generating coherent long distractors for reading comprehension&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aclanthology.org/2020.coling-main.189.pdf&quot;&gt;Automatic Distractor Generation for Multiple Choice Questions in Standard Tests&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aclanthology.org/W18-0533.pdf&quot;&gt;Distractor Generation for Multiple Choice Questions Using Learning to Rank&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ojs.aaai.org/index.php/AAAI/article/view/16559&quot;&gt;Knowledge-Driven Distractor Generation for Cloze-style Multiple Choice Questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;第一篇&quot;&gt;第一篇&lt;/h1&gt;
&lt;h2 id=&quot;title&quot;&gt;Title&lt;/h2&gt;
&lt;p&gt;A BERT-based Distractor Generation Scheme with Multi-tasking and
Negative Answer Training Strategies&lt;/p&gt;
&lt;h2 id=&quot;author&quot;&gt;Author&lt;/h2&gt;
&lt;p&gt;Ho-Lam Chung, Ying-Hong Chan, Yao-Chung Fan&lt;/p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;现有的DG&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;局限在只能生成一个误导选项，我们需要生成多个误导选项，文章中提到他们团队用multi-tasking和negative answer training技巧来生成多个误导选项，模型结果达到了学界顶尖。&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;DG效果不好，文章提出了两个提升的空间：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;DG质量提升：&lt;br /&gt;
 BERT模型来提升误导选项质量&lt;/li&gt;
  &lt;li&gt;多个误导选项生成：
 运用了覆盖的方法来选择distractor，而不是选择概率最高但是语义很相近的distractor&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;bert-distractor-generation&quot;&gt;BERT distractor generation&lt;/h2&gt;
&lt;h3 id=&quot;1bert-based-distractor-generationbdg&quot;&gt;1)BERT-based distractor generation(BDG)&lt;/h3&gt;
&lt;p&gt;输入：段落P，答案A，问题Q，用C表示这三者concatenate后的结果。&lt;br /&gt;
BDG模型是一个自回归模型，在预测阶段，每次输入C和上一次预测的词元，BDG迭代预测词元，直到预测出特殊词元[S]停止。下面这张图简单介绍了这个过程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;网络结构简单介绍：h&lt;sub&gt;[M]&lt;/sub&gt;表示bert输出的隐藏状态，隐藏状态再输入到一个全连接层中用来预测词元。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/3.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2multi-task-with-parallel-mlm&quot;&gt;2)Multi-task with Parallel MLM&lt;/h3&gt;
&lt;p&gt;MLM全称masked language model，遮蔽语言模型,通过并行BDG和P-MLM来训练模型让模型有更好的效果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/4.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图中左边的sequential MLM就是之前提到的BDG，BDG模型是一个词接一个词的预测，P-MLM是对所有的masked token进行预测，最后的损失函数是这两者相加&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;，公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/5.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/6.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/7.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;作者如此设计的思路是：BDG可能会忽略整体语义语义信息，但是会过拟合单个词预测。那么并行一个P-MLM可以防止过拟合。&lt;/p&gt;

&lt;h3 id=&quot;3answer-negative-regularization&quot;&gt;3)Answer Negative Regularization&lt;/h3&gt;
&lt;p&gt;目前机器预测的distractor和answer有很高的相似度，下面一张表可以展示相似度。其中PM表示机器，Gold表示人工，作者将这类问题称为answer copying problem。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/8.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了解决这个问题，作者提出了answer negative loss来让机器更多的选择与answer不同的词来表示新的distractor，公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/9.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出BDG的loss替换成了AN的loss，每一项都减去了Answer negative loss。&lt;/p&gt;

&lt;h2 id=&quot;multiple-distractor-generation&quot;&gt;Multiple Distractor Generation&lt;/h2&gt;
&lt;h3 id=&quot;1selecting-distractors-by-entropy-maximization&quot;&gt;1)Selecting Distractors by Entropy Maximization&lt;/h3&gt;
&lt;p&gt;选择语义不同的distractor set。文章借鉴了MRC&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;的方法，让BDGmodel生成很多distractor组成 $\hat{D}$ = {$\hat{d}$&lt;sub&gt;1&lt;/sub&gt;, $\hat{d}$&lt;sub&gt;2&lt;/sub&gt;, $\hat{d}$&lt;sub&gt;3&lt;/sub&gt;…}，然后找出最好的一组选项，一般情况下由三个误导选项和一个答案组成。选择的一句是最大化下面这个公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/10.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2bdg-em&quot;&gt;2)BDG-EM&lt;/h3&gt;
&lt;p&gt;我们可以通过不同的BDG模型来生成不同的误导选项最后组合，不同的模型区别是有没有answer negative/multi-task training，比如我们有这几个模型:$\hat{D}$,$\hat{D}$&lt;sub&gt;PM&lt;/sub&gt;,$\hat{D}$&lt;sub&gt;PM+AN&lt;/sub&gt;，它们分别代表含PM&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;和含AN&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/11.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;performance-evaluation&quot;&gt;Performance Evaluation&lt;/h2&gt;
&lt;h3 id=&quot;1datasets&quot;&gt;1)datasets&lt;/h3&gt;
&lt;p&gt;RACE,沿用了&lt;a href=&quot;https://ojs.aaai.org//index.php/AAAI/article/view/4606&quot;&gt;Gao&lt;/a&gt;那篇论文的处理,后面也会梳理那篇论文&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/12.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2implementation-details&quot;&gt;2)implementation details&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;tokenizer: wordpiece tokenizer&lt;/li&gt;
  &lt;li&gt;framewordk:huggingface trainsformers&lt;/li&gt;
  &lt;li&gt;optimizer:adamW(lr:5e-5)&lt;/li&gt;
  &lt;li&gt;github_url: &lt;a href=&quot;https://github.com/voidful/BDG&quot;&gt;BDG&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3compared-methods&quot;&gt;3)compared methods&lt;/h3&gt;
&lt;p&gt;比较了不同的distractor generation&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CO-Att：出自&lt;a href=&quot;https://ojs.aaai.org/index.php/AAAI/article/view/6522&quot;&gt;Zhou&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;DS-Att: 出自&lt;a href=&quot;https://ojs.aaai.org//index.php/AAAI/article/view/4606&quot;&gt;Gao&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;GPT:baseline&lt;/li&gt;
  &lt;li&gt;BDG: 没有应用P-MLM和Answer negative&lt;/li&gt;
  &lt;li&gt;BDG&lt;sub&gt;PM&lt;/sub&gt;&lt;/li&gt;
  &lt;li&gt;BDG&lt;sub&gt;AN+PM&lt;/sub&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4token-score-comparison&quot;&gt;4)token score comparison&lt;/h3&gt;
&lt;p&gt;BLEU和ROUGE(L)两种判断指标&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/13.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;copying problem的效果&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/14.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;5mcq-model-accuracy-comparison&quot;&gt;5)MCQ Model Accuracy Comparison&lt;/h3&gt;
&lt;p&gt;与回答系统相结合，将生成好的选项（一个正确答案三个误导选项）放入MCQ answering model，下面是回答正确率的表格&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/15.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出作者的模型选项的误导性还是很高的。&lt;/p&gt;

&lt;h3 id=&quot;6parameter-study-on-γ&quot;&gt;6）Parameter Study on γ&lt;/h3&gt;
&lt;p&gt;之前使用P-MLM并行训练时候有个权重参数γ，下表显示了不同γ值的影响，对于只有PM的模型来说，γ=6，对于既有AN和PM来说，γ=7&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/16.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;现存的DG可以分为cloze-style distractor generation和 reading comprehension distractor generation，前者主要是word filling，后者主要看重语义信息，基于两者的设计出了很多模型，目前来看还是考虑语义信息生成的误导选项更好。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/17.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;我的看法&quot;&gt;我的看法&lt;/h2&gt;
&lt;p&gt;文章中的模型提到了三种技术，第一是bert预训练模型使用。第二是P-MLM的并行使用， 它的使用让模型可以考虑段落的语义信息，那么生成的误导选项是sentence-level而不是之前模型所使用的类似word-filling这种word-level。第三是Answer negative loss的使用，它的使用相当于让模型不要考虑与正确答案语义很接近的误导选项，因为目前大多数DG生成多个选项时语义与正确答案都非常接近，这与实际情况不符，同时也起不到误导的作用。  &lt;br /&gt;
同时文章提出了生成多个误导选项时使用不同模型生成的误导选项拼在一起作为选项是一种比较好的解决方法，让一次性生成多个误导选型有了一定的可用性。&lt;br /&gt;
文章的代码开源，可以去&lt;a href=&quot;https://github.com/voidful/BDG&quot;&gt;github&lt;/a&gt;上看训练细节和网络结构细节。&lt;/p&gt;

&lt;h1 id=&quot;第二篇&quot;&gt;第二篇&lt;/h1&gt;
&lt;h2 id=&quot;title-1&quot;&gt;Title&lt;/h2&gt;
&lt;p&gt;Better Distractions: Transformer-based Distractor Generation and Multiple Choice Question Filtering&lt;/p&gt;
&lt;h2 id=&quot;author-1&quot;&gt;Author&lt;/h2&gt;
&lt;p&gt;Jeroen Offerijns, Suzan Verberne, Tessa Verhoef&lt;/p&gt;
&lt;h2 id=&quot;abstract-1&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;运用GPT2模型生成三个误导选项，同时用BERT模型去回答这个问题，只挑选出回答正确的问题。相当于使用了QA作为一个过滤器(QA filtering)。&lt;/p&gt;
&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;
&lt;p&gt;作者使用了Question generation model, distractor generation model和question answer filter，作者将从这三方面介绍，下图是大概的流程图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/18.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1question-generation&quot;&gt;1)question generation&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;预训练模型：GPT-2&lt;/li&gt;
  &lt;li&gt;数据集：English SQuAD&lt;/li&gt;
  &lt;li&gt;tokenizer：Byte-Pair-Encoding(BPE) tokenizer&lt;/li&gt;
  &lt;li&gt;optimizer:Adam&lt;/li&gt;
  &lt;li&gt;下图展示了QG的输入，黑框内被tokenizer标记为特殊词元&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/19.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2distractor-generation&quot;&gt;2)distractor generation&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;预训练模型：GPT-2&lt;/li&gt;
  &lt;li&gt;数据集：RACE&lt;/li&gt;
  &lt;li&gt;tokenizer:BPE&lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
  &lt;li&gt;使用了repetition penalty技术，保证了尽量不会生成相似的text，并且过滤到那些不好的生成（比如生成了空字符串）&lt;/li&gt;
  &lt;li&gt;输入：经典的C(context)，A(answer),Q(question)，下图展示了输入格式&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/20.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3qa-filtering&quot;&gt;3)QA filtering&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;预训练模型：DistilBERT&lt;/li&gt;
  &lt;li&gt;网络结构：CQA&lt;sup id=&quot;fnref:7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;输入到distilbert，再连接一个dropout，全连接层和softmax，最后输出一个答案，具体结构如下图&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/21.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;h3 id=&quot;1quantitative-evaluation&quot;&gt;1)quantitative evaluation&lt;/h3&gt;
&lt;p&gt;下表中展示了和上一篇论文类似的指标,与现有的模型进行了比较：SEQ2SEQ,HSA&lt;sup id=&quot;fnref:8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;和CHN&lt;sup id=&quot;fnref:9&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;。可以看出BLEU明显要比之前模型要好，但是ROUGE没有之前的高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/22.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2question-answering-ability&quot;&gt;2)question answering ability&lt;/h3&gt;
&lt;p&gt;用GPT-2模型生成误导选项再输入到QAmodel中，具体结果见下图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/23.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3human-evaluation&quot;&gt;3)human evaluation&lt;/h3&gt;
&lt;p&gt;人工评估，从两方面评估distractor生成的好坏：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Is the question well-formed and can you understand the meaning?&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;If the question is at least understandable, does the answer make sense in relation to the question?&lt;/strong&gt;
评估过程中，使用了155个没有经过QA筛选和155经过QA筛选的，了解一下QA过滤模型的效果。整体来说QA过滤器还是有一点效果，具体结果如下：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/24.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion-1&quot;&gt;conclusion&lt;/h2&gt;
&lt;p&gt;我认为作者使用的DG模型主要有两大特色，一个是使用了GPT2预训练模型，目前使用基于transformer的模型已经成为主流。第二个是使用了QA过滤器来筛选掉回答错误的，有一定提升但不显著。&lt;/p&gt;

&lt;h1 id=&quot;第三篇&quot;&gt;第三篇&lt;/h1&gt;
&lt;h2 id=&quot;title-2&quot;&gt;Title&lt;/h2&gt;
&lt;p&gt;Generating Distractors for Reading Comprehension Questions from Real Examinations&lt;/p&gt;
&lt;h2 id=&quot;author-2&quot;&gt;Author&lt;/h2&gt;
&lt;p&gt;Yifan Gao, Lidong Bing, Piji Li,
Irwin King, Michael R. Lyu&lt;/p&gt;
&lt;h2 id=&quot;abstract-2&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;上面两篇文献都有提到这篇文章。作者使用了&lt;strong&gt;Hierarchical encoder-decoder framework&lt;/strong&gt; with &lt;strong&gt;static&lt;/strong&gt; and &lt;strong&gt;dynamic&lt;/strong&gt; attention mechanisms来生成有语义信息的误导选项。使用了编码器-解码器结构网络和静态和动态注意力机制。&lt;/p&gt;
&lt;h2 id=&quot;framework-description-网络结构&quot;&gt;Framework Description 网络结构&lt;/h2&gt;
&lt;h3 id=&quot;1task-definition&quot;&gt;1)Task Definition&lt;/h3&gt;
&lt;p&gt;输入：文章，问题和答案。P代表文章，s&lt;sub&gt;1&lt;/sub&gt;,s&lt;sub&gt;2&lt;/sub&gt;,s&lt;sub&gt;3&lt;/sub&gt;…表示不同的句子，q和a分别表示问题和答案，那么我们的任务是生成误导选项$\overline{d}$。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/25.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2framework-overview&quot;&gt;2)Framework overview&lt;/h3&gt;
&lt;p&gt;网络结构如下图所示，下面将从各个组成部分分别介绍：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/26.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3hierarchical-encoder&quot;&gt;3)Hierarchical encoder&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;word embedding&lt;/strong&gt;:词嵌入，将每个句子s&lt;sub&gt;i&lt;/sub&gt;中的每个词元变成词向量(w&lt;sub&gt;i,1&lt;/sub&gt;,w&lt;sub&gt;i,2&lt;/sub&gt;,w&lt;sub&gt;i,3&lt;/sub&gt;…)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;word encoder&lt;/strong&gt;:将句子s&lt;sub&gt;i&lt;/sub&gt;的词向量(w&lt;sub&gt;i,1&lt;/sub&gt;,w&lt;sub&gt;i,2&lt;/sub&gt;,w&lt;sub&gt;i,3&lt;/sub&gt;…)作为输入，用&lt;strong&gt;双向LSTM&lt;/strong&gt;作为编码器，获得word-level representation h&lt;sub&gt;i,j&lt;/sub&gt;&lt;sup&gt;e&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/27.jpg&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;sentence encoder&lt;/strong&gt;:将word encoder中每个句子正向LSTM的最后一个隐藏状态和反向LSTM的最开始的隐藏状态作为输入到另一个双向LSTM中获得&lt;strong&gt;sentence-level representation&lt;/strong&gt;(u&lt;sub&gt;1&lt;/sub&gt;,u&lt;sub&gt;2&lt;/sub&gt;,u&lt;sub&gt;3&lt;/sub&gt;…)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4static-attention-mechanism&quot;&gt;4)static attention mechanism&lt;/h3&gt;
&lt;p&gt;目的：生成的误导选项必须和问题Q语义相关，但是和答案A必须语义不相关。我们从(s&lt;sub&gt;1&lt;/sub&gt;,s&lt;sub&gt;2&lt;/sub&gt;,s&lt;sub&gt;3&lt;/sub&gt;…)学习到句子的权重分布(γ&lt;sub&gt;1&lt;/sub&gt;,γ&lt;sub&gt;2&lt;/sub&gt;,γ&lt;sub&gt;3&lt;/sub&gt;…)，然后将问题q和答案a作为query。&lt;/p&gt;

&lt;h3 id=&quot;5encoding-layer&quot;&gt;5)encoding layer&lt;/h3&gt;
&lt;p&gt;我们希望把问题q，答案a和句子s都变成一样的长度的向量表示，也就是上图中紫色虚线部分。对于q和a，我们用两个独立的双向LSTM来获得(&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt;,&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;2&lt;/sub&gt;…&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;k&lt;/sub&gt;)和(&lt;strong&gt;q&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt;,&lt;strong&gt;q&lt;/strong&gt;&lt;sub&gt;2&lt;/sub&gt;…&lt;strong&gt;q&lt;/strong&gt;&lt;sub&gt;l&lt;/sub&gt;)，然后用平均池化层平均一下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/28.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于句子s，我们不用u而用h：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/29.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;6matching-layer&quot;&gt;6)matching layer&lt;/h3&gt;
&lt;p&gt;目的：加重与问题q有关的句子，减轻与答案a有关的句子。o&lt;sub&gt;i&lt;/sub&gt;表示不同句子的importance score&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/30.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;7nomalization-layer&quot;&gt;7)nomalization layer&lt;/h3&gt;
&lt;p&gt;目的：有些问题q和一两个句子有关，而有些问题q和很多句子有关，比如summarizing，下面的τ(temperature)就是这个作用&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/31.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/32.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;作者介绍static attention mechanism用了很大篇幅&lt;/p&gt;

&lt;h3 id=&quot;8distractor-decoder&quot;&gt;8)distractor decoder&lt;/h3&gt;
&lt;p&gt;解码器使用的也是LSTM，但是并没有使用编码器的最后一个隐藏状态作为初始状态，而是定义了一个
&lt;strong&gt;question-based initializer&lt;/strong&gt;来让生成的误导选项语法和问题q一致&lt;/p&gt;

&lt;h3 id=&quot;9question-based-initializer&quot;&gt;9)question-based initializer&lt;/h3&gt;
&lt;p&gt;定义了一个question LSTM来编码问题q，使用最后一层的cell state和hidden state作为decoder初始状态，同时输入q&lt;sub&gt;last&lt;/sub&gt;，表示问题q的最后一个词元。&lt;/p&gt;

&lt;h3 id=&quot;10dynamic-hierarchical-attention-mechanism&quot;&gt;10)dynamic hierarchical attention mechanism&lt;/h3&gt;
&lt;p&gt;常规的注意力机制将一篇文章作为长句子，然后decoder的每一个时间步都与encoder中所有的hidden state进行比较，但是这种方法并不适合目前的模型。原因：首先LSTM不能处理这么长的输入，其次，一些问题只与部分句子有关。&lt;br /&gt;
目的：每个decoder时间步只关注&lt;strong&gt;重要句子&lt;/strong&gt;，作者将这种注意力机制称为动态注意力机制，因为不同的时间步，word-level和sentence-level 注意力分布都不同。&lt;br /&gt;
每一个时间步的输入是词元d&lt;sub&gt;t-1&lt;/sub&gt;和上一个隐藏状态h&lt;sub&gt;t-1&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/33.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/34.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;α和β分别表示word-level,sentence-level权重，最后使用之前静态注意力机制获得的γ来调节α和β&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/35.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/36.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;获得上下文变量&lt;strong&gt;c&lt;/strong&gt;&lt;sub&gt;t&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/37.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;获得attention vector $\tilde{h}$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/38.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;11training-and-inference&quot;&gt;11)training and inference&lt;/h3&gt;
&lt;p&gt;损失函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/39.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;生成多个误导选项的方法是束搜索，但是生成的误导选项很相似，作者做了相应的处理方法，但我觉得效果还是很差&lt;/p&gt;

&lt;h2 id=&quot;experimental-setting-实验设置&quot;&gt;experimental setting 实验设置&lt;/h2&gt;
&lt;h3 id=&quot;1dataset&quot;&gt;1)dataset&lt;/h3&gt;
&lt;p&gt;RACE数据集，作者做了相应的处理，去掉了很多不合理的和语义不相关的，作者的处理标准是：对于误导选项中的词元，如果它们在文章中出现的次数小于5次，那么将被保留，同时去掉了那些需要在句子中间和句子开始填空的问题。下表展示了处理后的数据集的一些信息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/40.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2implementation-details-1&quot;&gt;2)implementation details&lt;/h3&gt;
&lt;p&gt;词表：保留了频率最高的50k个词元，同时使用GloVe作为词嵌入预训练模型。其他的细节都可以在文章中看见，这里不一一列出了，主要是超参数的设置。&lt;/p&gt;

&lt;h3 id=&quot;3baselines-and-ablations&quot;&gt;3)baselines and ablations&lt;/h3&gt;
&lt;p&gt;与HRED&lt;sup id=&quot;fnref:10&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;和seq2seq比较&lt;/p&gt;

&lt;h2 id=&quot;results-and-analysis-结果与分析&quot;&gt;results and analysis 结果与分析&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/41.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;人工评估：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/42.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;大致过程是这样：四个误导选项，分别来自seq2seq，HRED，作者的模型和原本的误导选项，让英语能力很好的人来选择最适合的选项，得出的结果可以发现，作者的模型生成的误导选项拥有最好的误导效果。&lt;/p&gt;

&lt;p&gt;下图直观展示了static attention distribution：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/43.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;我的看法-1&quot;&gt;我的看法&lt;/h2&gt;
&lt;p&gt;这篇文章应该是第一个提出用处理后的RACE数据集来处理MCQ问题，处理后的RACE数据集在后面也有很多文献用到，这篇文章使用了seq2seq网络结构同时使用了静态和动态注意力机制，对于网络结构和注意力机制的解释非常完全和详细，虽然这篇文章的效果放到现在来看可能不是最好了，但是它提出来的评估标准可能会成为一个通用的标准。它的数据集和训练代码在&lt;a href=&quot;https://github.com/Yifan-Gao/Distractor-Generation-RACE&quot;&gt;github&lt;/a&gt;上也完全开源。&lt;/p&gt;

&lt;h1 id=&quot;第四篇&quot;&gt;第四篇&lt;/h1&gt;
&lt;h2 id=&quot;title-3&quot;&gt;Title&lt;/h2&gt;
&lt;p&gt;Co-attention hierarchical network: Generating coherent long distractors for reading comprehension&lt;/p&gt;
&lt;h2 id=&quot;author-3&quot;&gt;Author&lt;/h2&gt;
&lt;p&gt;Xiaorui Zhou, Senlin Luo, Yunfang Wu&lt;/p&gt;
&lt;h2 id=&quot;abstract-3&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;这篇文献是针对上一篇Gao的文章(seq2seq)所作的改进。本篇文章提出了Gao的模型的两个问题：1.没有建立文章和问题的关系，他的解决方法是使用&lt;strong&gt;co-attention enhanced hierarchical architecture&lt;/strong&gt;来捕获文章和问题之间的关系，让解码器生成更有关联的误导选项。2.没有加重整篇文章和误导选项的关系。作者的解决思路是添加一个额外的语义相关性损失函数，让生成的误导选项与整篇文章更有关联。&lt;/p&gt;
&lt;h2 id=&quot;proposed-framework-网络结构&quot;&gt;Proposed Framework 网络结构&lt;/h2&gt;
&lt;h3 id=&quot;1notations-and-task-definition&quot;&gt;1)notations and task definition&lt;/h3&gt;
&lt;p&gt;article T=(s&lt;sub&gt;1&lt;/sub&gt;,s&lt;sub&gt;2&lt;/sub&gt;…s&lt;sub&gt;k&lt;/sub&gt;)，一篇文章有k个句子s，同时每个句子都有不同的长度l，s&lt;sub&gt;i&lt;/sub&gt;=(w&lt;sub&gt;i,1&lt;/sub&gt;,w&lt;sub&gt;i,2&lt;/sub&gt;…w&lt;sub&gt;i,l&lt;/sub&gt;)，每个文章有m个问题和z个误导选项，Q=(q&lt;sub&gt;1&lt;/sub&gt;,q&lt;sub&gt;2&lt;/sub&gt;…q&lt;sub&gt;m&lt;/sub&gt;),D=(d&lt;sub&gt;1&lt;/sub&gt;,d&lt;sub&gt;2&lt;/sub&gt;…d&lt;sub&gt;z&lt;/sub&gt;),我们的任务是根据输入的T和Q生成D&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/44.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2model-overview&quot;&gt;2)model overview&lt;/h3&gt;
&lt;p&gt;整体结构如下图所示，下面将从各个部分分别介绍：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/45.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3encoding-article-and-question&quot;&gt;3)encoding article and question&lt;/h3&gt;
&lt;p&gt;文章和问题的编码器结构&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;hierarchical article encoder&lt;/strong&gt;
双向LSTM，和上一篇结构很像，很多部分我就简单列个式子。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/46.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每一句最后的词元来表示整个句子&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/47.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;sentence-level encoder：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/48.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;同样，用最后一个句子来表示整篇文章&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/49.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;用&lt;strong&gt;H&lt;/strong&gt;&lt;sup&gt;*&lt;/sup&gt;来作为sentence-level representation of article,我们有&lt;strong&gt;H&lt;/strong&gt;&lt;sub&gt;:t&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;=h&lt;sub&gt;t&lt;/sub&gt;&lt;sup&gt;s&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;这样，通过使用两个双向LSTM获得word-level encoding和sentence-level encoding&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;question encoder&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/50.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;用&lt;strong&gt;U&lt;/strong&gt;&lt;sup&gt;*&lt;/sup&gt;来作为word-level representations of question, 我们有&lt;strong&gt;U&lt;/strong&gt;&lt;sub&gt;:t&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;=h&lt;sub&gt;t&lt;/sub&gt;&lt;sup&gt;q&lt;/sup&gt;&lt;/p&gt;

&lt;h3 id=&quot;4co-attention-between-article-and-question&quot;&gt;4)Co-attention between article and question&lt;/h3&gt;
&lt;p&gt;Co-attention mechanism就是使用了两个方向的注意力机制，有从article到question的，也有question到article的。&lt;br /&gt;
用一个“相似”矩阵S表示H和U的关系：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/51.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;S&lt;sub&gt;i,j&lt;/sub&gt;就表示第i个句子和第j个问题词元的相似性&lt;/p&gt;

&lt;p&gt;我们可以获得两个特殊的矩阵&lt;strong&gt;S&lt;/strong&gt;&lt;sup&gt;&lt;strong&gt;Q&lt;/strong&gt;&lt;/sup&gt;和&lt;strong&gt;S&lt;/strong&gt;&lt;sup&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/52.jpg&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;article-to-question attention&lt;br /&gt;
$\tilde{U}$&lt;sub&gt;:j&lt;/sub&gt; = $\sum$ S&lt;sub&gt;i,j&lt;/sub&gt;&lt;sup&gt;Q&lt;/sup&gt;U&lt;sub&gt;:,i&lt;/sub&gt;&lt;/li&gt;
  &lt;li&gt;question-to-article attention&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/53.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后，将问题的词级表示H，两个方向的注意力结果$\tilde{U}$和$\tilde{H}$结合一下获得G&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/54.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;5merging-sentence-representation&quot;&gt;5)Merging sentence representation&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/55.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Z表示final representation of sentence-level hidden states&lt;/p&gt;

&lt;h3 id=&quot;6question-initialization&quot;&gt;6)question initialization&lt;/h3&gt;
&lt;p&gt;接下来就进入decoder环节，这里的question initialization和上篇文献处理方法相同&lt;/p&gt;

&lt;h3 id=&quot;7hierarchical-attention&quot;&gt;7)hierarchical attention&lt;/h3&gt;
&lt;p&gt;不同时间步有不同的句子相关，和上篇文献的处理方法动态注意力机制相同。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/56.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/57.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/58.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/59.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;8semantic-similarity-loss&quot;&gt;8)semantic similarity loss&lt;/h3&gt;
&lt;p&gt;目的：获得文章和误导选项的关系。还记得之前定义的e&lt;sub&gt;T&lt;/sub&gt;吗，它表示整篇文章，那么我们通过下面的公式可以获得distractor representation:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/60.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中S&lt;sub&gt;M&lt;/sub&gt;是decoder最后一个隐藏状态，那么我们通过cos计算相似关系，那么最终的损失函数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/61.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;experimental-settings&quot;&gt;Experimental Settings&lt;/h2&gt;
&lt;h3 id=&quot;1dataset-1&quot;&gt;1)dataset&lt;/h3&gt;
&lt;p&gt;使用了上篇文献处理过的RACE数据集。&lt;/p&gt;

&lt;h3 id=&quot;2baselines-and-evaluation-metrics&quot;&gt;2)baselines and evaluation metrics&lt;/h3&gt;
&lt;p&gt;与seq2seq，HRED，HCP&lt;sup id=&quot;fnref:11&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;，HSA&lt;sup id=&quot;fnref:12&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;比较。&lt;/p&gt;

&lt;h3 id=&quot;3implementation-details&quot;&gt;3)implementation details&lt;/h3&gt;
&lt;p&gt;网络超参数设置技巧，不展开了&lt;/p&gt;

&lt;h2 id=&quot;results-and-analysis-结果与分析-1&quot;&gt;Results and Analysis 结果与分析&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/62.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/63.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/64.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;介绍一下上面这张表，这张表是人工评估的结果，从三个维度分析，分别是fluency,coherence,distracting ability。可以看出作者的模型并不是在所有维度都是最好的。&lt;/p&gt;

&lt;p&gt;下图是案例分析：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/65.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;我的看法-2&quot;&gt;我的看法&lt;/h2&gt;
&lt;p&gt;这篇文献是基于上一篇文献的方法进行了两个改进：1.关联了整篇文章和问题，解决方法是使用了Co-attention mechanism。2.让distractor和article语义相关，方法是定义了相关性loss。&lt;/p&gt;

&lt;h1 id=&quot;补充&quot;&gt;补充&lt;/h1&gt;
&lt;h2 id=&quot;race数据集简介&quot;&gt;RACE数据集简介&lt;/h2&gt;
&lt;p&gt;RACE数据集是一个来源于中学考试题目的大规模阅读理解数据集，包含了大约 28000 个文章以及近 100000 个问题。它的形式类似于英语考试中的阅读理解（选择题），给定一篇文章，通过阅读并理解文章（Passage），针对提出的问题（Question）从四个选项中选择正确的答案（Answers）。&lt;/p&gt;
&lt;h2 id=&quot;bleu&quot;&gt;BLEU&lt;/h2&gt;
&lt;p&gt;BLEU是一个评价指标，最开始用于机器翻译任务，定义如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/66.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;它的总体思想就是准确率，假如给定标准译文reference，神经网络生成的句子是candidate，句子长度为n，candidate中有m个单词出现在reference，m/n就是bleu的1-gram的计算公式。BLEU还有许多变种。根据n-gram可以划分成多种评价指标，常见的指标有BLEU-1、BLEU-2、BLEU-3、BLEU-4四种，其中n-gram指的是连续的单词个数为n。&lt;/p&gt;

&lt;h2 id=&quot;rouge&quot;&gt;ROUGE&lt;/h2&gt;
&lt;p&gt;Rouge(Recall-Oriented Understudy for Gisting Evaluation)，是评估自动文摘以及机器翻译的一组指标。它通过将自动生成的摘要或翻译与一组参考摘要（通常是人工生成的）进行比较计算，得出相应的分值，以衡量自动生成的摘要或翻译与参考摘要之间的“相似度”。它的定义如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/67.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;文献中使用的ROUGE-L是一种变种，L即是LCS(longest common subsequence，最长公共子序列)的首字母，因为Rouge-L使用了最长公共子序列。Rouge-L计算方式如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/68.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中LCS(X, Y)是X和Y的最长公共子序列的长度,m、n分别表示参考摘要和自动摘要的长度（一般就是所含词的个数），R&lt;sub&gt;lcs&lt;/sub&gt;,P&lt;sub&gt;lcs&lt;/sub&gt;分别表示召回率和准确率。最后的F&lt;sub&gt;lcs&lt;/sub&gt;即是我们所说的Rouge-L。&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;distractor generation 误导选项生成，简称DG &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;当我们test时，只需要Sequential MLM decoder来预测。 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;multi-choice reading comprehension (MRC) model &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;P-MLM &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Answer negative &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Byte-Pair-Encoding &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;context，question，answer &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;hierarchical encoder-decoder model with static attention &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;hierarchical model enhanced with co-attention &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;hierarchical encoder-decoder &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;相当于HRED+copy,是基于HRED的网络结构 &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;就是上篇文献的网络 &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Quehry</name></author><category term="paper" /><summary type="html">目录</summary></entry><entry><title type="html">软件方法</title><link href="http://localhost:4000/%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95.html" rel="alternate" type="text/html" title="软件方法" /><published>2021-11-30T00:00:00+08:00</published><updated>2021-11-30T00:00:00+08:00</updated><id>http://localhost:4000/%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95</id><content type="html" xml:base="http://localhost:4000/%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95.html">&lt;h1 id=&quot;软件方法&quot;&gt;软件方法&lt;/h1&gt;
&lt;h2 id=&quot;课程要求&quot;&gt;课程要求&lt;/h2&gt;
&lt;p&gt;学习面向对象这种软件开发方法（目前概念越来越广），通过java来了解面向对象具体怎么实现。&lt;/p&gt;

&lt;h3 id=&quot;随记&quot;&gt;随记&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;类，对象：
    &lt;ul&gt;
      &lt;li&gt;给类赋值变成实例/对象&lt;/li&gt;
      &lt;li&gt;c语言可以构建面向对象所有的结构&lt;/li&gt;
      &lt;li&gt;对象就是给类声明的一个变量&lt;/li&gt;
      &lt;li&gt;类集合了属性和方法&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;面向对象的三大特征：
    &lt;ul&gt;
      &lt;li&gt;封装（encapsulation）:
        &lt;ul&gt;
          &lt;li&gt;private, protected, public&lt;/li&gt;
          &lt;li&gt;可作用于属性和方法&lt;/li&gt;
          &lt;li&gt;一般是隐藏对象的属性和实现细节，但是提供方法的接口&lt;/li&gt;
          &lt;li&gt;提供公开的方法&lt;/li&gt;
          &lt;li&gt;提高了软件开发的效率&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/1.jpg&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;继承（inheritance）：
        &lt;ul&gt;
          &lt;li&gt;子类与父类&lt;/li&gt;
          &lt;li&gt;子类自动具有父类属性和方法，添加自己特有的属性和方法，并且子类使用父类的方法也可以覆盖/重写父类方法&lt;/li&gt;
          &lt;li&gt;可以实现代码的复用（当然功能不止于此）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;多态（polymorphism）：
        &lt;ul&gt;
          &lt;li&gt;父类有多个子类&lt;/li&gt;
          &lt;li&gt;子类覆盖/重写父类方法&lt;/li&gt;
          &lt;li&gt;相当于是根据实际创建的对象类型动态决定使用哪个方法&lt;/li&gt;
          &lt;li&gt;所有的子类都可以看成父类的类型，运行时，系统会自动调用各种子类的方法&lt;/li&gt;
          &lt;li&gt;UML可以画出类之间的关系&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;java程序设计
    &lt;ul&gt;
      &lt;li&gt;百分百面向对象
        &lt;ul&gt;
          &lt;li&gt;不存在类以外代码&lt;/li&gt;
          &lt;li&gt;只能采用面向对象方法编程&lt;/li&gt;
          &lt;li&gt;java文件命名规范
            &lt;ul&gt;
              &lt;li&gt;必须以.java结尾&lt;/li&gt;
              &lt;li&gt;源文件中如果只有一个类，文件类必须与该类名相同&lt;/li&gt;
              &lt;li&gt;如果有多个类，且没有public类，文件名可与任一类名相同&lt;/li&gt;
              &lt;li&gt;有多个类，且有public类，文件名必须与该类名相同&lt;/li&gt;
              &lt;li&gt;一个JAVA源文件只能有一个public类，一个文件中只能有一个main主函数&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;静态方法/static，可以直接用类和函数名直接调用，和普通方法的区别是不用new一个示例&lt;/li&gt;
      &lt;li&gt;多态的实现，先定义抽象的（abstract）父类，然后子类继承父类然后定义父类的抽象方法
        &lt;ul&gt;
          &lt;li&gt;通过抽象方法固定通用接口&lt;/li&gt;
          &lt;li&gt;子类通过强制实现抽象方法实现多态&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ppt整理&quot;&gt;PPT整理&lt;/h2&gt;

&lt;h3 id=&quot;1-对象类&quot;&gt;1. 对象，类&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;使用对象之前要先声明和创造&lt;/li&gt;
  &lt;li&gt;类定义了对象的类型，所有对象都是类的实例，所有的类描述了属性和定义了方法&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2面向对象&quot;&gt;2.面向对象&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;封装：保护类的属性和方法,private,default,protected,public&lt;/li&gt;
  &lt;li&gt;继承：B继承A，重用，修改，添加，A所有的属性都存在于B中，A的方法可以在B中重新定义，B的改动不会影响A&lt;/li&gt;
  &lt;li&gt;多态：一个对象属于多个类，通过使用不同类中的方法属于不同的类，父类是抽象类，各个子类继承父类并定义方法，调用的时候根据不同子类调用方法。判断类型是否相同instanceof，声明的时候可以这么声明: A a = new B(),其中B是A的子类。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3java&quot;&gt;3.JAVA&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;x = bool ? a : b，表示如果bool为true，执行a，如果为false执行b&lt;/li&gt;
  &lt;li&gt;for(Point p : this.getVect())表示遍历&lt;/li&gt;
  &lt;li&gt;exception:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/69.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;还有异常的抛出throws&lt;/p&gt;

&lt;p&gt;try-catch-finally&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;  
	    &lt;span class=&quot;c1&quot;&gt;// 可能会发生异常的程序代码  &lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Type1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;  
	    &lt;span class=&quot;c1&quot;&gt;// 捕获并处置try抛出的异常类型Type1  &lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Type2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;  
	    &lt;span class=&quot;c1&quot;&gt;//捕获并处置try抛出的异常类型Type2  &lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;  
	    &lt;span class=&quot;c1&quot;&gt;// 无论是否发生异常，都将执行的语句块  &lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;自定义异常：&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NombreNegatifException&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;NombreNegatifException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Vous avez un nombre négatif !&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;文件读写：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;类FileReader,FileWriter,使用里面的方法read()和write(x)和close()&lt;/p&gt;

&lt;p&gt;比如：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211130/70.jpg&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;枚举enum，举例说明&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;enum&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Jour&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;LUNDI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;MARDI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;MERCREDI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;JEUDI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VENDREDI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;SAMEDI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DIMANCHE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;EssaiJour&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Jour&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Jour&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;valueOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Jour&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;SAMEDI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;fin de semaine : &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;switch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jour&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
        &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;SAMEDI&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DIMANCHE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;se reposer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;travailler&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;接口interface,迭代器iterator&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;举例：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Main&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@FunctionalInterface&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;maFonction&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;appliquer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;transforme&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maFonction&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nouveauVect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; 
        &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nouveauVect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;appliquer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)));&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nouveauVect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nouveauVect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;83&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Les valeurs du vecteur initial : &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; 
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforme&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Les valeurs du vecteur modifié : &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Iterator&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hasNext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;4数据结构&quot;&gt;4.数据结构&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;数据结构一般含有以下功能：创建，插入，寻找，删除，排序&lt;/li&gt;
  &lt;li&gt;二维数组,举例说明：&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[][]={&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;a&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;e&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;i&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;o&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;u&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;3&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;4&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sousTab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sousTab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Valeur du tableau à l&apos;indice [&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;][&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;]: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;或者&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tabEntiers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tabEntiers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;// création effective du tableau précédent&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;列表，包含ArrayList, LinkedList&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。对于随机访问get和set，ArrayList优于LinkedList，因为ArrayList可以随机定位，而LinkedList要移动指针一步一步的移动到节点处。（参考数组与链表来思考）。对于新增和删除操作add和remove，LinedList比较占优势，只需要对指针进行修改即可，而ArrayList要移动数据来填补被删除的对象的空间。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Liste&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
    &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Liste&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;succ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Liste&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;changerValeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Liste&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;succ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;succ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;changerSucc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Liste&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;succ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;changerPred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Liste&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这是一个链表的简写，每一层包含了上一个元素，这一个元素，下一个元素&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;哈希表，通过简历KV关系查找，相比于之前的顺序访问或者其他指数访问要快。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.HashMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestHash&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;HashMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;annuaire&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HashMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// ajout des valeurs&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;annuaire&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Alfred&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2399020806&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;annuaire&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Daniel&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;2186000000&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// obtention d&apos;un numéro&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;annuaire&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;containsKey&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Danielle&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; 
        &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;annuaire&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Danielle&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;«&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Danielle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;+num&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; 
        &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pas trouve&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;树状结构tree&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;一般包含结点&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;结点的度&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;该结点下有多少子树的数目&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;树的度&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;不同的遍历方法&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;：&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;前序遍历&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;首先结点&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;然后左子树&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;右子树&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;中序遍历&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;左子树&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;结点&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;右子树&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;后序遍历&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;左子树&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;右子树&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;结点&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;层序遍历&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;从上到下&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;从左到右&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Arbre&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Arbre&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;existeFilsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;existeFilsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Arbre&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;filsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Arbre&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;filsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;affecterValeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;affecterFilsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Arbre&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;affecterFilsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Arbre&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;}&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;feuille&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hauteur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;existeFilsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hauteur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;existeFilsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hauteur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Constructeurs&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Arbre&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Arbre&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Arbre&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Arbre&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Affichage&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;afficherPrefixe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;\t&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;existeFilsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;afficherPrefixe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;existeFilsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;afficherPrefixe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;afficherInfixe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;existeFilsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;afficherInfixe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;\t&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;existeFilsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;afficherInfixe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;afficherPostfixe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;existeFilsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;afficherPostfixe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;existeFilsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;afficherPostfixe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;\t&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;二叉排序树是指左子树小于结点小于右子树，而且结点值不重复。判断是否为二叉排序树：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;superieur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// vrai si x est supérieur à tous les éléments de l’arbre&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feuille&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(((&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;existeFilsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())?&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;filsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;superieur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;):&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;existeFilsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())?&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;filsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;superieur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;):&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;inferieur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;//similaire a superieur ... }&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;binrech&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feuille&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;existeFilsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()?&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;superieur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsGauche&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;binrech&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()):&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
 &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;existeFilsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()?&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;inferieur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valeur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filsDroit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;binrech&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()):&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Quehry</name></author><category term="school" /><summary type="html">软件方法 课程要求 学习面向对象这种软件开发方法（目前概念越来越广），通过java来了解面向对象具体怎么实现。</summary></entry><entry><title type="html">课程总结</title><link href="http://localhost:4000/%E5%A4%A7%E5%9B%9B%E4%B8%8A%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93.html" rel="alternate" type="text/html" title="课程总结" /><published>2021-11-28T00:00:00+08:00</published><updated>2021-11-28T00:00:00+08:00</updated><id>http://localhost:4000/%E5%A4%A7%E5%9B%9B%E4%B8%8A%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93</id><content type="html" xml:base="http://localhost:4000/%E5%A4%A7%E5%9B%9B%E4%B8%8A%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93.html">&lt;h1 id=&quot;概率统计&quot;&gt;概率统计&lt;/h1&gt;

&lt;h3 id=&quot;简介&quot;&gt;简介&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;授课老师：牛薇&lt;/li&gt;
  &lt;li&gt;授课材料：一份法语讲义，一份习题集（10个EX），上课用的PPT&lt;/li&gt;
  &lt;li&gt;B站有录播，up主：却道成归&lt;/li&gt;
  &lt;li&gt;笔记记在侧边栏为大四上A的笔记本最前面&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;内容总览&quot;&gt;内容总览&lt;/h3&gt;

&lt;p&gt;一半时间概率一半时间统计&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;概率
    &lt;ul&gt;
      &lt;li&gt;先从之前学的概率空间讲起，介绍了概率分布（离散or连续），密度函数，期望方差，收敛性。&lt;/li&gt;
      &lt;li&gt;估计，比如说用平均值估计期望，用频率估计概率等等&lt;/li&gt;
      &lt;li&gt;估计又分为点估计和区间估计，点估计中介绍了似然函数以及最大似然法来找估计量&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;统计
    &lt;ul&gt;
      &lt;li&gt;主要介绍了几种检验方法来检验分布、估计量选择的好坏&lt;/li&gt;
      &lt;li&gt;包括了参数检验，分布检验，比较检验等等&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;A4纸&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/1.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/2.jpg&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;流体力学&quot;&gt;流体力学&lt;/h1&gt;

&lt;h3 id=&quot;简介-1&quot;&gt;简介&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;授课老师：方乐&lt;/li&gt;
  &lt;li&gt;授课材料：PPT，TD都是6个，分别对应六大章&lt;/li&gt;
  &lt;li&gt;B站有录播&lt;/li&gt;
  &lt;li&gt;笔记在侧边栏为大四上A的中后部分和大四上B前面&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;内容总览-1&quot;&gt;内容总览&lt;/h3&gt;

&lt;p&gt;第一章主要讲了流体的概念和动力学的公式。第二章从能量角度出发，介绍了NS方程（斯托克斯方程），和伯努利原理（压强和流速的关系）。第三章介绍了雷诺数，无量纲分析，雷诺数大的是湍流，雷诺数小的是层流。第四章介绍了边界层，第五章介绍了湍流，系统平均。第六章介绍了涡量。&lt;/p&gt;

&lt;h3 id=&quot;a4纸&quot;&gt;A4纸&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/3.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/4.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;报告&quot;&gt;报告&lt;/h3&gt;
&lt;p&gt;结课之前需要我们写一个报告，什么形式的都可以，我觉得这种方式挺好的，自由发挥，我做的实验，用牛奶和墨水还原了卡门涡街。&lt;/p&gt;

&lt;h1 id=&quot;电磁辐射波&quot;&gt;电磁辐射波&lt;/h1&gt;

&lt;h3 id=&quot;简介-2&quot;&gt;简介&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;授课老师: José Penuelas(负责前几章教学), Bertrand Vilquin(负责后几章教学), 孙鸣捷老师(负责TD)&lt;/li&gt;
  &lt;li&gt;授课形式：线上讲解原理，线下TD&lt;/li&gt;
  &lt;li&gt;授课材料：PPT，讲义，TD&lt;/li&gt;
  &lt;li&gt;B站有录播&lt;/li&gt;
  &lt;li&gt;有笔记，侧边栏叫做电磁学(大四上)&lt;/li&gt;
  &lt;li&gt;考试闭卷，所以没有A4纸&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;内容总览-2&quot;&gt;内容总览&lt;/h3&gt;
&lt;p&gt;首先回顾了之前学的波动物理和电磁学，电磁辐射，顾名思义是要将辐射，讲了波导，腔和光电效应，能级跃迁等等&lt;/p&gt;

&lt;h1 id=&quot;传感器&quot;&gt;传感器&lt;/h1&gt;

&lt;h3 id=&quot;简介-3&quot;&gt;简介&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;授课老师：徐平&lt;/li&gt;
  &lt;li&gt;授课形式：线下授课，做实验&lt;/li&gt;
  &lt;li&gt;授课材料：大学生MOOC&lt;/li&gt;
  &lt;li&gt;没有考试，没有笔记&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;内容总览-3&quot;&gt;内容总览&lt;/h3&gt;
&lt;p&gt;讲解了传感器的基本原理，构造和常见传感器，每节课都需要在MOOC上做题，也有安排答辩，我和蔡卓江、宋正浩、刘亚林、马卫一一组讲解了机器狗。做实验是指去214玩小车，上面有不少传感器，也有大疆的线上模拟器，还是挺不错的一次动手实验。&lt;/p&gt;

&lt;h1 id=&quot;结构力学&quot;&gt;结构力学&lt;/h1&gt;

&lt;h3 id=&quot;简介-4&quot;&gt;简介&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;授课老师：黄行蓉，Jean-Piere Lainé&lt;/li&gt;
  &lt;li&gt;授课形式：J-P录制ppt，黄老师线下授课&lt;/li&gt;
  &lt;li&gt;授课材料：讲义，PPT，TD&lt;/li&gt;
  &lt;li&gt;B站有录播&lt;/li&gt;
  &lt;li&gt;笔记：侧边栏结构力学，还有最后第八章记在大四上C前面&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;内容总览-4&quot;&gt;内容总览&lt;/h3&gt;
&lt;p&gt;结构力学分为了两大部分，弹性力学和材料力学。在弹性力学部分，首先介绍了应力和应力张量的概念，张量可以写成3*3矩阵形式，其中对角线上的元素被称作正应力。第二章介绍了应变，首先介绍了很多种张量，F、H、C、E，然后介绍了形变张量ε。第三章介绍了本构方程（应力应变关系方程）。第四章介绍了能量，包括最小势能和最大余能等等。&lt;/p&gt;

&lt;p&gt;第二部分是材料力学，主题内容和弹性力学类似，但是引进了力螺旋的概念，这个概念在中国授课好像是没有的，它描述了合力和力矩。第一张介绍了内力，在材料力学部分我们主要研究梁这个结构，它包括了中轴线和截面，这部分内容和之前学的理论力学很相似。第二章介绍了应力，可以用内力表示应力，用一些惯性矩、艾力函数连接。第三章介绍了应变和本构方程，第四章介绍了能量部分，主要是三大定理：théorème de ménabréa;théorème de maxwell-betti;théorème de castigliano。&lt;/p&gt;

&lt;h3 id=&quot;a4纸-1&quot;&gt;A4纸&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/5.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/6.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/7.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/8.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/9.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/posts/20211128/10.jpg&quot; /&gt;&lt;/p&gt;</content><author><name>Quehry</name></author><category term="school" /><summary type="html">概率统计</summary></entry><entry><title type="html">MCQ文献阅读</title><link href="http://localhost:4000/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html" rel="alternate" type="text/html" title="MCQ文献阅读" /><published>2021-11-25T00:00:00+08:00</published><updated>2021-11-25T00:00:00+08:00</updated><id>http://localhost:4000/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB</id><content type="html" xml:base="http://localhost:4000/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html">&lt;h2 id=&quot;整理集合&quot;&gt;整理集合&lt;/h2&gt;
&lt;p&gt;多选题自动生成：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;定义&lt;br /&gt;
输入一篇文章，从这篇文章生成一系列多选题&lt;/li&gt;
  &lt;li&gt;模型结构&lt;br /&gt;
待补充&lt;/li&gt;
  &lt;li&gt;工作流程&lt;br /&gt;
六大步：
    &lt;ul&gt;
      &lt;li&gt;输入文章预处理&lt;/li&gt;
      &lt;li&gt;选择句子&lt;/li&gt;
      &lt;li&gt;从句子中选择关键字&lt;/li&gt;
      &lt;li&gt;生成疑问句&lt;/li&gt;
      &lt;li&gt;生成误导选项&lt;/li&gt;
      &lt;li&gt;后期处理&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;主流的研究关注点与现存的问题
    &lt;ul&gt;
      &lt;li&gt;目前大多数处理文本都不考虑公式、图片和图标等等信息，文本预处理只提取文本信息，今后MCQG的研究需要关注处理嵌入在文本中的信息的能力。&lt;/li&gt;
      &lt;li&gt;现有的MCQ生成方法侧重于从单个句子生成问题，然而，文本可能通过多个句子来生成句子，所以今后的研究应该侧重于从多个句子中生成问题。&lt;/li&gt;
      &lt;li&gt;关键字的选择取决于下游任务或者应用领域，早期的关键字选择依赖于基本的统计和句法信息。最新的研究趋势是使用&lt;strong&gt;机器学习&lt;/strong&gt;或者&lt;strong&gt;语义信息&lt;/strong&gt;作为选择的标准。&lt;/li&gt;
      &lt;li&gt;误导选项的选择同样与应用领域有关，目前的MCQ生成系统中使用的都是简单的误导选项生成，但在实际情况中，误导选项可以是非常多种类的，可以是不同的命名体，数字大小，多个单词的误导选项等等。作者认为文本的深层语义分析或使用基于神经嵌入的方法可能是复杂误导答案生成的一个可能的方向。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;一篇关于mcqg的综述&quot;&gt;一篇关于MCQG的综述&lt;/h2&gt;
&lt;h3 id=&quot;title&quot;&gt;Title&lt;/h3&gt;
&lt;p&gt;Automatic Multiple Choice Question Generation From Text: A Survey&lt;/p&gt;
&lt;h3 id=&quot;author&quot;&gt;Author&lt;/h3&gt;
&lt;p&gt;Dhawaleswar Rao CH and Sujan Kumar Saha&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/Dhawaleswar.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/Sujan.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;abstract&quot;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;MCQ&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;工作20年前已经开始研究，综述将概括目前常见的多选题自动生成的&lt;strong&gt;工作流&lt;/strong&gt;和&lt;strong&gt;评估系统&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&quot;1introduction&quot;&gt;1.introduction&lt;/h3&gt;
&lt;p&gt;介绍了MCQ的重要性，是评估知识学习的工具之一，优点是耗时短但是人工出题需要很多时间，所以通过一段文章自动生成问题是人们关注的重点。&lt;/p&gt;
&lt;h3 id=&quot;2multiple-choice-question&quot;&gt;2.multiple choice question&lt;/h3&gt;
&lt;p&gt;介绍了MCQ和MCQ的基本结构，由题干，正确答案和误导答案组成，同时具体介绍了MCQ的优缺点。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;优点&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;缺点&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;快速评估，耗时短&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;涵盖的知识面很小&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;可以实现机器阅卷&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;答案有猜测出来的可能&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;3research-motivation-and-objectives&quot;&gt;3.research motivation and objectives&lt;/h3&gt;
&lt;p&gt;MCQ的研究动机主要来源于人工出题繁琐且耗时间。&lt;/p&gt;
&lt;h3 id=&quot;4review-methodology&quot;&gt;4.review methodology&lt;/h3&gt;
&lt;p&gt;作者从大量paper中挑选了86篇文章做来做MCQ的综述。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/article_collection.jpg&quot; alt=&quot;article_collection&quot; /&gt;&lt;/p&gt;

&lt;p&gt;介绍了一下检索文章的步骤&lt;br /&gt;
同时介绍了不同的QG的方法分布&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/分布图.jpg&quot; alt=&quot;distribution&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;5discussion-on-the-appproaches-for-mcq-generation&quot;&gt;5.discussion on the appproaches for MCQ generation&lt;/h3&gt;
&lt;p&gt;自动生成MCQ和手动生成MCQ的步骤大致相同：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pre-processing of Input Text 预处理输入文章&lt;/li&gt;
  &lt;li&gt;Sentence Selection 句子选择&lt;/li&gt;
  &lt;li&gt;Key Selection 选择答案信息&lt;/li&gt;
  &lt;li&gt;Question Formation 问题生成&lt;/li&gt;
  &lt;li&gt;Distractor Generation 错误答案生成&lt;/li&gt;
  &lt;li&gt;Post-Processing 后期处理&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/workflow.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面从这六个阶段分别分析：&lt;/p&gt;
&lt;h4 id=&quot;1pre-processing-of-input-text&quot;&gt;1.&lt;strong&gt;Pre-processing of Input Text&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;用到的技巧（每一个技巧都有对应的文献）：
    &lt;ul&gt;
      &lt;li&gt;text normalization: 将文本格式变成我们需要的格式，不同的应用领域需要不同的格式化方法&lt;/li&gt;
      &lt;li&gt;structure analysis：给出段落结构&lt;/li&gt;
      &lt;li&gt;sentence simplification：把长句子变成短句子&lt;/li&gt;
      &lt;li&gt;lexical analysis：词汇分析，把文本分隔成单词，符号和数字。同时需要进行词根提取&lt;/li&gt;
      &lt;li&gt;statistical analysis：统计分析，包括不同的统计手段，比如词频，n元词频等&lt;/li&gt;
      &lt;li&gt;syntactic analysis：语法分析，包括POS&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;，NER&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;，syntactic parsing&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;。&lt;/li&gt;
    &lt;/ul&gt;

    &lt;ul&gt;
      &lt;li&gt;coreference resolution: 代词通常不作为疑问句的主语，代词解析就是将代词映射到相应的名词。&lt;/li&gt;
      &lt;li&gt;word sense disambiguation：消除句子中单词的歧义&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;作者指出，对于text的预处理主要取决于输入文本的性质和下游任务的需求，比如说从web端爬下的文本会包含很多噪音和没必要的内容，那么文本清理就是必须的，再比如wikipedia文档作为输入时常常是一个长句子，需要把长句子简化变成短句子。&lt;br /&gt;
目前大多数处理文本都不考虑公式、图片和图标等等信息，文本预处理只提取文本信息，今后MCQG的研究需要关注处理嵌入在文本中的信息的能力。&lt;/p&gt;

&lt;h4 id=&quot;2sentence-selection&quot;&gt;2.&lt;strong&gt;sentence selection&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在对输入文本进行处理之后需要挑选出包含questionable fact的句子，我的理解是那些包含事实的句子。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;一些技巧：
    &lt;ul&gt;
      &lt;li&gt;sentence length：给出句子中单词的数量，一般来说，很短的句子不能包含足够的信息来生成问题，同样来说，很长的句子通常包含多个事实和关系，这会给生成问题带来困难。&lt;/li&gt;
      &lt;li&gt;occurrence of a particular word：查找特殊词汇&lt;/li&gt;
      &lt;li&gt;parts-of-speech information: 根据一个句子中出现词汇的词性挑选句子，比如说根据名词-形容词对的出来情况来选择句子。&lt;/li&gt;
      &lt;li&gt;parse information: 根据句子结构挑选，比如主谓宾&lt;/li&gt;
      &lt;li&gt;semantic information: 文本中包含的语义信息也作为选择句子的标准&lt;/li&gt;
      &lt;li&gt;machine learning: 使用机器学习算法，比如支持向量机、神经网络等&lt;/li&gt;
      &lt;li&gt;summarization：基于摘要的方法来选择句子&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;句子的选择同样需要根据任务的不同来选择。现有的MCQ生成方法侧重于从单个句子生成问题，然而，文本可能通过多个句子来生成句子，所以今后的研究应该侧重于&lt;strong&gt;从多个句子中生成问题&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&quot;3key-selection&quot;&gt;3.&lt;strong&gt;key Selection&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;选择好句子后，我们从中挑选出关键词。我们不能将一个句子的全部词汇都作为关键词，因此，关键字的选择是确定句子中要被删除的单词（或者短语、n元词元）&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一些技巧：
    &lt;ul&gt;
      &lt;li&gt;frequency count: 统计单词的出现频率作为选择标准&lt;/li&gt;
      &lt;li&gt;part-of-speech and parse information: 在某些特定的应用领域中，一个特定的词性或者语法可以成为一个潜在的关键字。比如一些研究用动词作为关键字，一些研究用介词作为关键字。&lt;/li&gt;
      &lt;li&gt;semantic information: 语义信息。&lt;/li&gt;
      &lt;li&gt;pattern matching：模式匹配，从结构相似的句子中提取出常见的句型，这样有助于句子解析结构来寻找关键字&lt;/li&gt;
      &lt;li&gt;machine learning：利用机器学习来生成动词或者部分习语或者副词来作为关键字。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;关键字的选择同样取决于下游任务或者应用领域，早期的关键字选择依赖于基本的统计和句法信息。最新的研究趋势是使用&lt;strong&gt;机器学习&lt;/strong&gt;或者&lt;strong&gt;语义信息&lt;/strong&gt;作为选择的标准。&lt;/p&gt;

&lt;h4 id=&quot;4question-formation&quot;&gt;4.&lt;strong&gt;question formation&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;选完关键字后，我们下一个任务就是把陈述句转化为疑问句。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一些技巧：
    &lt;ul&gt;
      &lt;li&gt;by appropriate wh-word selection: 根据句子的语法结构和关键字来确定使用哪个wh&lt;/li&gt;
      &lt;li&gt;subject-verb-object and their relationship：通过主谓宾结构来生成疑问句&lt;/li&gt;
      &lt;li&gt;knowledge in sentence：根据句子所包含的知识类型来确定转换规则，例如这个句子是概念，定义，示例等等。&lt;/li&gt;
      &lt;li&gt;dependency based patterns: 根据句子的依赖关系树来确定主要动词和将被问及的问题部分&lt;/li&gt;
      &lt;li&gt;syntactic transformation：通过句法结构来生成问题。&lt;/li&gt;
      &lt;li&gt;discourse connectives：通过不同的关系来转化，比如时间关系，空间关系。&lt;/li&gt;
      &lt;li&gt;semantic information based：基于语义来转化。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;question generation，问题生成也是一个热门的研究方向，该领域的目标是根据输入文本生成问题。在MCQ中，我们首先选取一个句子，然后选择关键字，最后根据关键字转换成问句形式。&lt;/p&gt;

&lt;h4 id=&quot;5distractor-generation&quot;&gt;5.&lt;strong&gt;distractor generation&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;错误选项在MCQ中扮演重要的地位，如果错误选项不能很好的迷惑学生，那么这道多选题出的并不好。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;一些技巧：
    &lt;ul&gt;
      &lt;li&gt;parts-of-speech information：错误选项和关键字在语义上很接近，所以他们的词性也要一样&lt;/li&gt;
      &lt;li&gt;frequency：频率也是一个重要的指标，关键字和错误选项的出现频率应该相近。&lt;/li&gt;
      &lt;li&gt;wordnet：wordnet是一个词汇数据库，它将单词分组为同义词集并记录这些词集成员的关系。因此可以用wordnet来生成错误选项。&lt;/li&gt;
      &lt;li&gt;domain ontology：一些文献用web ontology language来寻找错误答案。&lt;/li&gt;
      &lt;li&gt;distributional hypothesis: 分布假设认为相似的词出现在相似的语境中，那么我们可以基于分布相似度来寻找错误答案。&lt;/li&gt;
      &lt;li&gt;semantic analysis：基于语义。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;错误选项的选择同样与应用领域有关，目前的MCQ生成系统中使用的都是简单的错误选项生成，但在实际情况中，错误选项可以是非常多种类的，可以是不同的命名体，数字大小，多个单词的错误选项等等。作者认为文本的深层语义分析或使用基于神经嵌入的方法可能是复杂错误答案生成的一个可能的方向。&lt;/p&gt;

&lt;h4 id=&quot;6post-processing&quot;&gt;6.&lt;strong&gt;post-processing&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;后期处理是提高生成MCQ质量的阶段，系统生成的MCQ可能存在各种各样的错误。可能是标点符号错误，疑问词不恰当，问句过长等等，后期处理希望消除这些问题。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;一些技巧：
    &lt;ul&gt;
      &lt;li&gt;question post-editing：有些文献的方法是手动更改， 首先对于问题执行分类，是小问题就更正拼写和标点，如果是大问题就对题干进行重新措辞和替换等等。&lt;/li&gt;
      &lt;li&gt;question filtering：有些文献设计了一个过滤器来拒绝不对的问题，有的过滤器主要判断错误选项的质量，有的过滤器基于项目信息来过滤。&lt;/li&gt;
      &lt;li&gt;question ranking：对问题进行排名。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;6mcq-system-evalutaion&quot;&gt;6.MCQ system evalutaion&lt;/h3&gt;
&lt;p&gt;评估MCQ生成好坏，目前大多数系统采用
人工评估的办法。由于MCQ生成包含了很多步骤，那么就产生了不同的度量标准。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;evaluation of the stem and key&lt;/strong&gt;:
  目前还没有标准的公共数据集来评估MCQ，所以一般都是开发人员创建测试数据，下面有一张图展示了MCQ系统的评估过程，从表中可以看出，并没有一个标准的性能度量标准，开发人员采用了各种指标和参数。我们只能比较基于同一套评价体系下的MCQ。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;./assets/img/posts/20211125/evaluation.jpg&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;evaluation of the distractors&lt;/strong&gt;：
  同样的，错误答案的评估也没有标准的数据集和评估指标。在许多应用领域中，MCQ有大量的干扰因素，所以一个标准的数据集可能无法容纳所有。所以目前还是有相关专家来评估。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;7conclusion&quot;&gt;7.conclusion&lt;/h3&gt;
&lt;p&gt;总结了工作流程中的六个阶段，总结了目前的挑战和今后的研究方向，以及评价标准未确立等等。MCQ领域还有很多地方值得深入研究。&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;multiple choice question，多选题。 &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;part of speech 词性分析 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;命名实体识别 &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;句子结构分析 &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Quehry</name></author><category term="paper" /><summary type="html">整理集合 多选题自动生成： 定义 输入一篇文章，从这篇文章生成一系列多选题 模型结构 待补充 工作流程 六大步： 输入文章预处理 选择句子 从句子中选择关键字 生成疑问句 生成误导选项 后期处理 主流的研究关注点与现存的问题 目前大多数处理文本都不考虑公式、图片和图标等等信息，文本预处理只提取文本信息，今后MCQG的研究需要关注处理嵌入在文本中的信息的能力。 现有的MCQ生成方法侧重于从单个句子生成问题，然而，文本可能通过多个句子来生成句子，所以今后的研究应该侧重于从多个句子中生成问题。 关键字的选择取决于下游任务或者应用领域，早期的关键字选择依赖于基本的统计和句法信息。最新的研究趋势是使用机器学习或者语义信息作为选择的标准。 误导选项的选择同样与应用领域有关，目前的MCQ生成系统中使用的都是简单的误导选项生成，但在实际情况中，误导选项可以是非常多种类的，可以是不同的命名体，数字大小，多个单词的误导选项等等。作者认为文本的深层语义分析或使用基于神经嵌入的方法可能是复杂误导答案生成的一个可能的方向。</summary></entry><entry><title type="html">练习Markdown</title><link href="http://localhost:4000/%E7%BB%83%E4%B9%A0Markdown.html" rel="alternate" type="text/html" title="练习Markdown" /><published>2021-11-24T00:00:00+08:00</published><updated>2021-11-24T00:00:00+08:00</updated><id>http://localhost:4000/%E7%BB%83%E4%B9%A0Markdown</id><content type="html" xml:base="http://localhost:4000/%E7%BB%83%E4%B9%A0Markdown.html">&lt;h1 id=&quot;1标题&quot;&gt;1.标题&lt;/h1&gt;
&lt;h1 id=&quot;一级标题&quot;&gt;一级标题&lt;/h1&gt;
&lt;h2 id=&quot;二级标题&quot;&gt;二级标题&lt;/h2&gt;
&lt;h3 id=&quot;三级标题&quot;&gt;三级标题&lt;/h3&gt;
&lt;p&gt;一共有6级标题&lt;/p&gt;

&lt;h1 id=&quot;2段落及格式&quot;&gt;2.段落及格式&lt;/h1&gt;
&lt;p&gt;用两个空格加回车表示换行&lt;br /&gt;
当然也可以直接空一行出来表示换行&lt;/p&gt;

&lt;h2 id=&quot;1各种文字表示&quot;&gt;1)各种文字表示&lt;/h2&gt;
&lt;h3 id=&quot;斜体&quot;&gt;斜体&lt;/h3&gt;
&lt;p&gt;用两个&lt;em&gt;或者两个_把需要斜体的文字围起来&lt;br /&gt;
比如：&lt;br /&gt;
*斜体&lt;/em&gt;&lt;br /&gt;
&lt;em&gt;斜体&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;粗体&quot;&gt;粗体&lt;/h3&gt;
&lt;p&gt;用两个&lt;strong&gt;或者两个__把需要粗体的文字围起来&lt;br /&gt;
比如:&lt;br /&gt;
**粗体&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;粗体&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;粗斜体&quot;&gt;粗斜体&lt;/h3&gt;
&lt;p&gt;用两个&lt;strong&gt;&lt;em&gt;或者两个___把需要粗体的文字围起来&lt;br /&gt;
比如:&lt;br /&gt;
**&lt;/em&gt;粗体&lt;/strong&gt;*&lt;br /&gt;
&lt;strong&gt;&lt;em&gt;粗体&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;2分隔线&quot;&gt;2)分隔线&lt;/h2&gt;
&lt;p&gt;你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线：&lt;br /&gt;
***&lt;/p&gt;
&lt;hr /&gt;
&lt;hr /&gt;
&lt;hr /&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;3删除线&quot;&gt;3)删除线&lt;/h2&gt;
&lt;p&gt;如果段落上的文字要添加删除线，只需要在文字的两端加上两个波浪线&lt;del&gt;即可
比如：&lt;br /&gt;
~~哈哈哈哈&lt;/del&gt;&lt;/p&gt;

&lt;h2 id=&quot;4下划线&quot;&gt;4)下划线&lt;/h2&gt;
&lt;p&gt;下划线可以通过HTML的&amp;lt;u&amp;gt;标签来实现
比如：&lt;br /&gt;
&lt;u&gt;下划线&lt;/u&gt;&lt;/p&gt;

&lt;h2 id=&quot;5脚注&quot;&gt;5)脚注&lt;/h2&gt;
&lt;p&gt;脚注是对文本的补充说明   &lt;br /&gt;
创建脚注格式类似这样 &lt;sup id=&quot;fnref:12&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;br /&gt;
脚注链接与脚注不能紧挨在一起。&lt;br /&gt;
注脚默认在最后&lt;/p&gt;

&lt;h1 id=&quot;3列表&quot;&gt;3.列表&lt;/h1&gt;

&lt;h2 id=&quot;1无序列表&quot;&gt;1)无序列表&lt;/h2&gt;
&lt;p&gt;无序列表使用星号(*)、加号(+)或是减号(-)作为列表标记，这些标记后面要添加一个空格，然后再填写内容。&lt;br /&gt;
比如：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;第一项&lt;/li&gt;
  &lt;li&gt;第二项&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;第三项&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;第一项&lt;/li&gt;
  &lt;li&gt;第二项&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;第三项&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;第一项&lt;/li&gt;
  &lt;li&gt;第二项&lt;/li&gt;
  &lt;li&gt;第三项&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2有序列表&quot;&gt;2)有序列表&lt;/h2&gt;
&lt;p&gt;有序列表使用数字并加上 . 号来表示，如：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;第一项&lt;/li&gt;
  &lt;li&gt;第二项&lt;/li&gt;
  &lt;li&gt;第三项&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;3列表嵌套&quot;&gt;3)列表嵌套&lt;/h2&gt;
&lt;p&gt;列表嵌套只需在子列表中的选项前面添加四个空格即可。比如：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;第一项：
    &lt;ul&gt;
      &lt;li&gt;第一项嵌套的第一个元素&lt;/li&gt;
      &lt;li&gt;第一项嵌套的第二个元素&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;第二项：
    &lt;ul&gt;
      &lt;li&gt;第二项嵌套的第一个元素&lt;/li&gt;
      &lt;li&gt;第二项嵌套的第二个元素&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;3区块&quot;&gt;3.区块&lt;/h1&gt;

&lt;h2 id=&quot;1区块引用&quot;&gt;1)区块引用&lt;/h2&gt;
&lt;p&gt;Markdown 区块引用是在段落开头使用 &amp;gt; 符号 ，然后后面紧跟一个空格符号：&lt;br /&gt;
比如：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;区块引用&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;2区块嵌套&quot;&gt;2)区块嵌套&lt;/h2&gt;
&lt;p&gt;另外区块是可以嵌套的，一个 &amp;gt; 符号是最外层，两个 &amp;gt; 符号是第一层嵌套，以此类推：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;最外层&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;第一层嵌套&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;3区块中使用列表&quot;&gt;3)区块中使用列表&lt;/h2&gt;
&lt;p&gt;比如：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;区块中使用列表&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;第一项&lt;/li&gt;
    &lt;li&gt;第二项
      &lt;ul&gt;
        &lt;li&gt;第一项&lt;/li&gt;
        &lt;li&gt;第二项&lt;/li&gt;
        &lt;li&gt;第三项&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;4列表中使用区块&quot;&gt;4)列表中使用区块&lt;/h2&gt;
&lt;p&gt;如果要在列表项目内放进区块，那么就需要在 &amp;gt; 前添加四个空格的缩进。&lt;br /&gt;
列表中使用区块实例如下：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;第一项
    &lt;blockquote&gt;
      &lt;p&gt;菜鸟教程
学的不仅是技术更是梦想&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;第二项&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;4使用代码&quot;&gt;4.使用代码&lt;/h1&gt;

&lt;h2 id=&quot;1代码&quot;&gt;1)代码&lt;/h2&gt;
&lt;p&gt;如果是段落上的一个函数或片段的代码可以用反引号把它包起来(`)，例如：&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;printf()&lt;/code&gt;函数&lt;/p&gt;

&lt;h2 id=&quot;2指定一种语言&quot;&gt;2)指定一种语言&lt;/h2&gt;
&lt;p&gt;可以用```包裹一段代码，并指定一种语言（也可以不指定）：&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;  
    &lt;span class=&quot;n&quot;&gt;qhr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qhr&lt;/span&gt;  
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;qhr&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;5使用链接&quot;&gt;5.使用链接&lt;/h1&gt;

&lt;h2 id=&quot;1链接使用方法&quot;&gt;1)链接使用方法&lt;/h2&gt;
&lt;p&gt;[链接名称](链接地址)或者&lt;链接地址&gt;&lt;/链接地址&gt;&lt;/p&gt;

&lt;p&gt;比如：&lt;/p&gt;

&lt;p&gt;这是一个链接 &lt;a href=&quot;https://www.runoob.com&quot;&gt;菜鸟教程&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;2直接使用链接地址&quot;&gt;2)直接使用链接地址&lt;/h2&gt;
&lt;p&gt;用&amp;lt;&amp;gt;把链接括起来。&lt;br /&gt;
比如:&lt;a href=&quot;http://www.runoob.com&quot;&gt;http://www.runoob.com&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;6图片&quot;&gt;6.图片&lt;/h1&gt;

&lt;h2 id=&quot;1使用图片&quot;&gt;1)使用图片&lt;/h2&gt;
&lt;p&gt;图片的语法格式：![alt 属性文本](图片地址 “可选标题”)&lt;/p&gt;

&lt;h2 id=&quot;2链接图片&quot;&gt;2)链接图片&lt;/h2&gt;
&lt;p&gt;大概长这样：&lt;br /&gt;
&amp;lt;img src=”http://static.runoob.com/images/runoob-logo.png” width=”50%”&amp;gt;
结果：&lt;br /&gt;
&lt;img src=&quot;http://static.runoob.com/images/runoob-logo.png&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;7表格&quot;&gt;7.表格&lt;/h1&gt;

&lt;h2 id=&quot;1格式&quot;&gt;1)格式&lt;/h2&gt;

&lt;p&gt;Markdown 制作表格使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行。&lt;br /&gt;
比如：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;表头&lt;/th&gt;
      &lt;th&gt;表头&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;单元格&lt;/td&gt;
      &lt;td&gt;单元格&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;单元格&lt;/td&gt;
      &lt;td&gt;单元格&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;2对齐方法&quot;&gt;2)对齐方法&lt;/h2&gt;
&lt;p&gt;在---前面加上:表示左对齐，在后面加上:表示右对齐，在两端加上:表示居中&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;左对齐&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;右对齐&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;居中对齐&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;单元格&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;单元格&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;单元格&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;单元格&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;单元格&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;单元格&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;8高级技巧&quot;&gt;8.高级技巧&lt;/h1&gt;

&lt;h2 id=&quot;1插入数学公式&quot;&gt;1)插入数学公式&lt;/h2&gt;
&lt;p&gt;当你需要在编辑器中插入数学公式时，可以使用两个美元符 $$ 包裹 TeX 或 LaTeX 格式的数学公式来实现。提交后，问答和文章页会根据需要加载 Mathjax 对数学公式进行渲染。比如：&lt;/p&gt;

&lt;p&gt;$$&lt;br /&gt;
\mathbf{V}_1 \times \mathbf{V}_2 =  \begin{vmatrix} 
\mathbf{i} &amp;amp; \mathbf{j} &amp;amp; \mathbf{k} &lt;br /&gt;
\frac{\partial X}{\partial u} &amp;amp;  \frac{\partial Y}{\partial u} &amp;amp; 0 &lt;br /&gt;
\frac{\partial X}{\partial v} &amp;amp;  \frac{\partial Y}{\partial v} &amp;amp; 0 &lt;br /&gt;
\end{vmatrix}
${$tep1}{\style{visibility:hidden}{(x+1)(x+1)}}&lt;br /&gt;
$$&lt;/p&gt;

&lt;p&gt;输出结果为：&lt;/p&gt;

\[\mathbf{V}_1 \times \mathbf{V}_2 =  \begin{vmatrix} 
\mathbf{i} &amp;amp; \mathbf{j} &amp;amp; \mathbf{k} \\
\frac{\partial X}{\partial u} &amp;amp;  \frac{\partial Y}{\partial u} &amp;amp; 0 \\
\frac{\partial X}{\partial v} &amp;amp;  \frac{\partial Y}{\partial v} &amp;amp; 0 \\
\end{vmatrix}
${$tep1}{\style{visibility:hidden}{(x+1)(x+1)}}\]

\[\sum_{i=0}N\int_{a}{b}g(t,i)\text{d}t\]

&lt;p&gt;&lt;strong&gt;还没有整明白，用到的时候在看&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;未完待续&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:12&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;我是脚注脚注脚注注脚 &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Quehry</name></author><category term="daily" /><summary type="html">1.标题 一级标题 二级标题 三级标题 一共有6级标题</summary></entry></feed>